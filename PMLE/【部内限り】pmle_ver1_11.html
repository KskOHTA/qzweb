<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Professional Machine Learning Engneer問題集 01</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">


<div class='question' data-multiple='false' data-question='問題1<br>あなたは製造会社のMLエンジニアです。あなたは、組立ラインの最後に撮影された製品の画像に基づいて、製品の欠陥を識別するモデルを構築する必要があります。あなたは、製品の欠陥の特徴を素早く抽出するために、より少ない計算で画像を前処理するモデルを望んでいます。<br>モデルを構築するためにどのアプローチを採用すべきですか？' data-answer='0' data-explanation='解説<br>正解は「畳み込みニューラルネットワーク（CNN）」です。<br>この問題では、製品の欠陥を識別するためのモデルを構築する必要がありますが、特に画像データの前処理という観点が重要です。製品の画像から欠陥を特定するためには、モデルは画像データの特徴を効率的に抽出する能力が求められます。その上で、計算量を少なく抑えるというニーズに対応するためには、特定の種類のネットワークを選択することが求められます。選択肢から最も適切なアプローチを選ぶとき、画像データの特性と計算効率のバランスに注意しなければなりません。<br>基本的な概念や原則：<br>畳み込みニューラルネットワーク（CNN）：画像やビデオの解析に適した深層学習モデルです。画像の局所的な特徴を捉え、画像全体の理解を構築します。欠陥検出や画像分類などのタスクに適しています。<br>強化学習：試行錯誤を通じて行動を最適化するための機械学習の形式です。ゲームや制御システムなど、インタラクティブな環境での意思決定に適しています。<br>レコメンダーシステム：ユーザーの興味や動向に応じて、プロダクトやサービスを推薦するシステムです。ユーザーの行動や履歴などのデータに基づいて予測を行います。<br>リカレントニューラルネットワーク（RNN）：時系列データの分析に適したニューラルネットワークです。前のタイムステップの情報を次のタイムステップに伝達するという特性を持っています。時系列予測や自然言語処理に用いられます。<br>正解についての説明：<br>（選択肢）<br>・畳み込みニューラルネットワーク（CNN）<br>この選択肢が正解の理由は以下の通りです。<br>まず、畳み込みニューラルネットワーク（CNN）は、画像のような高次元データを効率的に処理するために設計されたニューラルネットワークの一種で、特に画像識別や解析に強い力を発揮します。製品の欠陥識別というタスクは基本的に画像分類問題であり、CNNはそのような問題に適しています。<br>CNNは、自動的に画像から特徴を抽出します。これにより、モデル訓練の過程で人手で特徴量を設計する必要がなくなり、省計算化と効率化が図られます。<br>また、CNNは階層的構造を持つため、低レベルの特徴から高レベルの特徴まで多様な抽象化が可能で、これが製品の欠陥識別という複雑なタスクを果たすのに有効です。<br>したがって、素早く特徴を抽出し画像を前処理するためには、CNNを採用するのが最適です。<br>不正解の選択肢についての説明：<br>選択肢：強化学習<br>この選択肢が正しくない理由は以下の通りです。<br>強化学習はエージェントが環境内で行動を選択し、報酬に基づいて学習を進める手法であり、画像の前処理や欠陥の特徴を素早く抽出するタスクには適していません。<br>一方、畳み込みニューラルネットワーク（CNN）は画像の特徴を局所的に捉え、階層的に学習することで高い性能を発揮するため、この問題に適しています。<br>選択肢：レコメンダシステム<br>この選択肢が正しくない理由は以下の通りです。<br>レコメンダシステムは、ユーザーの過去の行動や好みに基づいてアイテムを推薦するためのアルゴリズムです。製品の画像から欠陥を識別するという課題とは全く関連性がありません。<br>一方、畳み込みニューラルネットワーク（CNN）は、画像処理に特化した深層学習モデルであり、画像から特徴を抽出するのに適しています。<br>選択肢：リカレントニューラルネットワーク（RNN）<br>この選択肢が正しくない理由は以下の通りです。<br>リカレントニューラルネットワーク（RNN）は、テキストや音声などの連続的なデータを扱うのに適していますが、画像のような2次元のデータの特徴を抽出するのには効率が良くありません。<br>それに対して、畳み込みニューラルネットワーク（CNN）は、画像の特徴を効率よく抽出できるため、画像ベースの欠陥検出モデルに適しています。'>
<div class='choice'> 畳み込みニューラルネットワーク（CNN）</div>
<div class='choice'> レコメンダシステム</div>
<div class='choice'> 強化学習</div>
<div class='choice'> リカレントニューラルネットワーク（RNN）</div>
</div>

<div class='question' data-multiple='false' data-question='問題2<br>AI Platformに複数のバージョンの画像分類モデルをデプロイしました。あなたは、時間の経過とともにモデルのバージョンのパフォーマンスを監視したいと考えています。<br>この比較はどのように行うべきですか？' data-answer='2' data-explanation='解説<br>正解は「継続評価機能を使用して、モデル間の平均精度を比較します」です。<br>この問題では、AI Platform上でデプロイされた複数の画像分類モデルのパフォーマンスを時間的な視点で監視・比較する方法を選ぶことが求められています。フレーズ"時間の経過とともに"というキーワードは、モデルのパフォーマンスが時間とともに変化していく可能性を考慮に入れるべきであることを示しています。また、選択肢を評価する際には、"どの方法が最も効率的に時間を経てモデルのパフォーマンスを評価できるか"に重きを置く必要があります。<br>基本的な概念や原則：<br>AI Platform：機械学習モデルの開発、トレーニング、デプロイを支援するGoogle Cloudのフルマネージドサービスです。複数のモデルバージョンの管理とパフォーマンス監視も可能です。<br>継続評価：AI Platformで使用可能な機能で、時間の経過とともにモデルのバージョンのパフォーマンスを定期的に監視します。結果はGoogle CloudのMonitoringとLoggingで利用できます。<br>損失パフォーマンス：モデルの予測エラーの尺度です。低いほどモデルのパフォーマンスが良いとされます。ただし、これだけでモデルの全体的なパフォーマンスを評価することはできません。<br>受信者動作特性（ROC）曲線：機械学習モデルのパフォーマンスを測定するためのグラフです。一般的には、True Positive Rate（TPR）とFalse Positive Rate（FPR）の関係を図示します。沿っての面積（AUC）が大きいほどモデルのパフォーマンスが良いとされます。<br>What-Ifツール：機械学習モデルの行動を対話的に探索するためのツールです。データポイントを調整して、その影響を視覚化しますが、全体的なパフォーマンス比較には適していません。<br>正解についての説明：<br>（選択肢）<br>・継続評価機能を使用して、モデル間の平均精度を比較します<br>この選択肢が正解の理由は以下の通りです。<br>まず、AI Platformの継続評価機能を使うと、すでにデプロイされているモデルのバージョンのパフォーマンスを定期的に評価することが可能になります。こちらの機能は新たな評価データを自動的に適用してモデルのパフォーマンスメトリクスを生成し、その統計値をBigQueryに保存します。<br>したがって、この機能を使って保存されたモデルの評価結果をBigQueryから取得すれば、異なるバージョンのモデルのパフォーマンスを比較することができます。<br>更に、モデル間の平均精度を比較するという選択肢はモデルの予測精度を総合的に評価するための手法として有効です。このため、この選択肢は時間経過によるモデルバージョンのパフォーマンスを監視する課題に対する最適な解答です。<br>不正解の選択肢についての説明：<br>選択肢：保持されたデータセット上の各モデルの損失パフォーマンスを比較します<br>この選択肢が正しくない理由は以下の通りです。<br>保持されたデータセット上の損失パフォーマンスを比較する方法は一時的であり、時間経過とともにモデルのパフォーマンスを監視するニーズには沿わなりません。<br>一方、継続的な評価機能はパフォーマンスの長期的な監視を可能にします。<br>選択肢：検証データ上の各モデルの損失パフォーマンスを比較します<br>この選択肢が正しくない理由は以下の通りです。<br>検証データを使ってモデルの損失パフォーマンスを比較すると、一度しか測定できず時間経過によるパフォーマンスの監視ができません。<br>それに対して、継続評価機能は時間経過によるモデルのパフォーマンス変化を監視できるため適切です。<br>選択肢：What-Ifツールを使用して、各モデルの受信者動作特性（ROC）曲線を比較します<br>この選択肢が正しくない理由は以下の通りです。<br>What-Ifツールは個々の予測を視覚的に分析するのに便利ですが、時間の経過と共に複数のモデルバージョンのパフォーマンスを継続的に監視するための機能は提供していません。<br>一方、継続評価機能はモデルバージョン間の平均精度を正確に比較し、経時的なパフォーマンスを監視することを可能にします。'>
<div class='choice'> 保持されたデータセット上の各モデルの損失パフォーマンスを比較します</div>
<div class='choice'> 検証データ上の各モデルの損失パフォーマンスを比較します</div>
<div class='choice'> 継続評価機能を使用して、モデル間の平均精度を比較します</div>
<div class='choice'> What-Ifツールを使用して、各モデルの受信者動作特性（ROC）曲線を比較します</div>
</div>

<div class='question' data-multiple='false' data-question='問題3<br>あなたは1年前にMLモデルを本番環境にデプロイしました。毎月、前月にモデル予測サービスに送られたすべての生のリクエストを収集します。これらのリクエストのサブセットを人間によるラベリングサービスに送り、モデルのパフォーマンスを評価します。1年後、あなたはモデルの性能が1ヶ月後に著しく低下することもあれば、性能の低下に気づくまでに数ヶ月かかることもあることに気づきました。ラベリングサービスには費用がかかりますが、大幅な性能低下は避けなければなりません。コストを最小限に抑えながら高いパフォーマンスを維持するために、モデルを再トレーニングする頻度を決定したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「数日おきに、トレーニングデータセットの特徴量の統計量と、最近の提供データを比較するために、トレーニング-提供スキュー検出バッチジョブを実行します。スキューが検出された場合、最新のサービングデータをラベリングサービスに送ります」です。<br>この問題では、MLモデルのドリフト（モデルの性能が時間とともに低下する現象）に対処するためのコスト効率の良い戦略を模索しています。重要なのは、モデルが時間の経過とともに性能を低下させ、その検出に時間がかかる場合があるということ情と、ラベリングサービスにコストがかかるということ実を理解することです。MLモデルのパフォーマンスに影響を及ぼす可能性のある要素を考慮に入れながら、コストを抑えつつパフォーマンスを維持する戦略を選択することが問題の解決策の中心です。特に、模型のパフォーマンスの流動性と何がその変動を引き起こすか、そしてその最適化にどの程度のコストがかかるか、といった要素を重視することが重要です。<br>基本的な概念や原則：<br>MLモデルの再トレーニング：機械学習モデルの性能を向上させるために行われるプロセスです。新しいデータでモデルを訓練することで、より正確な予測が可能になります。<br>人間によるラベリングサービス：人間がデータにラベルを付けることで、機械学習モデルの訓練データを生成するサービスです。これにより、モデルは特定のタスクを正確に実行することができます。<br>トレーニング-提供スキュー：トレーニングデータと提供データの間の分布の不一致のことです。スキューがあると、モデルの性能が低下する恐れがあります。<br>特徴量の統計：データセットの特徴量に関する統計情報です。これには、平均、中央値、標準偏差などが含まれます。<br>異常検知モデル：データの異常値を検出するモデルです。異常検知モデルは、通常の状態から大きく逸脱したデータポイントを検出します。<br>時間的パターンの特定：モデルの性能変動のパターンを時間経過とともに追跡し、理解することです。これは、将来の性能予測やスケジューリングに役立ちます。<br>ラベリングサービスのコストと性能低下による損失の比較：モデル性能の低下によって生じる損失と、ラベリングサービスにかかるコストを比較し、コスト効率の良い再トレーニングのスケジュールを決定するプロセスです。<br>正解についての説明：<br>（選択肢）<br>・数日おきに、トレーニングデータセットの特徴量の統計量と、最近の提供データを比較するために、トレーニング-提供スキュー検出バッチジョブを実行します。スキューが検出された場合、最新のサービングデータをラベリングサービスに送ります<br>この選択肢が正解の理由は以下の通りです。<br>まず、MLモデルのパフォーマンスが低下する一つの可能性として、モデルがトレーニングされた時点のデータ特徴と、最新の提供データの特徴との間にスキュー（偏り）が生じていることが考えられます。つまり、時間とともにデータの分布が変わるため、モデルのパフォーマンスが変動していると考えられます。<br>そのため、数日おきにトレーニングデータセットの特徴量の統計と、最新の提供データを比較し、その偏りを検出することで、予めモデルのパフォーマンス低下を予知することができます。スキューが検出されたら、その最新のサービングデータを人間のラベリングサービスに送ります。ラベリングを行うことで、パフォーマンスの問題を特定し、必要に応じてモデルの再トレーニングを決定することができます。<br>これにより、モデルの再トレーニングの頻度を適切に制御し、パフォーマンスを維持しつつコストを抑えることができます。ラベリングサービスのコスト問題も解決でき、大幅なパフォーマンス低下も避けられるため、このアプローチが正解です。<br>不正解の選択肢についての説明：<br>選択肢：トレーニングデータセットで異常検知モデルをトレーニングし、すべての 受信リクエストをこのモデルに通します。異常が検出された場合、最新のサービングデータをラベリングサービスに送ります<br>この選択肢が正しくない理由は以下の通りです。<br>異常検知モデルを使用すると、問題のあるリクエストだけを特定できますが、全体的にモデルのパフォーマンスが下がっている原因を特定するための情報は提供できません。<br>一方、トレーニング提供スキュー検出ジョブは、モデルの性能低下の原因が新たなパターンの出現であるときに特に有効です。<br>選択肢：前年度のモデルのパフォーマンスの時間的パターンを特定します。これらのパターンに基づいて、次年度のラベリングサービスへのデータ送信スケジュールを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>前年度のモデルのパフォーマンスの時間的パターンは、新しいトレンドや異常値を捉えることができないため、新たなパフォーマンス低下のリスクを未然に防ぐことができません。<br>一方、正解の選択肢では、実際の提供データとトレーニングデータの間にスキューが生じた時点でラベリングを行い、最新の情報に基づいて再トレーニングを行うため、より適切に性能を維持できます。<br>選択肢：ラベリングサービスのコストと、過去1年間のモデル性能低下による損失収益を比較します。失われた収益がラベリングサービスのコストより大きい場合は、モデルの再トレーニングの頻度を増やし、そうでない場合は、モデルの再トレーニングの頻度を減らします<br>この選択肢が正しくない理由は以下の通りです。<br>過去の収益損失とラベリングサービスのコストを比較する方法は、パフォーマンスの低下を事前に捉えられないため、モデルの精度維持には適していません。パフォーマンスの低下に気づいたときには既に損失が発生してしまっているため、事前の予防策としては不適切です。'>
<div class='choice'> ラベリングサービスのコストと、過去1年間のモデル性能低下による損失収益を比較します。失われた収益がラベリングサービスのコストより大きい場合は、モデルの再トレーニングの頻度を増やし、そうでない場合は、モデルの再トレーニングの頻度を減らします</div>
<div class='choice'> 数日おきに、トレーニングデータセットの特徴量の統計量と、最近の提供データを比較するために、トレーニング-提供スキュー検出バッチジョブを実行します。スキューが検出された場合、最新のサービングデータをラベリングサービスに送ります</div>
<div class='choice'> トレーニングデータセットで異常検知モデルをトレーニングし、すべての 受信リクエストをこのモデルに通します。異常が検出された場合、最新のサービングデータをラベリングサービスに送ります</div>
<div class='choice'> 前年度のモデルのパフォーマンスの時間的パターンを特定します。これらのパターンに基づいて、次年度のラベリングサービスへのデータ送信スケジュールを作成します</div>
</div>

<div class='question' data-multiple='false' data-question='問題4<br>あなたはクレジットカード会社に勤務しており、AutoML Tableを使用して履歴データに基づくカスタム不正検出モデルの作成を依頼されています。偽陽性を最小限に抑えながら、不正取引の検出を優先する必要があります。<br>モデルをトレーニングする際、どの最適化目標を使用すべきですか？' data-answer='1' data-explanation='解説<br>正解は「精度-再現曲線下面積（AUC PR）値を最大化する最適化目標」です。<br>この問題では、正解はどの評価指標を用いてモデル精度を最適化するべきかを選ぶのがポイントです。偽陽性を最小限に抑えつつも、不正取引の検出を優先する必要があるという前提を理解していることが重要です。そのため、選択肢を評価する際には、不均衡なデータに対し、これらの要件を満たす評価指標を選ぶことが求められます。<br>基本的な概念や原則：<br>AutoML Tables：構造化データから予測モデルを自動的に作成するためのGoogle Cloudのサービスです。機械学習に必要な作業の大部分を自動化します。<br>精度-再現曲線下面積（AUC PR）：偽陽性率が低くなるようにモデルを最適化する指標です。不均衡なデータセットに対して効果的です。<br>偽陽性：真の結果が"陰性"なのに"陽性"と判断される誤検出のことです。誤って不正取引と検出されるトランザクションが増えることを示します。<br>不正検出モデル：不正行為を検出するために訓練されたモデルです。多くの場合、不正行為の発生率は低く、データは不均衡です。<br>ログ損失：予測の信頼性を考慮に入れる評価指標です。真の分布と予測分布との距離を測定しますが、不均衡なデータセットでは不適切かもしれません。<br>受信者動作特性曲線下面積（AUC ROC）：偽陽性率と真陽性率の間のトレードオフを示す評価指標です。しかし、不均衡なクラス分布では、性能を過大評価する可能性があります。<br>正解についての説明：<br>（選択肢）<br>・精度-再現曲線下面積（AUC PR）値を最大化する最適化目標<br>この選択肢が正解の理由は以下の通りです。<br>不正取引の検出では、真の陽性（TP）数を増やすために偽陽性（FP）数も増やさざるを得ません。つまり、陽性の取引すべてを特定しようとすると、誤って偽陽性に分類する可能性も増えます。そのため、適合率と再現率のバランスを見つける必要があります。このために精度-再現曲線下面積（AUC PR）が役立ちます。AUC PRは適合率と再現率のバランスを評価し、クラス間のバランスが取れたデータセットではない場合（例えば不正行為は全体の取引のごく一部であるといった状況）に特に有用であるとされています。不正検出では陽性事例（不正行為）が陰性事例（正常な取引）に比べて大幅に少ないため、このケースではAUC PRが最適な選択です。<br>不正解の選択肢についての説明：<br>選択肢：ログ損失を最小化する最適化目標<br>この選択肢が正しくない理由は以下の通りです。<br>ログ損失を最小化する最適化目標はモデルの全体的な精度を向上させますが、偽陽性を最小限に抑えつつ不正取引を優先的に検出するという特定の目的には適していません。<br>それに対して、AUC PRは偽陽性率が低く、真陽性率が高いモデルを評価するための最適化目標であり、このケースに適しています。<br>選択肢：Recall値0.50でPrecisionを最大化する最適化目標<br>この選択肢が正しくない理由は以下の通りです。<br>Recall値0.50でPrecisionを最大化するという目標は特定の閾値に依存するものであり、不正取引の全体的な検出能力を評価できません。<br>一方、AUC PR値の最大化は全体的な性能を考慮します。そのため、一部の不正取引を逃すリスクを低減できます。<br>選択肢：受信者動作特性曲線下面積（AUC ROC）値を最大化する最適化目標<br>この選択肢が正しくない理由は以下の通りです。<br>AUC ROCは偽陽性と真陽性率のトレードオフを表現しますが、不均衡なデータセットには最適ではありません。対してAUC PRは、ポジティブクラスが一般的に珍しい場合に適しており、不正取引の検出などのケースではこちらが適しています。'>
<div class='choice'> ログ損失を最小化する最適化目標</div>
<div class='choice'> 精度-再現曲線下面積（AUC PR）値を最大化する最適化目標</div>
<div class='choice'> Recall値0.50でPrecisionを最大化する最適化目標</div>
<div class='choice'> 受信者動作特性曲線下面積（AUC ROC）値を最大化する最適化目標</div>
</div>

<div class='question' data-multiple='false' data-question='問題5<br>あなたは、5,000万人以上の読者にニュース記事を配信するオンライン出版社に勤めています。あなたは、会社の週刊ニュースレターのコンテンツを推薦するAIモデルを構築しました。ニュースレターの発行日から2日以内に記事が開かれ、ユーザーがページに1分以上とどまった場合、レコメンデーションは成功したとみなされます。<br>成功の指標を計算するために必要なすべての情報はBigQueryで利用可能であり、1時間ごとに更新されます。モデルは8週間分のデータでトレーニングされ、平均すると5週間後にパフォーマンスが許容ベースラインより低下し、トレーニング時間は12時間です。コストを最小限に抑えながら、モデルのパフォーマンスを許容基準値以上にしたいと考えています。<br>再トレーニングが必要な時期を判断するために、モデルをどのように監視すべきですか？' data-answer='3' data-explanation='解説<br>正解は「成功指標を計算するために、BigQueryで毎週クエリをスケジュールします」です。<br>この問題では、大量のユーザーにコンテンツを配信するオンライン出版社で、ニュースレターのコンテンツ推薦に使用するAIモデルのパフォーマンスを監視し、許容範囲内に保つ方法を問います。既にAIモデルは構築され、目標は1時間ごとにBigQueryに更新されること、そして許容範囲を超えたパフォーマンス低下が観察されるまでの期間とモデルの再トレーニング時間が明記されています。コストを最小限に抑えつつ適切なタイミングでモデルを再トレーニングするため、これらの情報を使って効率的な監視方法およびトリガーを決定することが求められています。<br>基本的な概念や原則：<br>BigQuery：Google Cloudのフルマネージドなビッグデータ分析サービスです。大規模なデータセットに対してSQLクエリを実行し、迅速な分析結果を得ることができます。<br>スケジュールクエリ：BigQueryの機能で、定期的に特定のSQLクエリを実行することができます。分析結果の定期的な更新や監視に役立ちます。<br>Vertex AI：Google Cloudの統合AI Platformです。モデルのトレーニングからデプロイ、予測まで一貫してAI開発のライフサイクルを管理することができます。<br>Cloud Tasks：Google Cloudの分散型タスクキューサービスです。非同期タスクの実行やタスクのスケジューリングが可能です。<br>再トレーニング：機械学習モデルが新しいデータに効果的に対応できるように、定期的にモデルを訓練し直すことです。<br>Cloud Composer：Google Cloudの完全マネージドワークフローオーケストレーションサービスです。Apache Airflowをベースにしたサービスで、データパイプラインの構築と管理を容易にします。<br>Dataflow：大規模なデータのバッチ処理とリアルタイム処理を行うGoogle Cloudのサービスです。処理作業を自動的にスケーリングし、遅延なくデータを分析できます。<br>正解についての説明：<br>（選択肢）<br>・成功指標を計算するために、BigQueryで毎週クエリをスケジュールします<br>この選択肢が正解の理由は以下の通りです。<br>まず、再トレーニングの必要性は、モデルのパフォーマンスが基準値を下回ったときに発生します。パフォーマンスは成功指標によって計測され、この指標はBigQueryのデータを用いて計算できます。<br>また、モデルが8週間のデータで訓練され、平均して5週間後にパフォーマンスが低下するとわかっています。これらの情報から、モデルのパフォーマンスを適切に監視するためには、BigQueryで毎週クエリをスケジュールするのが最適です。<br>毎週クエリをスケジュールすることで、定期的にモデルのパフォーマンスを確認し、低下が始まったときに即時に再トレーニングを開始することが可能になります。このようにして、モデルのパフォーマンスを許容基準値以上に維持しつつ、無駄な再トレーニングのコストを抑えることができます。<br>不正解の選択肢についての説明：<br>選択肢：Vertex AI Model Monitoringを使用して、サンプルレート100％、監視頻度2日で入力特徴のスキューを検出します<br>この選択肢が正しくない理由は以下の通りです。<br>問題の要件はモデルのパフォーマンスを確認することであり、Vertex AI Model Monitoringのスキュー検出機能は、入力データの分布が訓練データから乖離しているかを検出するためのもので、モデルのパフォーマンスに直接的な関連がないためです。<br>選択肢：ニュースレターが作成される前に、毎週モデルを再トレーニングするようにCloud Tasksでcronジョブをスケジュールします<br>この選択肢が正しくない理由は以下の通りです。<br>モデルを毎週再トレーニングすると、必要ない場合もあるにも関わらず毎週大量のコストが発生します。この問題ではコストを最小限に抑えることが求められているため、不必要に再トレーニングするのは適切ではありません。<br>また、モデルのパフォーマンス低下が5週間後に起こるだけなので、毎週再トレーニングするのは有効性が低いです。<br>選択肢：Cloud Composerで毎日Dataflowジョブをスケジュールし、成功メトリクスを計算します<br>この選択肢が正しくない理由は以下の通りです。<br>毎日Dataflowジョブをスケジュールすると、無駄なリソースが使われコストが増える可能性があります。モデルのパフォーマンスは5週間後に低下するため、毎週BigQueryで成功指標を計算する方が効率的でコストも最小限に抑えられます。'>
<div class='choice'> ニュースレターが作成される前に、毎週モデルを再トレーニングするようにCloud Tasksでcronジョブをスケジュールします</div>
<div class='choice'> Vertex AI Model Monitoringを使用して、サンプルレート100％、監視頻度2日で入力特徴のスキューを検出します</div>
<div class='choice'> Cloud Composerで毎日Dataflowジョブをスケジュールし、成功メトリクスを計算します</div>
<div class='choice'> 成功指標を計算するために、BigQueryで毎週クエリをスケジュールします</div>
</div>

<div class='question' data-multiple='false' data-question='問題6<br>あなたは、販売数の予測を担当する生産システムを構築し、管理しています。生産モデルは市場の変化に対応する必要があるため、モデルの精度は非常に重要です。しかし、モデルの精度は時間と共に低下しています。<br>モデルの精度が低下している原因として最も考えられる問題は何ですか？' data-answer='3' data-explanation='解説<br>正解は「モデルの再トレーニングプロセスが欠如しています」です。<br>この問題では、時間の経過とともに予測モデルの精度が低下している事象について、問題の原因を探求することが求められています。ここで大事なのは、モデルの性能低下が"時間の経過とともに"と述べられている点です。ここから、モデルが新たに生じたパターンや傾向を捉えられていない可能性に気づくことが重要です。選択肢を見直すときには、時間的な変動を考慮した内容を選びます。<br>基本的な概念や原則：<br>モデルの再トレーニング：機械学習モデルが新しく入力されるデータに対応し、精度を維持もしくは向上させるために行われるプロセスです。適切な再トレーニングが行われないと、時間とともにモデルの予測精度が低下します。<br>データの質：機械学習モデルの訓練と評価に使用されるデータのクオリティです。データの質が低いと、モデルの予測精度も低下します。<br>モデルのレイヤー数：ニューラルネットワークモデルの深さを示す指標です。レイヤー数が少なすぎると、モデルが必要な複雑さを捉えることができない場合があります。<br>データ分割比率：モデル訓練、評価、検証、テストに使用するデータの分割比率です。この比率が最適でないと、モデルの性能評価が正確でない可能性があります。<br>正解についての説明：<br>（選択肢）<br>・モデルの再トレーニングプロセスが欠如しています<br>この選択肢が正解の理由は以下の通りです。<br>まず、機械学習モデルは、訓練データセットに基づいて調整されるため、そのモデルの精度は基本的に訓練データに依存します。<br>しかし、時間とともに変化も起こり、新たなトレンドやパターンが登場します。そのため、過去のトレーニングデータだけに依存しているモデルは時間とともに精度が低下する傾向があります。<br>そこで不可欠となるのが再トレーニングのプロセスです。再トレーニングにより、モデルは新たなパターンを学習し、新たなデータに対する予測精度を向上させることができます。<br>したがって、モデルの精度が時間と共に低下している場合、最も考えられる問題はモデルの再トレーニングプロセスの欠如であると言えます。<br>不正解の選択肢についての説明：<br>選択肢：データの質が劣化しています<br>この選択肢が正しくない理由は以下の通りです。<br>データの質が劣化するという表現自体は一部のシナリオで確かに問題となりますが、ここで述べられているモデルの精度が時間と共に低下している問題については、データの質は大きく影響しづらいです。適切な再トレーニングプロセスが欠如していることが、時間経過による精度低下の主な原因です。<br>選択肢：モデルのレイヤー数が少なすぎます<br>この選択肢が正しくない理由は以下の通りです。<br>モデルのレイヤー数が少なすぎるという設定はモデルの複雑さに関わりますが、モデルの精度が時間と共に低下する原因と直接は関連付けにくいです。<br>一方で、正解の"モデルの再トレーニングプロセスが欠如している"とは、市場の変化に対応し新しいデータに適合するために定期的にモデルを更新することを指し、時間経過とともに精度が下がる問題と直接関係しています。<br>選択肢：モデルのトレーニング、評価、検証、テストにおけるデータ分割比率が最適化されていません<br>この選択肢が正しくない理由は以下の通りです。<br>データ分割比率の最適化は、モデル訓練の初期段階で重要ですが、時間と共にモデルの精度が低下する問題には直接関連しません。精度の低下は、新しいデータに対応できない既存のモデルを示しており、再トレーニングの欠如が直接的な原因である可能性が高いです。'>
<div class='choice'> データの質が劣化しています</div>
<div class='choice'> モデルのトレーニング、評価、検証、テストにおけるデータ分割比率が最適化されていません</div>
<div class='choice'> モデルのレイヤー数が少なすぎます</div>
<div class='choice'> モデルの再トレーニングプロセスが欠如しています</div>
</div>

<div class='question' data-multiple='false' data-question='問題7<br>あなたは、テーブルデータで学習された大規模で複雑なTensorFlowモデルを本番環境にうまくデプロイしました。あなたは、cloudjp-projectというプロジェクトのsubscription.subscriptionPurchaseというBigQueryテーブルに格納されている各サブスクリプションの顧客生涯価値（LTV）フィールドを予測したいと考えています。<br>あなたは、BigQueryテーブルからのデータの前処理からVertex AIエンドポイントへの検証済みモデルのデプロイまで、すべてのトレーニングコードをTensorFlow Extended（TFX）パイプラインに編成しました。予測ドリフト、つまり本番環境での特徴データ分布が時間の経過とともに大きく変化する状況を防ぎたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「受信予測の10%を24時間サンプリングするモデル監視ジョブを追加します」です。<br>この問題では、BigQueryテーブルのデータを使用して顧客生涯価値を予測するTensorFlowモデルを管理している状況が提示されています。特定の重要な要件は予測ドリフト、つまり特徴データ分布が時間の経過とともに大きく変化することを防ぐことです。問題は、この要件をどのように満たすかという点に集中しています。モデルの監視の頻度や範囲、再訓練の頻度などが重要な要素です。これらの要素を適切にバランスさせ、選択肢を比較することが求められています。<br>基本的な概念や原則：<br>TensorFlow：オープンソースの機械学習ライブラリで、Googleが開発しました。ディープラーニングモデルの訓練と実行をサポートします。<br>BigQuery：Google Cloudのフルマネージドで高性能のデータウェアハウスサービスです。大量のデータに対するSQLクエリの実行を高速に処理します。<br>モデル監視：機械学習モデルの性能を監視し、時間の経過とともに予測精度が低下したり、入力データのパターンが変わった場合にそれを追跡するプロセスです。<br>TensorFlow Extended（TFX）：TensorFlowのエンドツーエンドプラットフォームで、本番環境でのモデルのデプロイから機械学習モデルのライフサイクル全体をサポートします。<br>Vertex AI：Google Cloudの統合AI Platformで、MLモデルのトレーニングからデプロイまでを一元管理できます。<br>サンプリング：大量のデータセットからランダムにデータを選択し、そのデータを基に分析や推測を行うプロセスです。<br>予測ドリフト：機械学習モデルが時間の経過とともに特徴データ分布の変化に対応できず、予測性能が低下する現象です。<br>正解についての説明：<br>（選択肢）<br>・受信予測の10%を24時間サンプリングするモデル監視ジョブを追加します<br>この選択肢が正解の理由は以下の通りです。<br>まず、予測ドリフトとは、モデルが学習したパターンから実際のデータのパターンが離れてしまう現象を指します。これを検知し、適切に対応するためには、モデルが生成する予測と実際のデータを定期的に比較することが重要になります。<br>このような監視作業を反復的かつ体系的に行う方法の一つが、モデル監視ジョブを設定することです。膨大な量の予測データから一定の割合（この場合は10%）をサンプリングし、その予測結果が実際のデータとどれだけ合致しているかを監視します。<br>また、この監視は24時間ごとに行われるため、本番環境での特徴データ分布が時間の経過とともに大きく変化する可能性も考慮しています。つまり、定期的にモデルの予測精度をチェックし、予測ドリフトを早期に検知し、対応することができます。これにより、モデルの性能の低下を防ぎ、信頼性の高いプロジェクトの運用を実現します。<br>不正解の選択肢についての説明：<br>選択肢：Vertex AI Pipelinesを使用して、モデルの継続的な再トレーニングを毎日実施します<br>この選択肢が正しくない理由は以下の通りです。<br>毎日のモデルの再トレーニングは、モデルが新しいデータに適用するのに役立つかもしれませんが、予測ドリフトの状況を直接防ぐものではありません。<br>一方、モデル監視ジョブはモデルの性能を継続的に監視し、予測ドリフトを特定して通知するための具体的な手段を提供します。<br>選択肢：受信予測の90%を24時間サンプリングするモデル監視ジョブを追加します<br>この選択肢が正しくない理由は以下の通りです。<br>受信予測の90%をサンプリングするとリソースの浪費となり、コストが高くなります。<br>また、ドリフト検出には10%のサンプリングでも充分であり、大規模なモデルでも結果を適切に予測することができます。<br>したがって、効率とコストの観点から、この選択肢は適切ではありません。<br>選択肢：1時間ごとに入力予測の10%をサンプリングするモデル監視ジョブを追加します<br>この選択肢が正しくない理由は以下の通りです。<br>1時間ごとに10%の予測をサンプリングすると、1日あたりのデータ量が240%となるため量が大きすぎます。<br>一方、正解の24時間に10%をサンプリングすると、1日あたりのデータ量は10%となり、管理が容易です。<br>また、予測ドリフトを確認するのは長期的な視点が必要で、1時間ごとは短すぎます。'>
<div class='choice'> 1時間ごとに入力予測の10%をサンプリングするモデル監視ジョブを追加します</div>
<div class='choice'> Vertex AI Pipelinesを使用して、モデルの継続的な再トレーニングを毎日実施します</div>
<div class='choice'> 受信予測の10%を24時間サンプリングするモデル監視ジョブを追加します</div>
<div class='choice'> 受信予測の90%を24時間サンプリングするモデル監視ジョブを追加します</div>
</div>

<div class='question' data-multiple='false' data-question='問題8<br>あなたの会社は、ユーザーが動画を見たりアップロードしたりできる動画共有サイトを運営しています。あなたは、新しくアップロードされた動画のうち、どの動画が最も人気があるかを予測するMLモデルを作成する必要があります。<br>モデルが成功したかどうかを判断するために、どの指標を使うべきですか？' data-answer='0' data-explanation='解説<br>正解は「このモデルは、アップロードされてから30日以内に、視聴時間によって測定される最も人気のある動画の95％を予測します」です。<br>この問題では、MLモデルの評価指標選択について考えます。特に、MLモデルが"最も人気のある動画"を予測しようとしていることに注目します。評価指標は、MLモデルがどの程度うまく機能しているかを判断するための基準なので、"人気"を定義し、それをいかに正確に予測できるかが重要になります。選択肢を評価する際には、どの指標がモデルのタスクを最も適切に反映しているかを判断することが必要です。<br>基本的な概念や原則：<br>指標：モデルのパフォーマンスや成果を評価するために用いられる具体的な基準や値です。<br>視聴時間：動画がどれくらい視聴されているかを測る指標です。一般的には、視聴時間が長ければ長いほどその動画は人気があるとされます。<br>予測：モデルが未知のデータや未来の結果について行う推測です。モデルの精度は、予測がどれだけ実際の結果と一致しているかで評価されます。<br>クリック数：ウェブページや広告、動画などがどれだけクリックされたかをカウントする指標です。しかし、クリックされただけで実際には視聴されていない可能性もあるため、動画の人気を評価するだけの指標としては不十分な場合があります。<br>ピアソン相関係数：2つの変数間の線形相関関係の強さと方向を測定する指標です。しかし、非線形の関係性や個々の観測値の詳細を評価するのには適していません。<br>正解についての説明：<br>（選択肢）<br>・このモデルは、アップロードされてから30日以内に、視聴時間によって測定される最も人気のある動画の95％を予測します<br>この選択肢が正解の理由は以下の通りです。<br>まず、MLモデルの成功を評価するためには、モデルの予測結果が実際の結果とどれだけ一致しているかを見る指標が必要です。<br>このシナリオでは、最も人気のある動画を予測するために、視聴時間という具体的な指標を用いています。<br>さらに、時間範囲（この場合、アップロードから30日以内）を指定することで、モデルの予測力を時系列的に評価することが可能になります。<br>また、"95％を予測する"というターゲットは、モデルの成功を明確に測定するための具体的な基準を設けています。一般的に、MLモデルの評価では多くの場合、予測の正確さをパーセンテージで表すことが一般的です。<br>このように、指標はモデルの目標を明確にし、その達成度を測定するための基準を提供しています。<br>したがって、この指標はMLモデルの成功を判断するのに適しています。<br>不正解の選択肢についての説明：<br>選択肢：このモデルは、動画をアップロードしたユーザーが10,000以上の"いいね"を獲得していれば、その動画は人気があると予測します<br>この選択肢が正しくない理由は以下の通りです。<br>動画が人気があるかどうかを単に"いいね"の数で決定するのではなく、視聴時間などの様々な要素を複合的に考える必要があります。<br>また、"いいね"の数だけでなく、視聴時間やコメント、シェア数など、動画の人気度を反映する他の指標も必要です。<br>選択肢：このモデルは、クリック数で測定した最も人気のあるクリックベイト動画の97.5％を予測しています<br>この選択肢が正しくない理由は以下の通りです。<br>クリック数で人気のクリックベイト動画を予測するという目標は、本質的に動画の人気を測るには不適切です。ある動画がクリックされた数だけがその人気を反映しているとは限りません。<br>一方、視聴時間による予測は、ユーザーが実際にその動画をどれだけ見ているかという行動を考慮しているため、より有効な指標です。<br>選択肢：公開後7日後と30日後の対数変換されたビュー数の間のピアソン相関係数が0に等しくなることを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>ピアソン相関係数が0に等しいとは、ビュー数の増減と時間の関連性が全く無い、つまり予測的な有効性が無いということを示します。<br>一方、正解の選択肢は具体的な成功基準を明確に設定し、モデルの効果を定量的に評価するためには適切です。'>
<div class='choice'> このモデルは、アップロードされてから30日以内に、視聴時間によって測定される最も人気のある動画の95％を予測します</div>
<div class='choice'> このモデルは、動画をアップロードしたユーザーが10,000以上の"いいね"を獲得していれば、その動画は人気があると予測します</div>
<div class='choice'> このモデルは、クリック数で測定した最も人気のあるクリックベイト動画の97.5％を予測しています</div>
<div class='choice'> 公開後7日後と30日後の対数変換されたビュー数の間のピアソン相関係数が0に等しくなることを確認します</div>
</div>

<div class='question' data-multiple='false' data-question='問題9<br>あなたは、世界各地のデータセンターに設置された大規模なオンプレミスサーバーを管理する国際企業の運用チームに所属しています。あなたのチームは、CPU/メモリ消費量などの監視データをサーバーから収集しています。サーバーでインシデントが発生すると、あなたのチームはそれを修正する責任を負います。インシデントデータはまだ適切にラベル付けされていません。管理チームは、VMからの監視データを使用して潜在的な障害を検出し、サービスデスクチームに警告する、予測保守ソリューションを構築することを望んでいます。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「単純なヒューリスティック（例えばZスコアに基づく）を実装し、マシンの過去のパフォーマンスデータにラベルを付けます。このラベル付けされたデータセットに基づいて、異常を予測するモデルをトレーニングします」です。<br>この問題では、監視データを使用して潜在的な障害を自動で検出し警告する予測保守ソリューションを構築する方法が求められています。具体的には、ラベルがまだ付けられていないインシデントデータをどのように扱い、それを元にどのようにモデルを設定するべきかです。この要件を満たすためには、データのラベル付け方法とそのデータを用いた異常検出モデルの設計がポイントとなります。各選択肢ではデータの扱い方やラベルの付け方、モデルの形成方法が異なっており、それらを適切に理解して問題の要求に最も適している方法を選ぶ事が求められています。<br>基本的な概念や原則：<br>予測保守：機械学習やデータ分析を用いて、機器の故障やシステムの問題を事前に予測して対処する手法です。効率的な運用とコスト削減を実現します。<br>ヒューリスティック：問題解決のための経験ベースの方法論です。完全な解を保証しないものの、合理的な時間内に十分な解を見つけるのに役立ちます。たとえば、Zスコアを用いた外れ値検知などがそれに該当します。<br>ラベル付け：教師あり学習のための、データに対する"答え"のマーキングプロセスです。これにより、モデルは特定のパターンを学習することができます。<br>異常検知モデル：データ内の異常パターンまたは外れ値を特定するモデルです。異常パターンは、問題の兆候やシステムの故障を示していることがあります。<br>時系列モデル：時間の経過に伴うデータパターンを予測するモデルです。範囲外の予測を通じて、問題の早期発見が可能です。<br>Zスコア：データが平均からどれだけ離れているかを示す統計的尺度です。これを利用したヒューリスティックは、データの異常を検出するのに有用です。<br>手動ラベル付け：人間がデータにラベルを付ける行為です。高精度のラベルが可能ですが、大量のデータに対しては手間と時間がかかります。<br>正解についての説明：<br>（選択肢）<br>・単純なヒューリスティック（例えばZスコアに基づく）を実装し、マシンの過去のパフォーマンスデータにラベルを付けます。このラベル付けされたデータセットに基づいて、異常を予測するモデルをトレーニングします<br>この選択肢が正解の理由は以下の通りです。<br>まず、提案されている解決策は、ヒューリスティック（経験に基づくルールやパラメータの推測方法）を使用してデータセットにラベルを付け、それに基づいて異常検出モデルをトレーニングすることを提案しています。これは、問題で述べられた"インシデントデータがまだ適切にラベル付けされていない"という状況に対処するための適切な方法です。そのため、ヒューリスティックを使用して初期のラベル付けを行い、そのデータを用いて異常検出モデルをトレーニングすることで、潜在的な問題を早期に検出し、応答時間を短縮することができます。<br>また、Zスコアは、データポイントが平均からどれだけ離れているかを測定することで、異常な値を特定するのに役立つ統計的手法です。これにより、異常値を検出し、それに対応するラベルを付けることが可能になります。<br>不正解の選択肢についての説明：<br>選択肢：時系列モデルをトレーニングして、マシンのパフォーマンス値を予測します。マシンの実際のパフォーマンス値が予測されたパフォーマンス値と大きく異なる場合、アラートを設定します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、時系列モデルをトレーニングするだけでは、異常検出や予測保守の問題に対しては十分ではありません。これは、単にパフォーマンス値を予測してアラートを出すだけでは、具体的な予測ラベルが無いためにクラス分類問題を解くことができません。その点、正解の選択肢では過去のパフォーマンスデータに基づいてラベルをつけることで潜在的な異常を予測できます。<br>選択肢：マシンの過去のパフォーマンスデータにラベル付けするための、単純なヒューリスティック（例：Zスコアに基づく）を開発します。このヒューリスティックを本番環境でテストします<br>この選択肢が正しくない理由は以下の通りです。<br>単純なヒューリスティックを直接本番環境でテストするだけでは予測保守ソリューションを実現できません。それだけでは潜在的な障害を予測し、サービスデスクチームに警告するためのモデルをトレーニングすることはできません。<br>選択肢：優秀なアナリストのチームを雇い、マシンの過去のパフォーマンスデータをレビューし、ラベル付けします。この手動でラベル付けされたデータセットに基づいてモデルをトレーニングします<br>この選択肢が正しくない理由は以下の通りです。<br>優秀なアナリストのチームを雇うという方法は、非常に時間と労力を要し、その結果としてコストが高くなります。<br>一方、単純なヒューリスティックを実装することで、手間や時間を大幅に削減し、また膨大な量のデータに対するラベル付けも自動的に行うことができます。'>
<div class='choice'> マシンの過去のパフォーマンスデータにラベル付けするための、単純なヒューリスティック（例：Zスコアに基づく）を開発します。このヒューリスティックを本番環境でテストします</div>
<div class='choice'> 時系列モデルをトレーニングして、マシンのパフォーマンス値を予測します。マシンの実際のパフォーマンス値が予測されたパフォーマンス値と大きく異なる場合、アラートを設定します</div>
<div class='choice'> 単純なヒューリスティック（例えばZスコアに基づく）を実装し、マシンの過去のパフォーマンスデータにラベルを付けます。このラベル付けされたデータセットに基づいて、異常を予測するモデルをトレーニングします</div>
<div class='choice'> 優秀なアナリストのチームを雇い、マシンの過去のパフォーマンスデータをレビューし、ラベル付けします。この手動でラベル付けされたデータセットに基づいてモデルをトレーニングします</div>
</div>

<div class='question' data-multiple='false' data-question='問題10<br>あなたのチームは、DNN回帰モデルをトレーニングし、テストして、良い結果を得ました。導入から6ヵ月後、入力データの分布が変化したため、モデルのパフォーマンスが低下しました。<br>本番環境で入力の違いにどのように対処すべきですか？' data-answer='3' data-explanation='解説<br>正解は「アラートを作成してスキューを監視し、モデルを再トレーニングします」です。<br>この問題では、あなたのチームが訓練したディープニューラルネットワーク（DNN）回帰モデルのパフォーマンスが下がった原因と対策について問われています。配布が変わったとの情報から、入力データが時間とともに変化し、そのためにモデルが当初のパフォーマンスを発揮できなくなったことが問題だと理解してください。これが重要なのは、選択肢を評価する際に、ただモデルの再訓練だけでなく、入力データの分布が変化した際の対処法に焦点を当てる必要があるからです。<br>基本的な概念や原則：<br>データスキュー：トレーニングデータと予測時のデータとの間で発生する一貫性のなさです。データの分布、範囲、全体的な特性が異なる場合に発生します。<br>モデルの再トレーニング：モデルのパフォーマンスが低下したときや、入力データが時間とともに変化したときに行われるプロセスです。再トレーニングにより、モデルは新しいデータパターンを学習し、パフォーマンスを改善します。<br>アラート作成：システムに問題が発生したときや重要な状況が発生したときに通知を受け取ることができる機能です。データスキューなどの問題を素早く認識し、対応するために使用できます。<br>DNN回帰モデル：ディープニューラルネットワーク（DNN）を使用した回帰分析モデルです。連続的な目的変数を予測するために使用されます。<br>特徴選択：モデルの精度を向上させるために使用される手法の一つです。不要な特徴を削除することで、モデルの予測性能を改善します。<br>ハイパーパラメータチューニング：モデルの学習プロセスを制御するパラメータの最適値を見つけるためのプロセスです。これにより、モデルのパフォーマンスが向上します。<br>正解についての説明：<br>（選択肢）<br>・アラートを作成してスキューを監視し、モデルを再トレーニングします<br>この選択肢が正解の理由は以下の通りです。<br>ディープニューラルネットワーク（DNN）モデルは、訓練データに基づいてモデルを生成します。<br>ただし、実際の問題空間やデータ分布は変動する可能性があり、訓練データと現実のデータ分布が異なると、モデルのパフォーマンスが低下する恐れがあります。これを"スキュー"と言います。<br>アラートを作成してスキューを監視し、モデルを再トレーニングするという選択肢は、このスキューの問題に対応するためのものです。監視を通じて異常を早期に検知し、適切なタイミングでモデルの再トレーニングを行うことで、モデルの精度を維持することができます。<br>このような手法は、機械学習モデルのライフサイクル管理において重要です。モデルのパフォーマンスが維持できるか否かは、モデルの価値を決定づける要素の一つです。<br>したがって、アラートの設定、スキューの監視、そして必要に応じてのモデルの再トレーニングは、機械学習モデルを本番環境で運用する際に不可欠なプラクティスとなります。<br>不正解の選択肢についての説明：<br>選択肢：モデルに対して特徴選択を行い、より少ない特徴でモデルを再トレーニングします<br>この選択肢が正しくない理由は以下の通りです。<br>特徴選択を行って特徴量を減らしても、入力データの分布の変化によるモデルのパフォーマンスの低下は解決しません。正解の選択肢は入力データの分布の変化（スキュー）を監視し、それに対応してモデルを再トレーニングするという適切な対応を示しています。<br>選択肢：モデルを再学習し、ハイパーパラメータチューニングサービスでL2正則化パラメータを選択します<br>この選択肢が正しくない理由は以下の通りです。<br>モデルを再トレーニングしてL2正則化パラメータを選択することは、過学習を防ぐための手法ですが、入力データの分布の変化に対応する手段ではありません。<br>それに対して、アラートを作成してスキューを監視し、モデルを再トレーニングする方が、入力データの変化を、適切に対処しパフォーマンス低下を改善できます。<br>選択肢：モデルに対して特徴選択を行い、より少ない特徴で毎月モデルを再トレーニングします<br>この選択肢が正しくない理由は以下の通りです。<br>特徴選択を行い、より少ない特徴でモデルを再トレーニングするというのは、入力データの分布が変化してパフォーマンスが低下した場合の対処としては不適切です。問題は、入力データ自体の変化であり、そのデータがモデルパフォーマンスに与える影響を把握し、必要に応じて再トレーニングすべきです。このようなエラーを検知するためには、アラートを作成してスキューを監視すべきです。'>
<div class='choice'> モデルに対して特徴選択を行い、より少ない特徴で毎月モデルを再トレーニングします</div>
<div class='choice'> モデルを再学習し、ハイパーパラメータチューニングサービスでL2正則化パラメータを選択します</div>
<div class='choice'> モデルに対して特徴選択を行い、より少ない特徴でモデルを再トレーニングします</div>
<div class='choice'> アラートを作成してスキューを監視し、モデルを再トレーニングします</div>
</div>

<div class='question' data-multiple='false' data-question='問題11<br>あなたは、ユーザーが記事を投稿し、ニュースについて議論する大規模なソーシャルネットワークサービスプロバイダーで働いています。毎日何百万ものコメントがオンラインに投稿され、200人以上の人間のモデレーターが常にコメントをチェックし、不適切なものにフラグを立てています。あなたのチームは、人間のモデレータがプラットフォーム上のコンテンツをチェックするのを支援するMLモデルを構築しています。このモデルは各コメントを採点し、疑わしいコメントにフラグを立て、人間がレビューするようにします。<br>モデルのパフォーマンスを監視するために、どの指標を使うべきですか？' data-answer='2' data-explanation='解説<br>正解は「毎分、不適切な可能性があるとしてモデルによってフラグが立てられたメッセージのサンプルに基づく精度とリコールの推定値」です。<br>この問題では、大規模なソーシャルネットワークサービスプロバイダーで、不適切なユーザーコメントを自動的に検知する機械学習モデルのパフォーマンスをどの指標で監視すべきかということが求められています。より具体的には、モデルが不適切なコメントにどれ程効果的にフラグを立てられるかという観点です。このため、モデルがどの程度正確に不適切なコメントを検知できるか（精度）と、不適切なコメントを見逃さないか（リコール）を評価する指標が適していると考えられます。ただし、全てのコメントを検証するのは非現実的なため、一部のサンプルを用いて推定を行うべきです。<br>基本的な概念や原則：<br>機械学習（ML）モデル：AIの一部であり、データから学習し、予測や決定を行う能力があります。学習データとアルゴリズムに基づいて、新たな入力データに対して的確な予測を行います。<br>精度：分類モデルの評価指標で、正しく分類できたインスタンスの割合を示します。しかし、偏ったデータセットの場合、精度は誤解を招く可能性があります。<br>リコール率：分類モデルの評価指標で、正しく分類できたポジティブなケースの割合を表します。偽陰性の数（実際はポジティブだが、ネガティブと予測されたケース）を最小限に抑えることが目的です。<br>モデルのパフォーマンス監視：MLモデルのパフォーマンスを適切に評価し、必要に応じて改善するためのプロセスです。精度やリコールなどの指標を使用し、モデルの推測結果を定期的に検証します。<br>コンテンツモデレーション：ユーザが投稿するコンテンツを管理し、適切なものだけが公開されるようにするプロセスです。AIや人間のレビューを組み合わせて行われます。<br>サンプリング：大量のデータセットから代表的なデータをランダムに選び出す手法です。全体の傾向を把握するのに有用です。<br>フラグ付け：不適切なコンテンツを識別し、注意を引くために使用されるプロセスです。AIや人間のモデレータがフラグを立てることで、他のユーザが不適切なコンテンツを避けるのに役立ちます。<br>正解についての説明：<br>（選択肢）<br>・毎分、不適切な可能性があるとしてモデルによってフラグが立てられたメッセージのサンプルに基づく精度とリコールの推定値<br>この選択肢が正解の理由は以下の通りです。<br>精度とリコールの指標を使用することは、不適切なコメントの検出における機械学習モデルの効果を評価するのに適しています。精度はモデルがフラグを立てたコメントが実際に不適切であった割合を表し、高い精度は偽陽性（不適切ではないのにフラグが立つ）の発生率が低いことを示します。<br>一方、リコールは実際に不適切なコメントの中でモデルが正しくフラグを立てた割合を表し、高いリコールは偽陰性（不適切なのにフラグが立たない）の発生率が低いことを示します。これらの値を毎分更新して監視することで、モデルのパフォーマンスが時系列的にどのように変化しているかをリアルタイムで確認することができます。<br>また、精度とリコールを"不適切な可能性があるとしてモデルによってフラグが立てられたメッセージのサンプル"に基づいて計算することで、最終的に人間のモデレータが確認するべきコメントの質を評価することが可能になります。これは、モデレータの作業効率化という本プロジェクトの目的に直結する指標です。このため、この指標は適切であるといえます。<br>不正解の選択肢についての説明：<br>選択肢：1分間にモデルによってフラグが立てられたメッセージの数<br>この選択肢が正しくない理由は以下の通りです。<br>モデルによってフラグが立てられたメッセージの数だけを監視しても、モデルが不適切なコメントを適切に検証できているかの評価にはなりません。精度とリコールの推定値により、適切なコメントと不適切なコメントの区別の能力をキャプチャできます。<br>選択肢：人間によって不適切であると確認された、1分間にモデルによってフラグが立てられたメッセージの数<br>この選択肢が正しくない理由は以下の通りです。<br>フラグが立てられたメッセージの数だけを計測すると、モデルがどれだけの不適切なメッセージを見逃しているか、またはどれぐらいの誤報があるかを理解することができません。<br>一方、精度とリコールはこれらの情報を提供します。<br>選択肢：毎分0.1%の生メッセージの無作為サンプルに基づく精度とリコール率の見積もり<br>この選択肢が正しくない理由は以下の通りです。<br>コメント全体の0.1％の無作為サンプルでは、モデルのパフォーマンスを適切に評価するためには、不適切な可能性があるコメントが不足している可能性があります。そのため、モデルが指摘した疑わしいコメントを基に評価する方が必要な精度とリコールの見積もりが得られます。'>
<div class='choice'> 1分間にモデルによってフラグが立てられたメッセージの数</div>
<div class='choice'> 毎分0.1%の生メッセージの無作為サンプルに基づく精度とリコール率の見積もり</div>
<div class='choice'> 毎分、不適切な可能性があるとしてモデルによってフラグが立てられたメッセージのサンプルに基づく精度とリコールの推定値</div>
<div class='choice'> 人間によって不適切であると確認された、1分間にモデルによってフラグが立てられたメッセージの数</div>
</div>

<div class='question' data-multiple='false' data-question='問題12<br>あなたは、リアルタイムのセンサーデータの異常を検出するMLモデルを構築しています。Pub/Subを使って受信リクエストを処理します。分析・可視化のために結果を保存したいと考えています。<br>パイプラインはどのように構成すべきですか？' data-answer='3' data-explanation='解説<br>正解は「1 = Dataflow、2 = AI Platform、3 = BigQuery」です。<br>この問題では、リアルタイムのセンサーデータの異常検出を行うMLモデルの作成とその結果の保存方法について考えます。Pub/Subでの受信リクエスト処理から始まり、最終的に結果を保存するまでのパイプラインの構築を考える必要があります。その際、各種アプリケーションと技術の特性やロールを理解し、それらがどのように連携して目的を達成するかを考察することが大切です。正解の選択肢は、それらの要素がどのように効果的なパイプラインを形成するかを強調します。<br>基本的な概念や原則：<br>Dataflow：リアルタイムとバッチの両方のデータ処理パイプラインを作成、デプロイ、管理するためのGoogle Cloudのフルマネージドサービスです。ストリーミングデータを処理するためのエンジンとして重要です。<br>AI Platform：機械学習モデルの訓練、デプロイ、予測を一元化できるフルマネージドサービスです。<br>BigQuery：Google Cloudの高速なフルマネージドエンタープライズデータウェアハウスです。大量のデータの分析や可視化に便利です。<br>Pub/Sub：大量のメッセージをリアルタイムに発行および消費することができるフルマネージドリアルタイムメッセージングサービスです。エンドツーエンドのデータ下流の一部として重要です。<br>Cloud Bigtable：Google CloudのNoSQL Big Dataデータベースサービスです。リアルタイム分析と大量の時系列データの処理に適していますが、今回の選択肢には最適ではないとされています。<br>DataProc：分散データ処理を目的としたフルマネージドHadoopとSpark環境サービスです。このケースには不適切とされています。<br>AutoML：自動機械学習モデルの訓練、評価、改良を可能にするGoogle Cloudのサービスですが、このケースには不適切とされています。<br>正解についての説明：<br>（選択肢）<br>・1 = Dataflow、2 = AI Platform、3 = BigQuery<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud Dataflowは、ストリーム型とバッチ型の両方のデータを処理するための完全マネージドのサービスです。リアルタイムのセンサーデータのような高速で大量のデータをリアルタイムで処理する能力を持つため、Pub/Subからのデータストリームを適切に管理するのに適しています。<br>次に、AI Platformは機械学習モデルのトレーニング、チューニング、デプロイ、そして予測を行うためのクラウドベースのプラットフォームです。Dataflowによって前処理されたデータを使って異常検出モデルを適用し、リアルタイムの予測を出力する作業に適しています。<br>最後に、BigQueryは、巨大なデータセットに対するSQLクエリを高速に実行することができるフルマネージド型のビッグデータ分析ツールです。AI Platformからの出力データをストアして分析や可視化を行うのに最適なツールと言えます。<br>このように、各ツールが対応する適切な役割を果たしているので、この選択肢がモデルを効率的に構築し、リアルタイムの予測を維持して分析を容易にするための適切な回答です。<br>不正解の選択肢についての説明：<br>選択肢：1 = DataProc、2 = AutoML、3 = Cloud Bigtable<br>この選択肢が正しくない理由は以下の通りです。<br>まず、DataProcはバッチ処理向けのサービスなので、リアルタイムのデータ処理には不適切です。<br>一方、Dataflowはストリーミングとバッチの両方のデータ処理に対応しています。<br>また、AutoMLも使えますが、特に言及されていないためAI Platformのほうが適しています。<br>最後に、Cloud Bigtableは高い書き込みスループットを提供しますが、分析・可視化の観点からはBigQueryの方が適しています。<br>選択肢：1 = BigQuery、2 = AutoML、3 = Cloud Functions<br>この選択肢が正しくない理由は以下の通りです。<br>まず、BigQueryはストリーム収集データをクエリすることに適していますが、リアルタイムでのデータ処理には不向きです。<br>しかし、Dataflowはリアルタイムのデータ処理に適しています。<br>次に、AutoMLはMLモデルを構築するためのツールですが、AI Platformがリアルタイムの予測に適しています。<br>最後に、Cloud Functionsではなく、BigQueryが結果を保存するために適したサービスです。<br>選択肢：1 = BigQuery、2 = AI Platform、3 = Cloud Storage<br>この選択肢が正しくない理由は以下の通りです。<br>まず、BigQueryはリアルタイムデータの処理サービスではなく、大量データをインタラクティブに分析するデータウェアハウスサービスです。<br>一方、Dataflowはリアルタイムデータのストリーム処理とバッチ処理をサポートするため、正解の選択肢に適しています。<br>また、結果を保存するためにはBigQueryが適しており、Cloud Storageは一般的なファイル保存に利用されます。'>
<div class='choice'> 1 = DataProc、2 = AutoML、3 = Cloud Bigtable</div>
<div class='choice'> 1 = BigQuery、2 = AI Platform、3 = Cloud Storage</div>
<div class='choice'> 1 = BigQuery、2 = AutoML、3 = Cloud Functions</div>
<div class='choice'> 1 = Dataflow、2 = AI Platform、3 = BigQuery</div>
</div>


            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>