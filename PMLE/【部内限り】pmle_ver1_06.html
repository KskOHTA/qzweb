<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Professional Machine Learning Engneer問題集 01</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">


<div class='question' data-multiple='false' data-question='問題18<br>あなたは世界的な靴の小売企業に勤めており、過去の在庫データに基づいて商品がいつ品切れになるかを予測する必要があります。靴の需要はさまざまな要因に影響されるため、顧客の行動は非常に動的です。利用可能なすべてのデータでトレーニングされたモデルを提供したいですが、本番稼動する前に特定のサブセットのデータでパフォーマンスを追跡したいと考えています。<br>この検証を行うための最も合理的で信頼性の高い方法は何ですか？' data-answer='3' data-explanation='解説<br>正解は「TFX ModelValidatorツールを使用して、本番環境準備のためのパフォーマンス指標を指定します」です。<br>この問題では、靴の小売業における在庫予測のためのモデルを設計している状況にあなたが立たされています。全データを使用してモデルを訓練したいと同時に、特定のデータサブセットでのパフォーマンスを確認したいという要件があります。問題の読み解き方としては、適切なモデルの検証方法を選ぶことを考えながら、全体と特定のサブセットの両方で高品質の予測を行うためにはどのような手段が適用できるかを把握することが重要です。<br>基本的な概念や原則：<br>TFX ModelValidator：TensorFlow Extended（TFX）の一部で、機械学習モデルのパフォーマンスを評価し、受け入れられる基準を満たすかどうかを判断するためのツールです。<br>k分割交差検証：機械学習のモデルが新たなデータに対してどれほど適用できるかを評価するための手法の一つです。データセットをk個のサブセットに分割し、モデルの学習と評価を繰り返します。<br>受信者動作特性曲線下面積（AUC ROC）：機械学習モデルの性能を評価するための指標の一つです。偽陽性率に対する真陽性率をプロットしたROCカーブ下の面積を示します。<br>在庫管理の予測モデリング：在庫データから商品の品切れを予測するために使用される機械学習アプローチです。需要が非常に動的である場合でも、統計的手法を用いることで効果的な予測を行うことができます。<br>正解についての説明：<br>（選択肢）<br>・TFX ModelValidatorツールを使用して、本番環境準備のためのパフォーマンス指標を指定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、TFX ModelValidatorはTensorFlow Extended（TFX）の一部であり、新たにトレーニングされたモデルのパフォーマンスを以前のモデルや特定のパフォーマンス指標と比較できます。<br>さらに、特定のサブセットのデータでパフォーマンスを追跡することも可能です。これにより、新たなモデルが期待したパフォーマンスを示しているかどうか、また、全体的なパフォーマンスが改善されているかどうかを確認することができます。<br>また、特定のサブセットのデータでパフォーマンスが期待通りでない場合、その早期発見も可能です。これらの性質は、問題文で要求されている"本番稼動前に特定のサブセットのデータでパフォーマンスを追跡したい"という要件を満たすため、TFX ModelValidatorを使用することが最も合理的で信頼性の高い方法と言えます。<br>不正解の選択肢についての説明：<br>選択肢：k分割交差検証を検証戦略として使用し、モデルが本番に対応できることを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>k分割交差検証は、訓練データ内部の検証用データセットを用いてモデルの性能を評価する手法で、本番環境準備に直接的に寄与する手法ではありません。<br>それに対して、TFX ModelValidatorは具体的なパフォーマンス指標を設定し、本番環境での動作を評価できます。<br>選択肢：直近1週間のデータを検証セットとして使用し、モデルが現在のデータで正確に機能していることを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>直近1週間のデータを検証セットとして使用する方法は、短期間のデータしか反映されず、顧客の行動の動的な変化を十分に捉えることができません。結果としてモデルの信頼性が下がります。<br>一方、TFX ModelValidatorツールを使うと、数多くのデータを使用してモデルのパフォーマンスを追跡し、より信頼性の高い検証が可能になります。<br>選択肢：データセット全体を使用し、受信者動作特性曲線下面積（AUC ROC）を主要指標として扱います<br>この選択肢が正しくない理由は以下の通りです。<br>データセット全体を使用し、AUC ROCを主要指標として扱うことは一般的な評価手法でありますが、問題設定では"本番稼動する前に特定のサブセットのデータでパフォーマンスを追跡したい"となっています。それに対してこの選択肢では、特定のサブセットのパフォーマンスを追跡する手法が考慮されていません。<br>一方、TFX ModelValidatorは新しいモデルが前のモデルよりも優れているか確認するためのツールであり、特定のサブセットデータに対する評価も可能です。'>
<div class='choice'> 直近1週間のデータを検証セットとして使用し、モデルが現在のデータで正確に機能していることを確認します</div>
<div class='choice'> k分割交差検証を検証戦略として使用し、モデルが本番に対応できることを確認します</div>
<div class='choice'> データセット全体を使用し、受信者動作特性曲線下面積（AUC ROC）を主要指標として扱います</div>
<div class='choice'> TFX ModelValidatorツールを使用して、本番環境準備のためのパフォーマンス指標を指定します</div>
</div>

<div class='question' data-multiple='false' data-question='問題19<br>あなたは、MLモデルのトレーニングパイプラインの設計と実装を担当するMLエンジニアです。あなたは、TensorFlowモデルのエンドツーエンドのトレーニングパイプラインを作成する必要があります。TensorFlowモデルは、数TBの構造化データで学習されます。パイプラインには、トレーニング前のデータ品質チェックと、トレーニング後デプロイ前のモデル品質チェックを含める必要があります。開発時間とインフラのメンテナンスの必要性を最小限にしたいと考えています。<br>トレーニングパイプラインをどのように構築し、オーケストレーションすべきですか？' data-answer='0' data-explanation='解説<br>正解は「TensorFlow Extended（TFX）と標準TFXコンポーネントを使用してパイプラインを作成します。Vertex AI Pipelinesを使用してパイプラインをオーケストレーションします」です。<br>この問題では、TensorFlowモデルのエンドツーエンドの訓練パイプラインを作成するために、どのツールやテクノロジーを使用すべきかを尋ねています。数TBの構造化データで学習され、データ品質チェックと、モデル品質チェックを含める必要があります。また開発時間とインフラのメンテナンスの最低限化が求められています。これらの要点を踏まえながら各選択肢の技術的特性とそれが提供する機能性が要件と一致しているかを考慮して答えを選択します。Google Cloudのサービスを使用することに注意すべきです。<br>基本的な概念や原則：<br>TensorFlow Extended（TFX）：機械学習モデルのエンドツーエンドプロセスをサポートするフレームワークです。データの検証、トレーニング、モデルの検証とデプロイなどの一連の処理をサポートします。<br>Vertex AI Pipelines：Google Cloudのサービスで、機械学習ワークフローのオーケストレーションに利用されます。リソースの管理やパイプラインの実行ステップの追跡を自動化します。<br>Kubeflow Pipelines：Kubernetesのマルチステップの機械学習ワークフローをオーケストレーションするプラットフォームです。独自のDSLを使用し、再利用可能なコンポーネントを基にパイプラインを作成できます。<br>Google Kubernetes Engine（GKE）：Google Cloudの管理型Kubernetesサービスです。クラスターの設定やアップグレード、スケーリングなどを自動化することができます。<br>モデル品質チェック：学習後のモデルが与えられた評価基準を満たしているか確認するプロセスです。これはモデルのパフォーマンスを保証し、問題がある場合にそれを早期に発見するために重要です。<br>正解についての説明：<br>（選択肢）<br>・TensorFlow Extended（TFX）と標準TFXコンポーネントを使用してパイプラインを作成します。Vertex AI Pipelinesを使用してパイプラインをオーケストレーションします<br>この選択肢が正解の理由は以下の通りです。<br>まず、TensorFlow Extended（TFX）はTensorFlow専用のエンドツーエンド機械学習パイプラインフレームワークで、データ検証、モデル検証など、多数の再利用可能な機能を提供します。<br>また、標準のTFXコンポーネントを使用することで、データ品質とモデル品質チェックなどの要件を満たすことができます。<br>次に、開発時間とインフラのメンテナンスを最小限にするためには、自動化とオーケストレーションが重要です。Vertex AI Pipelinesは、機械学習ワークフローのオーケストレーションと自動化をサポートするGoogle Cloudサービスで、これを用いることで、TFXパイプラインのオーケストレーションを効率よく行うことができます。<br>これらの組み合わせにより、機能が豊富でかつ管理が効率的なMLモデルのトレーニングパイプラインを開発することができます。<br>不正解の選択肢についての説明：<br>選択肢：Kubeflow Pipelinesドメイン固有言語（DSL）と定義済みのGoogle Cloudコンポーネントを使用してパイプラインを作成します。Vertex AI Pipelinesを使用してパイプラインをオーケストレーションします<br>この選択肢が正しくない理由は以下の通りです。<br>Kubeflow Pipelinesの使用は不適切です。これは、開発時間とメンテナンスの必要性を最小限にするためには、TensorFlowのワークフローに最適化されたTensorFlow Extended（TFX）を使用するほうが適切です。<br>これに対し、Kubeflow Pipelinesはより汎用的なパイプライン作成に向いていますが、開発とメンテナンスの手間は増えます。<br>選択肢：Kubeflow Pipelinesのドメイン固有言語（DSL）と定義済みのGoogle Cloudコンポーネントを使用してパイプラインを作成します。Google Kubernetes EngineにデプロイされたKubeflow Pipelinesを使用してパイプラインをオーケストレーションします<br>この選択肢が正しくない理由は以下の通りです。<br>Kubeflow PipelinesのDSLとGoogle Cloudコンポーネントを使用すると、開発時間とメンテナンスが増えてしまいます。そのため、開発時間とメンテナンスの最小化を目指す要件に反しています。<br>対照的に、TFXとVertex AI Pipelinesは、これらの要素を軽減し、より専門的にTensorFlowモデルのトレーニングに集中できます。<br>選択肢：TensorFlow Extended（TFX）と標準TFXコンポーネントを使用してパイプラインを作成します。Google Kubernetes EngineにデプロイされたKubeflow Pipelinesを使用してパイプラインをオーケストレーションします<br>この選択肢が正しくない理由は以下の通りです。<br>Google Kubernetes EngineにデプロイされたKubeflow Pipelinesを使用すると、運用とメンテナンスの負担が増大します。開発時間とインフラのメンテナンスを最小限にしたいという要件に反します。<br>それに対し、Vertex AI Pipelinesは管理型のサービスであり、開発とデプロイの時間短縮に寄与します。'>
<div class='choice'> TensorFlow Extended（TFX）と標準TFXコンポーネントを使用してパイプラインを作成します。Vertex AI Pipelinesを使用してパイプラインをオーケストレーションします</div>
<div class='choice'> Kubeflow Pipelinesのドメイン固有言語（DSL）と定義済みのGoogle Cloudコンポーネントを使用してパイプラインを作成します。Google Kubernetes EngineにデプロイされたKubeflow Pipelinesを使用してパイプラインをオーケストレーションします</div>
<div class='choice'> Kubeflow Pipelinesドメイン固有言語（DSL）と定義済みのGoogle Cloudコンポーネントを使用してパイプラインを作成します。Vertex AI Pipelinesを使用してパイプラインをオーケストレーションします</div>
<div class='choice'> TensorFlow Extended（TFX）と標準TFXコンポーネントを使用してパイプラインを作成します。Google Kubernetes EngineにデプロイされたKubeflow Pipelinesを使用してパイプラインをオーケストレーションします</div>
</div>

<div class='question' data-multiple='false' data-question='問題20<br>モデルトレーニングのGPU使用率をモニタリングしているときに、ネイティブの同期実装があることに気づきました。トレーニングデータは複数のファイルに分割されています。一方で、入力パイプラインの実行時間を短縮したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「パイプラインにパラレルインターリーブを追加します」です。<br>この問題では、トレーニングデータの入力パイプラインの実行時間を短縮するための最適な方法を問われています。具体的には、GPU使用率のモニタリングというコンテキストと、トレーニングデータが複数のファイルに分割されているということ実を踏まえて回答を導き出すことが求められます。選択肢を考えるときは、これらの情報がヒントとなりうることを覚えておきましょう。また、一般的なパイプライン最適化やデータ処理手法の知識も問われます。<br>基本的な概念や原則：<br>パラレルインターリーブ：データ処理パイプラインにおけるテクニックの一つで、複数のファイルから同時にデータを読み込むことで入力パイプラインの実行時間を短縮します。<br>GPU使用率：GPU利用の割合を示し、100％に近いほどGPUがフルに活用されていると解釈できます。低い場合、GPUが待機状態にある可能性があり、パフォーマンスが最大に達していない可能性があります。<br>ネイティブの同期実装：実装されているプログラムやスクリプトが一つずつ順に実行される方式を指します。効率的なリソース利用のためには、非同期処理や並列処理が推奨されることが多いです。<br>モデルトレーニング：機械学習を適用するためのプロセスで、大量のデータからパターンを学習して新しいデータに対する予測を行います。<br>パイプラインキャッシュ：特定のパイプライン操作を高速化するために使用される一時的なデータ保存領域です。しかし、無差別にキャッシュを追加するのではなく、パフォーマンスに直接影響を与える部分に適用するべきです。<br>正解についての説明：<br>（選択肢）<br>・パイプラインにパラレルインターリーブを追加します<br>この選択肢が正解の理由は以下の通りです。<br>パイプラインにパラレルインターリーブを追加することで、データの読み込み及び前処理の効率を大幅に向上させることができます。トレーニングデータが複数のファイルに分割されている場合、各ファイルからデータを交互に読み込むことで、I/O待ちの時間を大幅に減らすことができます。これは、GPUが最大限に活用され、モデルのトレーニング時間が大幅に短縮されることを意味します。<br>さらに、この変更はパイプラインの実装を大幅に複雑にすることなく、既存の同期パイプラインを取り替えることなく達成することができます。<br>したがって、パラレルインターリーブの追加は、入力パイプラインの実行時間を短縮するための理想的な解決策です。<br>不正解の選択肢についての説明：<br>選択肢：CPU負荷を高めます<br>この選択肢が正しくない理由は以下の通りです。<br>CPU負荷を高めることは、単にリソースの消費を増やすだけで、入力パイプラインの実行時間を短縮するとは限りません。<br>一方、パラレルインターリーブを追加することで、複数のデータを同時に処理することが可能になり、効率的なリソース利用を実現し、パイプラインの実行時間を短縮します。<br>選択肢：パイプラインにキャッシュを追加します<br>この選択肢が正しくない理由は以下の通りです。<br>パイプラインにキャッシュを追加すると、データ処理の回数が減るため実行時間は短縮されますが、ネイティブの同期実装から非同期の並列処理に変更する要件を満たしません。<br>一方、パラレルインターリーブを追加すると、同期実装を並列に実行し、実行時間を短縮しGPU使用率も最適化します。<br>選択肢：ネットワーク帯域幅を拡大します<br>この選択肢が正しくない理由は以下の通りです。<br>ネットワーク帯域幅を拡大することは、データ伝送速度を高める手段であり、同期実装の問題やパイプラインの速度自体には直接影響を及ぼしません。<br>一方、パラレルインターリーブの追加は複数のファイルから同時にデータを読み込むことができ、直接パイプラインの実行時間を短縮するための最適な解決策です。'>
<div class='choice'> ネットワーク帯域幅を拡大します</div>
<div class='choice'> パイプラインにキャッシュを追加します</div>
<div class='choice'> CPU負荷を高めます</div>
<div class='choice'> パイプラインにパラレルインターリーブを追加します</div>
</div>

<div class='question' data-multiple='false' data-question='問題21<br>あなたは、AI Platformを使用してTensorFlowでテキスト分類モデルをトレーニングしました。学習したモデルを、計算オーバーヘッドを最小限に抑えながら、BigQueryに格納されたテキストデータのバッチ予測に使用したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「モデルをBigQuery MLにエクスポートします」です。<br>この問題では、AIに関する理解だけでなく、各サービス間の整合性についても理解が求められます。まず、AI Platformで訓練したTensorFlowのモデルを用いて、BigQuery上のテキストデータを用いたバッチ予測を行いたいという状況設定です。そこで最重要なのが、計算オーバーヘッドを抑制するという要請です。選択肢をチェックする際には、この計算オーバーヘッドの制約に適った方法を見極めることが重要になります。<br>基本的な概念や原則：<br>TensorFlow：オープンソースの機械学習ライブラリで、複雑なネットワークのトレーニングと実行を容易にします。Googleが開発し、AI Platformと統合して使用できます。<br>AI Platform：Google Cloud上で機械学習モデルを作成、トレーニング、デプロイするためのマネージドサービスです。<br>BigQuery：Google Cloudのサーバレスな、高価能のデータウェアハウスサービスです。<br>BigQuery ML：BigQueryの中で機械学習モデルを作成、トレーニング、予測を行う機能です。SQLを使って操作し、データのエクスポートやインポートの手間をなくします。<br>SavedModel：TensorFlowのモデル保存フォーマットで、モデルのパラメータと計算グラフを一緒に保存します。これにより、トレーニング状態を維持しながらモデルを再利用できます。<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスで、大規模なデータの保存や共有に適しています。データの永続化や多地域アクセスが可能です。<br>正解についての説明：<br>（選択肢）<br>・モデルをBigQuery MLにエクスポートします<br>この選択肢が正解の理由は以下の通りです。<br>まず、GoogleのBigQuery MLは高度な機械学習モデルのトレーニングと予測をBigQuery内で行うことを可能にします。具体的には、SQLクエリを使用してBigQueryに保存されたデータに直接機械学習モデルを適用することができます。これは別の場所にデータをエクスポートする手間やその際に発生するコストを削減します。<br>また、BigQuery MLは、トレーニングされたTensorFlowモデルを直接インポートして使用できます。これにより、既存のテキスト分類モデルをそのまま流用し、BigQuery内でバッチ予測を行うことが可能になります。これにより、計算オーバーヘッドが最小限に抑えられ、効率的に大量のテキストデータに対する予測を行うことができます。<br>したがって、学習したモデルをBigQuery MLにエクスポートする選択肢が最適と言えます。<br>不正解の選択肢についての説明：<br>選択肢：AI Platformにモデルをデプロイし、バージョン管理します<br>この選択肢が正しくない理由は以下の通りです。<br>AI Platformにモデルをデプロイしてバージョン管理すると、それぞれの予測リクエストがオーバーヘッドを伴います。<br>それに対して、モデルをBigQuery MLにエクスポートすれば、BigQuery内で直接予測を行うため、オーバーヘッドを最小限に抑えることができます。<br>選択肢：SavedModelとDataflowを使用して、BigQueryからデータを読み込みます<br>この選択肢が正しくない理由は以下の通りです。<br>SavedModelとDataflowを使用することでデータを読み込むことは可能ですが、方法自体がバッチ処理操作に多少の計算オーバーヘッドを伴います。<br>対照的に、正解のモデルをBigQuery MLにエクスポートする方法なら、バッチ予測を直接BigQuery内で行うことが可能で、計算オーバーヘッドを最小限に抑えられます。<br>選択肢：Cloud Storage内のモデルの場所を指すバッチ予測ジョブをAI Platform上に送信します<br>この選択肢が正しくない理由は以下の通りです。<br>AI Platform上でバッチ予測ジョブを送信すると、BigQuery上のテキストデータをCloud Storageにエクスポートし、予測を行ってから再度BigQueryにインポートする必要があり、計算オーバーヘッドが大きくなります。<br>逆に、モデルをBigQuery MLにエクスポートした方が、データ移動を最小限に抑えて効率的に予測が行えます。'>
<div class='choice'> Cloud Storage内のモデルの場所を指すバッチ予測ジョブをAI Platform上に送信します</div>
<div class='choice'> SavedModelとDataflowを使用して、BigQueryからデータを読み込みます</div>
<div class='choice'> AI Platformにモデルをデプロイし、バージョン管理します</div>
<div class='choice'> モデルをBigQuery MLにエクスポートします</div>
</div>

<div class='question' data-multiple='false' data-question='問題22<br>あなたの組織のコールセンターは、各コールにおける顧客の感情を分析するモデルの開発をあなたに依頼しました。コールセンターは毎日100万件以上のコールを受け、データはCloud Storageに保存されます。収集されたデータは、コールが発信された地域を離れてはならず、個人を特定できる情報（PII）を保存または分析することはできません。データサイエンスチームは、SQL ANSI-2011準拠のインターフェースを必要とする可視化とアクセス用のサードパーティー製ツールを使用しています。データ処理用と分析用のコンポーネントを選択する必要があります。<br>データパイプラインはどのように設計すべきですか？' data-answer='3' data-explanation='解説<br>正解は「1 = Dataflow、2 = BigQuery」です。<br>この問題では、データの規模と特性、そして利用者の要件を理解し、それに対して最適なデータパイプラインを設計する能力が求められています。まず、毎日100万件以上のコールが発生し、そのデータはCloud Storageに保存されていることに注目します。さらに、データは原則として発信地域を離れないという要件と、個人を特定できる情報を保存・分析できないという制約がある点にも注意が必要です。最後に、データサイエンスチームはSQL ANSI-2011準拠のインターフェースを必要とし、それを用いた可視化とアクセスをサードパーティー製ツールで行いたいという要望があります。これらの情報を元に、各選択肢のデータパイプラインが問題文の要件にどれだけマッチするかを判断します。<br>基本的な概念や原則：<br>Dataflow： Google Cloudの完全マネージドのストリームとバッチ処理のサービスです。大規模なデータセットに対する情報処理と変換に使用します。<br>BigQuery： Google Cloudのフルマネージド、パワフルなデータウェアハウスサービスです。大量のデータ分析をリアルタイムに行うことが可能で、SQL ANSI-2011準拠のインターフェースを提供します。<br>Pub/Sub： Google Cloudのリアルタイムのメッセージングサービスです。アプリケーション間の非同期通信を可能にします。<br>Datastore： NoSQLドキュメントデータベースであり、Web、モバイルアプリケーションに対するスケーラブルなストレージを提供します。<br>Cloud SQL： Google Cloudの完全マネージドのリレーショナルデータベースサービスです。データアクセスと可視化には、データウェアハウスよりもデータベースの方が適しています。<br>Cloud Functions： Google Cloudのイベント駆動型のサーバレスコンピューティングプラットフォームです。個々の関数を実行するためのトリガーを使用します。<br>正解についての説明：<br>（選択肢）<br>・1 = Dataflow、2 = BigQuery<br>この選択肢が正解の理由は以下の通りです。<br>まず、DataflowはGoogle Cloudが提供するフルマネージド型のデータ処理サービスであり、大量のデータをリアルタイムまたはバッチ処理で効率よく処理できます。コールセンターからの大量のデータを直接取り扱うのに適しています。<br>また、Dataflowはデータの事前処理や変換作業に役立ちます。個人を特定できる情報（PII）を保存または分析しないようにするためには、これが頻繁に行われる可能性があります。<br>次に、BigQueryはGoogle Cloudのフルマネージド型の大規模データ分析サービスです。標準SQLに準拠しており、データサイエンスチームが使用するサードパーティー製の可視化とアクセス用ツールとシームレスに統合できます。<br>また、BigQueryはリージョンレベルでデータの移動を制限することができます。これにより、コールが発信された地域を離れないという要件に対応できます。<br>したがって、DataflowとBigQueryを組み合わせることで、問題のすべての要件に効果的に対応するパイプラインを設計できます。<br>不正解の選択肢についての説明：<br>選択肢：1 = Pub/Sub、2 = Datastore<br>この選択肢が正しくない理由は以下の通りです。<br>まず、Pub/Subはデータをリアルタイムで収集・配信するためのサービスであり、大量のデータを処理するのに適していません。<br>また、DatastoreはNoSQLデータベースであり、SQL ANSI-2011準拠のインターフェースを提供していません。<br>対照的に、Dataflowは大規模なデータ処理に適しており、BigQueryはSQL ANSI-2011準拠のインターフェースを提供するため、これらは問題の要件を満たします。<br>選択肢：1 = Dataflow、2 = Cloud SQL<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud SQLはANSI-2011準拠のインターフェースを提供しますが、高度な分析用途にはBigQueryの方が最適です。BigQueryは大量のデータを高速に処理し、SQL ANSI-2011準拠のクエリインターフェースを提供し、さまざまなサードパーティー製ツールとの互換性も高いです。<br>選択肢：1 = Cloud Functions、2 = Cloud SQL<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Functionsでは大量のデータを効率的に処理するには限度があり、100万件以上のコール処理には負荷が大きすぎます。<br>一方、Dataflowは大量のデータをリアルタイムで効率的に処理することができます。<br>また、Cloud SQLはSQL ANSI-2011準拠のインターフェースを提供できますが、大規模データの分析にはBigQueryの方が適しています。'>
<div class='choice'> 1 = Dataflow、2 = Cloud SQL</div>
<div class='choice'> 1 = Cloud Functions、2 = Cloud SQL</div>
<div class='choice'> 1 = Pub/Sub、2 = Datastore</div>
<div class='choice'> 1 = Dataflow、2 = BigQuery</div>
</div>

<div class='question' data-multiple='false' data-question='問題23<br>サードパーティーのデータブローカーから提供されたデータを使用して、モデルをトレーニングしています。データブローカーは、データのフォーマット変更の通知を保証していません。このような問題に対して、モデル学習パイプラインをより堅牢にしたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「TensorFlow Data Validationを使用して、スキーマの異常を検出し、フラグを立てます」です。<br>この問題では、予測不能なデータフォーマットの変更という問題に対して、モデル学習パイプラインをいかにして強固に保つかを模索しています。1つの重要なポイントは、フォーマットの変更はデータブローカーから事前通知されないということ実です。したがって、複雑な事前処理や規格化処理、既知エラーパターンの検出などではなく、異常検知や未知のエラーパターンの発見などを可能にする方法を探求します。<br>基本的な概念や原則：<br>TensorFlow Data Validation：大規模データセットの統計情報の計算と可視化、スキーマの推定と検証、スキーマとデータの不一致を検出するためのツールです。受信データの品質を保証するために使用します。<br>TensorFlow Transform：TensorFlowが提供するライブラリで、学習前のデータの前処理を行います。ただし、スキーマ異常の自動検出はサポートしていません。<br>tf.math：TensorFlowのAPIの一部で、数学的な演算を提供します。ただし、スキーマ異常の自動検出機能は提供していません。<br>カスタムTensorFlow関数：TensorFlowで実装された特定の関数のことで、特定のデータ操作や処理を行います。ただし、スキーマ異常の全自動検出機能を構築するには労力が必要です。<br>正解についての説明：<br>（選択肢）<br>・TensorFlow Data Validationを使用して、スキーマの異常を検出し、フラグを立てます<br>この選択肢が正解の理由は以下の通りです。<br>まず、TensorFlow Data Validation（TFDV）は、データの異常を検出したり、変更のあったデータを適切にフラグ付けしたりする機能を持つツールです。この機能により、データの品質を維持し、未知の問題を防ぐことができます。データブローカーがデータのフォーマット変更に関して事前の通知を保証していない場合、データの変更や異常に迅速に対応するためにはTFDVが非常に役立ちます。<br>また、TFDVには、トレーニングデータとテストデータのスキーマの一貫性を確認するための機能もあります。これにより、モデル学習パイプラインが堅牢であるという要件を満たすことができます。<br>したがって、データのフォーマットが変更された場合でもモデルのパフォーマンスに影響を与えることなく、モデルのトレーニングを続けることができます。<br>不正解の選択肢についての説明：<br>選択肢：TensorFlow Transformを使用して、データを期待される分布に正規化し、スキーマに一致しない値を0に置き換える前処理コンポーネントを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>TensorFlow Transformはデータの前処理には有効ですが、スキーマの異常検出機能を持っていません。<br>一方、TensorFlow Data Validationは入力データのスキーマを分析し異常を検出する機能を持つため、データのフォーマット変更による影響を検知・管理するのに適しています。<br>選択肢：tf.mathを使用して、データを分析し、要約統計量を計算し、統計的異常にフラグを立てます<br>この選択肢が正しくない理由は以下の通りです。<br>tf.mathはテンソル操作に使用され、要約統計量を計算するために使用することができますが、データのスキーマの異常を自動で検出したりフラグを立てたりする機能はありません。<br>一方、TensorFlow Data Validationはデータのスキーマの異常検出や統計的機能を持ち、データ問題を自動検出できますので設問の要件を満たします。<br>選択肢：モデル学習の開始時にカスタムTensorFlow関数を使用して、既知のフォーマットエラーを検出し、フラグを立てます<br>この選択肢が正しくない理由は以下の通りです。<br>カスタムTensorFlow関数を使用して既知のフォーマットエラーを検出する方法は、新たなフォーマットの変更を自動検出できないため、未知のエラーには対応できません。<br>逆に、TensorFlow Data Validationはスキーマの異常を自動検出し、新たなフォーマット変更にも柔軟に対応できるため、パイプラインをより堅牢にすることができます。'>
<div class='choice'> モデル学習の開始時にカスタムTensorFlow関数を使用して、既知のフォーマットエラーを検出し、フラグを立てます</div>
<div class='choice'> TensorFlow Transformを使用して、データを期待される分布に正規化し、スキーマに一致しない値を0に置き換える前処理コンポーネントを作成します</div>
<div class='choice'> TensorFlow Data Validationを使用して、スキーマの異常を検出し、フラグを立てます</div>
<div class='choice'> tf.mathを使用して、データを分析し、要約統計量を計算し、統計的異常にフラグを立てます</div>
</div>

<div class='question' data-multiple='false' data-question='問題24<br>あなたの組織は、社内シャトルサービスのルートをより効率的にしたいと考えています。シャトルは現在、午前7時から午前10時の間、30分おきに市内のすべてのピックアップポイントに停車しています。開発チームはすでにGoogle Kubernetes Engine上にアプリケーションを構築しており、ユーザーは1日前に自分の存在とシャトル駅を確認する必要があります。<br>どのようなアプローチを取るべきですか？' data-answer='2' data-explanation='解説<br>正解は「1.キャパシティ制約の下で、与えられた時刻に乗客が確認されたすべてのシャトル停留所を通過する最短ルートを最適ルートと定義します<br>2.適切な大きさのシャトルを派遣し、地図上に必要な停留所を示します」です。<br>この問題では、シャトルサービスの運用について最適化のアプローチを選択するための提案が求められています。問題文からは、シャトルの停車場所や発車時間が固定でありますが、情報の連携が可能であり、そのためのアプリケーションがすでに存在することが理解できます。シャトルの容量、道路の状況、乗客の予約状況など、多くの変数を考慮に入れる必要があります。ここで重要なのは、最適化のアプローチが実現可能であること、そして乗客の確認とシャトルの停車場所、時間枠について考慮していることです。あくまで効率的なルート選択と車両の最適な配車を図るためのシナリオの元で、適当な選択肢を選びましょう。<br>基本的な概念や原則：<br>Google Kubernetes Engine：Google Cloudのコンテナ化されたアプリケーションをキャパシティ制約なく実行できる管理型サービスです。アプリケーションのデプロイ、スケーリング、障害からの復旧などを自動で手掛けます。<br>ルート最適化：特定の制約の下で最短または最も効率的なルートを見つける問題です。物流、配達、輸送などの業務で利用されます。<br>キャパシティ制約：システムやリソースの量、目標を達成するためのリソースの最大量、または一度に処理できるタスクの最大量を指します。<br>ツリーベースのモデル：決定木などのアルゴリズムに基づく予測モデルのことで、データを分類したり回帰分析を行ったりします。<br>予測モデル：未来の出来事や結果を予測するために構築された統計モデルのことです。<br>分類モデル：機械学習アルゴリズムの一つで、与えられた入力データを特定のカテゴリに分類することが目的です。<br>強化学習モデル：エージェントが行動を選択することで環境が変化し、その結果に基づいて報酬が与えられる学習モデルです。目標は総報酬を最大化することです。<br>正解についての説明：<br>（選択肢）<br>・1.キャパシティ制約の下で、与えられた時刻に乗客が確認されたすべてのシャトル停留所を通過する最短ルートを最適ルートと定義します<br>2.適切な大きさのシャトルを派遣し、地図上に必要な停留所を示します<br>この選択肢が正解の理由は以下の通りです。<br>まず、乗客の予約が1日前に確定することから、それを利用し、確定した乗客のいる停留所のみを通過するルートを最初に決定します。これにより、乗客がいない停留所に無駄に止まることを避けることができ、全体のルートが効率的になります。<br>次に、キャパシティ制約の下で最短ルートを求めます。これは"巡回セールスマン問題"として知られる複雑な最適化問題に対応しますが、利用可能な最適化ツールを使用して解決できます。このルート計算はコンピュータが得意とするタスクで、最終的に社内シャトルの運行が大幅に効率化されます。<br>また、必要な停留所を地図上に示すことで、シャトルドライバーは最適なルートを簡単に理解し、移動できるようになります。この結果、遅延を最小限に抑えることができます。<br>最後に、適切な大きさのシャトルを派遣することで、乗客の数が少ない時間帯に大型のシャトルを使うといったリソースの無駄を防ぎます。<br>これら全ての要素が、社内シャトルサービスのルートをより効率的にする試みと共に連携し、効率的な運行を実現します。<br>不正解の選択肢についての説明：<br>選択肢：1.各シャトル駅で何人の乗客がピックアップされるかを予測する、ツリーベースの回帰モデルを構築します<br>2.適切なサイズのシャトルを配車し、予測に基づいて必要な停留所を地図に表示します<br>この選択肢が正しくない理由は以下の通りです。<br>ツリーベースの回帰モデルを活用することで事前に乗客の人数を予測することは可能ですが、これだけでは最短ルートを特定するのには足りません。<br>また、既にユーザーが1日前に自分の存在を確認しているため、予測よりもこれらの確認された情報を基にしたルート最適化の方がより効果的です。<br>選択肢：1.各シャトル停留所でシャトルが乗客をピックアップすべきかどうかを予測する、ツリーベースの分類モデルを構築します<br>2.利用可能なシャトルを配車し、予測に基づいて必要な停留所を地図に表示します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、この選択肢は、乗客が確認されるまでその需要を予測することに依存していますが、このアプローチは不確実性が高くなります。<br>一方、正解の選択肢では、具体的な乗客データに基づいてルートとシャトルのサイズを最適化するため、より効率的で確実な結果を提供します。<br>選択肢：1.シャトル停留所での乗客の存在をエージェントとして予測するツリーベースの分類モデルと、距離ベースのメトリクスを中心とした報酬関数による強化学習モデルを構築します<br>2.適切なサイズのシャトルを配車し、シミュレーション結果に基づいて必要な停留所をマップに提供します<br>この選択肢が正しくない理由は以下の通りです。<br>選択肢では、強化学習モデルとツリーベースの分類モデルを使用することを提案していますが、これは不必要に複雑で時間とリソースを大量に消費します。<br>一方、正解は既に確定した乗客の情報を元に最適ルートを定義しており、これがより効率的でシンプルな方法です。'>
<div class='choice'><br>1.各シャトル停留所でシャトルが乗客をピックアップすべきかどうかを予測する、ツリーベースの分類モデルを構築します<br>2.利用可能なシャトルを配車し、予測に基づいて必要な停留所を地図に表示します</div>
<div class='choice'><br>1.シャトル停留所での乗客の存在をエージェントとして予測するツリーベースの分類モデルと、距離ベースのメトリクスを中心とした報酬関数による強化学習モデルを構築します<br>2.適切なサイズのシャトルを配車し、シミュレーション結果に基づいて必要な停留所をマップに提供します</div>
<div class='choice'><br>1.キャパシティ制約の下で、与えられた時刻に乗客が確認されたすべてのシャトル停留所を通過する最短ルートを最適ルートと定義します<br>2.適切な大きさのシャトルを派遣し、地図上に必要な停留所を示します</div>
<div class='choice'><br>1.各シャトル駅で何人の乗客がピックアップされるかを予測する、ツリーベースの回帰モデルを構築します<br>2.適切なサイズのシャトルを配車し、予測に基づいて必要な停留所を地図に表示します</div>
</div>

<div class='question' data-multiple='false' data-question='問題25<br>あなたは、Parquetファイルに格納されたデータで学習されるモデルを構築しました。Google Cloud上でホストされているHiveテーブルを介してデータにアクセスします。これらのデータをPySparkで前処理し、CSVファイルとしてCloud Storageにエクスポートします。前処理の後、モデルを学習・評価するための追加ステップを実行します。このモデル学習をKubeflow Pipelinesでパラメトリクス化したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「パイプラインにContainerOpを追加して、Dataprocクラスターをスピンし、変換を実行し、変換されたデータをCloud Storageに保存します」です。<br>この問題では、Parquetファイルのデータを前処理し、その結果をGoogle Cloud Storageに保存するためのPySparkプロセスをKubeflow Pipelinesでパラメトリクス化する方法を評価する必要があります。問題で提供されている情報から、データはHiveテーブルを通じてアクセスされ、データの変換はGoogle Cloud上で行われることが分かります。Kubeflow Pipelinesのパラメトリーズされたプロセスとして適切な方法を選択する必要があります。異なるサービスやツールを駆使して最適な解決策を導き出す能力が試されています。<br>基本的な概念や原則：<br>Parquetファイル：列指向のデータストレージフォーマットで、大規模なデータセット用に設計されています。高度な圧縮とエンコーディングスキームにより最高の効率を実現します。<br>Hive：大規模データセットをクエリ、分析、要約するためのデータウェアハウスソフトウェアです。HiveQLというSQLの方言を使用します。<br>PySpark：Apache SparkのPythonライブラリで、大規模データの処理と分析を行います。<br>Google Cloud Storage：パブリッククラウドデータの保存と取得のためのサービスで、オブジェクトストレージを提供します。<br>Kubeflow Pipelin：機械学習ワークフローを作成、実行および管理するためのソフトウェアです。パーツごとにコンテナ化されたコンポーネントでできた作業フローを作成します。<br>ContainerOp：Kubeflow Pipelinesのためのクラスです。一連のステップの計算を隔離します。これによりステップは独立して実行できます。<br>Dataprocクラスター：予構成されたHadoopとSpark環境の一部です。このクラスターで大規模データ処理タスクを行うことができ、スピンアップやスピンダウンが容易です。<br>正解についての説明：<br>（選択肢）<br>・パイプラインにContainerOpを追加して、Dataprocクラスターをスピンし、変換を実行し、変換されたデータをCloud Storageに保存します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Kubeflow Pipelinesは、あらゆるステップを個々のコンテナとしてカプセル化できる包括的なエンドツーエンドの機械学習ワークフローツールです。ContainerOpは、Kubeflow Pipelinesにおける基本的なビルディングブロックで、独立したタスクを扱うためのコンテナを生成します。<br>この問題では、前処理とその後の学習・評価を別々のタスクとして扱う必要があるため、各タスクに対してContainerOpを作成することが適切です。<br>また、DataprocはGoogle Cloudの完全マネージドのApache HadoopとApache Spark環境で、Parquet形式のデータとHiveテーブルに対するPySparkの前処理に適しています。前処理が完了した後、変換されたデータをCloud Storageに保存することで、次の学習・評価ステップで利用できるようになります。<br>したがって、このワークフローを実現するためには、ContainerOpを用いてDataprocクラスターを起動し、変換を実行し、結果をCloud Storageに保存するのが適切でしょう。<br>不正解の選択肢についての説明：<br>選択肢：パイプラインからデータ変換ステップを削除します<br>この選択肢が正しくない理由は以下の通りです。<br>データ変換ステップを削除すると、ParquetファイルからCSVファイルへの前処理が省略され、それがモデル学習の一部として必要な場合に対応できなくなります。データ変換はパイプラインの重要な一部であり、これを削除するとモデルの性能が低下する恐れがあります。<br>選択肢：PySparkの変換ステップをコンテナ化し、パイプラインに追加します<br>この選択肢が正しくない理由は以下の通りです。<br>この選択肢では、PySparkの変換ステップを単にコンテナ化して追加するだけであり、Hiveテーブルからデータにアクセスしたり、変換したデータをCloud Storageに保存したりといった要件を満たすための具体的な手段が示されていないため、問題文の条件を満たしていません。<br>一方、正解の選択肢ではDataprocクラスターを使い、変換を実行しデータをCloud Storageに保存することで要件を満たす行動がとられています。<br>選択肢：Google Kubernetes Engineクラスターの別のノードプールにApache Sparkをデプロイします。このSparkインスタンスに対応する変換ジョブを呼び出すContainerOpをパイプラインに追加します<br>この選択肢が正しくない理由は以下の通りです。<br>Apache Sparkを直接Google Kubernetes Engineクラスターにデプロイすると、Sparkが最適に動作するような資源管理や設定が必要になり、それを維持するコストが増大します。<br>一方、Dataprocを使用すれば、SparkとHadoopエコシステムを管理し、リソースを効率的に扱う環境が提供され、コストと運用負荷が軽減します。'>
<div class='choice'> パイプラインからデータ変換ステップを削除します</div>
<div class='choice'> Google Kubernetes Engineクラスターの別のノードプールにApache Sparkをデプロイします。このSparkインスタンスに対応する変換ジョブを呼び出すContainerOpをパイプラインに追加します</div>
<div class='choice'> パイプラインにContainerOpを追加して、Dataprocクラスターをスピンし、変換を実行し、変換されたデータをCloud Storageに保存します</div>
<div class='choice'> PySparkの変換ステップをコンテナ化し、パイプラインに追加します</div>
</div>

<div class='question' data-multiple='true' data-question='問題26<br>AI Platformを使用してMLモデルのハイパーパラメータをチューニングし、最適にチューニングされたパラメータをトレーニングに使用します。ハイパーチューニングに予想以上の時間がかかり、下流のプロセスが遅延しています。チューニングの有効性を大きく損なうことなく、チューニング作業をスピードアップしたいと考えています。<br>あなたが取るべき行動はどれですか？（2つ選択）' data-answer='1, 3' data-explanation='解説<br>正解は以下の通りです。<br>・浮動小数点値の範囲を小さくします<br>・早期停止パラメータをTRUEに設定します<br>この問題では、MLモデルのハイパーパラメータチューニングにかかる時間短縮のための手段を考えるべきですが、その際にチューニングの有効性が大きく損なわれるような手段は選ばないよう注意が必要です。選択肢の中には、時間短縮に寄与するかもしれないものと、チューニングの有効性を損なう可能性のあるものが混在していることに留意します。したがって、時間短縮とチューニング有効性のバランスを考慮しながら選択肢を選ぶようにする必要があります。<br>基本的な概念や原則：<br>ハイパーパラメータチューニング：機械学習モデルの学習過程において人間が手動で設定するパラメータの最適化処理のことです。これには、学習率、エポック数、隠れ層の数などが含まれます。<br>浮動小数点値の範囲を小さくする：ハイパーパラメータの探索範囲を減らし、スピードアップする方法です。ただし、範囲が狭すぎると最適解から大きくずれる可能性もあります。<br>早期停止：モデルの訓練をある時点で早く終了させるテクニックです。訓練段階でモデルがアンダーフィットやオーバーフィットになるのを防ぎます。<br>並行試行：ハイパーパラメータチューニング中に同時に複数の設定でモデルを訓練することです。これにより、より早く最適なハイパーパラメータを見つけることができます。<br>ベイズ検索とランダム検索：ハイパーパラメータチューニングのための検索アルゴリズムです。ベイズ検索は、前の検索結果をベースに次のパラメータを選ぶのに対し、ランダム検索はパラメータの探索をランダムに行います。ランダム検索は時間がかかる可能性があります。<br>正解についての説明：<br>（選択肢）<br>・浮動小数点値の範囲を小さくします<br>・早期停止パラメータをTRUEに設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、"浮動小数点値の範囲を小さくします"が選択肢に挙げられている理由は、ハイパーパラメータチューニングが多くの異なるパラメータ値に対するモデルのパフォーマンスを試すプロセスであることからです。このパラメータ値の範囲を狭めることで、試すべき値の総数が減り、それに伴いチューニングのために必要な時間も減少します。これらの操作は、モデルのパフォーマンスに大きな悪影響を与えることなく、チューニング速度を向上させるための効率的な手段となり得ます。<br>また、"早期停止パラメータをTRUEに設定します"が選択肢に挙げられている理由は、早期停止がチューニング作業の効率を向上させるための一般的なテクニックです。早期停止は、特定の条件が満たされたときにトレーニングを中断するメカニズムで、これにより時間のかかる不必要なトレーニングステップを避けることができます。<br>したがって、このパラメータをTRUEに設定することで、ハイパーパラメータチューニングプロセス全体のスピードアップが期待できます。<br>不正解の選択肢についての説明：<br>選択肢：並行試行回数を減らします<br>この選択肢が正しくない理由は以下の通りです。<br>並行試行回数を減らすと、ハイパーパラメータチューニングのスピードアップどころか、試行の総数が減るため全体の処理時間が長くなります。<br>一方、範囲を小さくしたり早期停止パラメータを設定することで、無駄な試行を省き、ハイパーパラメータチューニングを効率的に行うことが可能になります。<br>選択肢：検索アルゴリズムをベイズ検索からランダム検索に変更します<br>この選択肢が正しくない理由は以下の通りです。<br>ベイズ検索からランダム検索への変更は、パラメータの探索速度は向上させますが、最適なハイパーパラメータの発見には劣るため、チューニングの有効性を損ないます。<br>逆に、早期停止をTRUEに設定すると、未来設定の改善が見込めない場合に早めに学習が収束し、全体的なチューニング時間を減らします。<br>選択肢：その後のトレーニング段階で、最大試行回数を減らします<br>この選択肢が正しくない理由は以下の通りです。<br>最大試行回数を減らすのは、ハイパーパラメータチューニングのスピードアップには寄与しますが、チューニングの有効性を大きく損なう可能性があります。早期停止パラメータをTRUEに設定することや浮動小数点値の範囲を細かくすることは、チューニング時間を短縮しながらもチューニングの有効性を保つための手段です。'>
<div class='choice'> 検索アルゴリズムをベイズ検索からランダム検索に変更します</div>
<div class='choice'> 浮動小数点値の範囲を小さくします</div>
<div class='choice'> その後のトレーニング段階で、最大試行回数を減らします</div>
<div class='choice'> 早期停止パラメータをTRUEに設定します</div>
<div class='choice'> 並行試行回数を減らします</div>
</div>

<div class='question' data-multiple='false' data-question='問題27<br>Google Cloud上で構造化データ用のMLパイプラインを再構築したいと考えています。大規模なデータ変換を行うためにPySparkを使用していますが、パイプラインの実行に12時間以上かかっています。開発とパイプラインの実行時間を短縮するために、サーバレスツールとSQL構文を使用したいと考えています。生データはすでにCloud Storageに移動しています。<br>スピードと処理の要件を満たしながら、Google Cloud上でどのようにパイプラインを構築すべきですか？' data-answer='2' data-explanation='解説<br>正解は「BigQuery Loadを使ってデータをBigQueryに取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます」です。<br>この問題では、大規模な構造化データのマシンラーニングパイプラインを構築し、その実行時間を短縮する手法を探しています。PySparkを使用してデータ変換を行っていますが、これが時間がかかってしまっているという状況です。そして、その解決のためにはサーバレスツールとSQL構文の使用を検討しています。ここでのポイントは、サーバレスツールとSQL構文を使用したいという要望と、実行時間の短縮が求められているということです。よって、Google Cloudのサービス群の中から、この要望を満たすもの、特にパフォーマンスに優れたものを選び、それをどのように使うべきかが問われています。<br>基本的な概念や原則：<br>BigQuery：Google Cloudのフルマネージド、SQLをベースにしたデータウェアハウスです。大量のデータを高速に処理できます。<br>BigQuery Load：BigQueryにデータをロード（取り込み）する方法の一つです。大きなデータセットを効率的に取り込むことができます。<br>BigQuery SQL：BigQueryで使用するSQL言語です。標準SQLと非常に似ていますが、BigQuery特有の機能も提供しています。<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスです。大量のデータを安全に保存し、他のGoogle Cloudサービスと統合して利用できます。<br>PySpark：PythonベースのSparkライブラリです。大規模なデータ処理と機械学習タスクを行うために使用されます。<br>サーバレス：従来のサーバマネージメントが不要なアーキテクチャスタイルです。運用コストと管理の複雑さを削減することができます。<br>Data Fusion：サーバレスのデータパイプライン構築サービスです。GUIを使ってデータソースの選択と変換、結果の書き出しを行うことができます。大量のデータ変換に対しては作業時間が長くなる可能性があります。<br>正解についての説明：<br>（選択肢）<br>・BigQuery Loadを使ってデータをBigQueryに取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます<br>この選択肢が正解の理由は以下の通りです。<br>まず、BigQueryはGoogle Cloudのフルマネージドで、サーバレスの大規模なデータウェアハウスです。これにより開発時間が短縮され、サーバレス要件も満たされます。<br>また、BigQueryではSQL形式でクエリを行うことが可能で、これが要件の"SQL構文を使用する"部分に対応します。<br>次に、BigQuery LoadはCloud StorageからBigQueryにデータを効率的に取り込むツールです。このツールを使うことで、生データを速やかにBigQueryで利用可能な状態にすることができます。<br>そして、PySparkコマンドをBigQuery SQLクエリに変換することにより、大規模なデータ変換を高速化します。<br>最後に、変換結果を新しいテーブルに書き込むことで、継続的な分析や活用が可能になります。この一連の流れが、スピードと処理の要件を満たすための最適な解です。<br>不正解の選択肢についての説明：<br>選択肢：Data FusionのGUIを使って変換パイプラインを構築し、データをBigQueryに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Data FusionはGUIを使用してデータ転送と変換パイプラインを視覚的に構築できますが、SQL構文を活用したり、開発や実行時間を大幅に短縮する、といった要件には適していません。<br>一方、BigQuery LoadとBigQuery SQLクエリを使用すると、大規模なデータのロードや変換が高速に、かつSQL構文を用いて行えます。<br>選択肢：PySparkをSparkSQLクエリに変換してデータを変換し、Dataprocでパイプラインを実行してデータをBigQueryに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Dataprocを使用すると、サーバレスな環境を求める問題の要件を満たしません。<br>さらに、Dataprocの使用はパイプラインの実行時間を短縮する保証がありません。<br>これに対して、正解の選択肢はBigQuery Loadを使用することでサーバレスな環境を提供し、容易にSQL構文でデータ変換が行えます。<br>選択肢：Cloud SQLにデータを取り込み、PySparkコマンドをSQLクエリに変換してデータを変換し、BigQueryからの連携クエリを使用して機械学習を行います<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud SQLはサーバレスではなく、大規模なデータ変換には性能が不足しています。<br>一方、BigQueryはサーバレスで大規模なデータ変換に対応しています。<br>また、Cloud SQLからBigQueryへの連携クエリは一般的には存在しないため、選択肢は不適切です。'>
<div class='choice'> Data FusionのGUIを使って変換パイプラインを構築し、データをBigQueryに書き込みます</div>
<div class='choice'> PySparkをSparkSQLクエリに変換してデータを変換し、Dataprocでパイプラインを実行してデータをBigQueryに書き込みます</div>
<div class='choice'> BigQuery Loadを使ってデータをBigQueryに取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます</div>
<div class='choice'> Cloud SQLにデータを取り込み、PySparkコマンドをSQLクエリに変換してデータを変換し、BigQueryからの連携クエリを使用して機械学習を行います</div>
</div>

<div class='question' data-multiple='false' data-question='問題28<br>あなたは、CTスキャンの画像セグメンテーションのために、AI Platformを使ってMLモデルを開発しています。最新の研究論文に基づいてモデルのアーキテクチャを頻繁に更新し、同じデータセットでトレーニングを再実行して性能をベンチマークする必要があります。コードのバージョン管理を行いながら、計算コストと手作業を最小限に抑えたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「新しいコードがリポジトリにプッシュされたときに再トレーニングをトリガーするために、Cloud Source RepositoriesとリンクしたCloud Buildを使用します」です。<br>この問題では、CTスキャンの画像セグメンテーションのためのMLモデルを開発する過程で、新たな研究論文を基に頻繁にモデルのアーキテクチャをアップデートし、性能をベンチマークしながら、コストと手間を最小化する解決策を求めています。コードのバージョン管理の要件から、Google Cloudの各種サービスを組み合わせて実装する解決策が必要であることが伺えます。Cloud Source Repositories, Cloud Build, Cloud Functions, gcloudコマンドラインツールやCloud Composerをどのように組み合わせるかがカギとなります。<br>基本的な概念や原則：<br>AI Platform：Google Cloudのマネージドサービスで、機械学習モデルのトレーニング、デプロイ、予測を充実させます。組み込まれた高度なMLモデルと共に、カスタムモデルのトレーニングとデプロイもサポートされています。<br>Cloud Source Repositories：Google CloudのプライベートGitリポジトリで、コードのバージョン管理を行います。別のプロジェクトやリポジトリとのコード共有やリンクも可能です。<br>Cloud Build：Google Cloudのビルド自動化ツールです。コードの変更を検出すると自動的にビルドとテストを開始し、トリガーを設定して特定の操作を自動化できます。<br>Cloud Functions：イベント駆動型のサーバレスコンピューティング環境です。Google Cloudのクラウドイベントに応答してアプリケーションの一部をデプロイ、実行できます。<br>gcloudコマンドラインツール：Google Cloudのコマンドラインインターフェースです。Google Cloudのリソースとアプリケーションを簡単に操作できます。<br>Cloud Composer：Google Cloudのフルマネージドワークフローオーケストレーションサービスで、Apache Airflowに基づいています。スケジュール、管理、モニタリングを一元管理できます。<br>正解についての説明：<br>（選択肢）<br>・新しいコードがリポジトリにプッシュされたときに再トレーニングをトリガーするために、Cloud Source RepositoriesとリンクしたCloud Buildを使用します<br>この選択肢が正解の理由は以下の通りです。<br>まず、新しいコードがリポジトリにプッシュされるたびに、Cloud Buildがトレーニングをトリガーする機能により、モデルの頻繁な更新とベンチマークが自動化されます。これが計算コストと手作業を最小限に抑えることに寄与します。結果的に高い生産性を確保することが出来ます。<br>次に、新たなコードがリポジトリにプッシュされる際にCloud Source Repositoriesが使用されます。これにより、必要なバージョン管理を確実に行うことができ、開発過程における整合性を保つことができます。<br>最後に、AI Platformでモデル開発を行うことで、Google Cloudのマネージドサービスをフルに活用することが出来ます。これによりスケーリング、モデルの運用管理、依存関係管理など、開発に必要な多くの負荷をGoogle Cloudに委ねることができます。<br>これらの要素が合わさって、実用的かつ生産性の高い機械学習ワークフローを構築することが出来ます。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Functionsを使用して、Cloud Storageにあるコードの変更を識別し、再トレーニングジョブをトリガーします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Functionsを使用しても、Cloud Storageにあるコードの変更を監視して再トレーニングをトリガーすることは可能ですが、バージョン管理は実現できません。<br>逆に、Cloud Source RepositoriesとCloud Buildを使うと、コードのバージョン管理と再トレーニングの自動化が共に可能になります。<br>選択肢：gcloudコマンドラインツールを使用して、コードを更新したときにAI Platformにトレーニングジョブを送信します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloudコマンドラインツールを使った手動のトレーニングジョブ送信は効率が悪く、自動的にトリガーする仕組みに比べて計算コストや手間を削減するという目的に沿いません。<br>一方、Cloud Buildは新しいコードがプッシュされたときに自動でトリガーでき、より効率的です。<br>選択肢：Cloud Composerで自動ワークフローを作成し、毎日実行し、センサーを使ってCloud Storageのコードの変更を探します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Composerは主にワークフローオーケストレーションに使用され、毎日ランの設定はリソースとコストの無駄です。<br>一方、Cloud Buildはコードがリポジトリにプッシュされるときに自動的に再トレーニングを始めることができ、より効率的です。'>
<div class='choice'> Cloud Composerで自動ワークフローを作成し、毎日実行し、センサーを使ってCloud Storageのコードの変更を探します</div>
<div class='choice'> 新しいコードがリポジトリにプッシュされたときに再トレーニングをトリガーするために、Cloud Source RepositoriesとリンクしたCloud Buildを使用します</div>
<div class='choice'> gcloudコマンドラインツールを使用して、コードを更新したときにAI Platformにトレーニングジョブを送信します</div>
<div class='choice'> Cloud Functionsを使用して、Cloud Storageにあるコードの変更を識別し、再トレーニングジョブをトリガーします</div>
</div>

<div class='question' data-multiple='false' data-question='問題29<br>あなたは公共交通機関に勤務しており、複数の交通ルートの遅延時間を予測するモデルを構築する必要があります。予測はアプリでリアルタイムにユーザーに直接提供されます。季節や人口の増加がデータの関連性に影響を与えるため、毎月モデルを再トレーニングする必要があります。また、Googleが推奨するベストプラクティスに従う必要があります。<br>予測モデルのエンドツーエンドのアーキテクチャはどのように構成すべきですか？' data-answer='0' data-explanation='解説<br>正解は「Kubeflow Pipelinesを設定して、トレーニングからモデルのデプロイまでのマルチステップワークフローをスケジュールします」です。<br>この問題では、公共交通の遅延時間を予測するモデルのエンドツーエンドのアーキテクチャの設計が求められています。重要な点として、モデルはリアルタイムに結果を提供し、さらに季節性や人口増加などの要因により、毎月再トレーニングが必要となること、またGoogleのベストプラクティスに従わなければならないことが挙げられます。これらの要件を満たすためには、適切なツールやサービスを選び、モデルのトレーニングからデプロイまでをスケジューリング管理することが肝要です。選択肢から適切なGoogle Cloudのサービスを選び出すのが解決策です。<br>基本的な概念や原則：<br>Kubeflow Pipelines：エンドツーエンドの機械学習ワークフローを簡化、共有、再利用できるオープンソースプラットフォームです。トレーニングからモデルのデプロイまでのマルチステップワークフローを作成およびスケジュールできます。<br>BigQuery ML：BigQuery内で直接機械学習モデルをビルドし、予測することを可能にするサービスです。しかし、柔軟性やパフォーマンスにおいて、大規模なトレーニングや予測タスクに対して最適化されていません。<br>Cloud Scheduler：Google Cloudのジョブスケジューラで、定義したスケジュールに従って自動的にジョブを起動します。しかし、このサービスだけでは完全な機械学習パイプラインを構築するのは難しいです。<br>AI Platform：Google Cloudのフルサービスのマネージドサービスで、機械学習モデルのトレーニングからデプロイ、予測までを管理します。ただし、トリガーやスケジューリングの機能は含まれていません。<br>Cloud Functions：Google Cloudのサーバレス実行環境で、特定のイベントに基づいて自動的にコードを実行します。しかし、これは単独で使うよりも他のサービスと組み合わせて使うことが一般的です。<br>Cloud Composer：Google Cloudのフルマネージドのワークフローオーケストレーションサービスで、Apache Airflowを元にしたワークフローの作成と管理を行います。ただし、これは一般的にデータ処理やETLタスクのワークフローを管理するのに使われます。<br>Dataflow：Google Cloudのバッチとストリームのデータ処理サービスで、大量のデータを処理し、必要な形式に変換します。ただし、これを直接機械学習のワークフローに適用するのは難しいです。<br>正解についての説明：<br>（選択肢）<br>・Kubeflow Pipelinesを設定して、トレーニングからモデルのデプロイまでのマルチステップワークフローをスケジュールします<br>この選択肢が正解の理由は以下の通りです。<br>まず、Kubeflow Pipelinesは機械学習ワークフローを構築、デプロイ、管理するためのツールであり、トレーニングからデプロイまでのワークフローを簡易化します。これは特に頻繁にモデルを再トレーニングする必要がある場合に役立ちます。Kubeflow Pipelinesは、トレーニング、評価、デプロイまでの各ステップを予測モデルの生成に消費する時間と労力を大幅に削減する効率的な手段です。<br>さらに、これらのパイプラインはスケジュール可能であり、再トレーニングが必要なタイミング（このケースでは月次）で自動実行することができます。<br>また、KubeflowはGoogleが推奨するプラクティスを採用しており、コンテナ化された環境であるため、再現性とポータビリティが確保されています。これにより、一貫性のある開発とデプロイ環境が確保され、エラーや予期せぬ挙動が抑制されます。<br>これらの要素により、Kubeflow Pipelinesを使用してトレーニングからデプロイまでのマルチステップワークフローをスケジュールすることがこのユースケースには最適です。<br>不正解の選択肢についての説明：<br>選択肢：BigQuery MLでトレーニングされデプロイされたモデルを使用し、BigQueryのスケジュールされたクエリ機能で再トレーニングをトリガーします<br>この選択肢が正しくない理由は以下の通りです。<br>BigQuery MLとスケジュールされたクエリはモデルの再トレーニングに使用できますが、モデルをアプリでリアルタイムに提供する要件を満たしません。<br>一方、Kubeflow Pipelinesはモデルのトレーニングからデプロイまでの全エンドツーエンドプロセスを管理し、リアルタイムの予測提供も可能です。<br>選択肢：Cloud SchedulerによってトリガーされるAI Platform上のトレーニングとデプロイジョブを起動するCloud Functionsスクリプトを書きます<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud FunctionsとCloud Schedulerを使うとトレーニングとデプロイジョブをスケジューリングできますが、これらはエンドツーエンドのワークフローや再利用可能なコンポーネントの管理をサポートしていません。これに対してKubeflow Pipelinesは各ステップ間の依存性を管理し、エンドツーエンドのワークフローが必要な問題に適切です。<br>選択肢：Cloud Composerを使用して、トレーニングからモデルのデプロイまでのワークフローを実行するDataflowジョブをプログラムでスケジュールします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud ComposerとDataflowはデータパイプラインの作成や運用には適していますが、機械学習モデルのトレーニングやデプロイを効率的に管理するには不適切です。それに比べ、Kubeflow Pipelinesは機械学習ワークフローを効率的に管理するための設計がなされており、再トレーニングなどの要件を満たします。'>
<div class='choice'> Kubeflow Pipelinesを設定して、トレーニングからモデルのデプロイまでのマルチステップワークフローをスケジュールします</div>
<div class='choice'> BigQuery MLでトレーニングされデプロイされたモデルを使用し、BigQueryのスケジュールされたクエリ機能で再トレーニングをトリガーします</div>
<div class='choice'> Cloud SchedulerによってトリガーされるAI Platform上のトレーニングとデプロイジョブを起動するCloud Functionsスクリプトを書きます</div>
<div class='choice'> Cloud Composerを使用して、トレーニングからモデルのデプロイまでのワークフローを実行するDataflowジョブをプログラムでスケジュールします</div>
</div>

<div class='question' data-multiple='false' data-question='問題30<br>あなたのデータサイエンスチームは、スケジュールされたモデルの再トレーニングをサポートするシステム、Dockerコンテナ、オンライン予測リクエストの自動スケーリングとモニタリングをサポートするサービスを要求しています。<br>このシステムにはどのプラットフォームコンポーネントを選択すべきですか？' data-answer='2' data-explanation='解説<br>正解は「Vertex AI Pipelines、Vertex AIによる予測、Vertex AI Model Monitoring」です。<br>この問題では、データサイエンスチームが要求する機能を捉え、それを満たすGoogle Cloudのプラットフォームコンポーネントを選ぶ必要があります。具体的には、スケジュールされたモデルの再トレーニング、Dockerコンテナ、オンライン予測リクエストの自動スケーリングとモニタリングの機能を持ったGoogle Cloudのサービスを見つけ出すことが求められています。選択肢の中からこれらの要求を全て満たすものを選ぶことが重要です。<br>基本的な概念や原則：<br>Vertex AI Pipelines：機械学習ワークフローを自動化し、実行し、管理するためのサービスです。スケジュールされたモデルの再トレーニングなども扱います。<br>Vertex AIによる予測：機械学習モデルからの予測をリクエストするためのサービスです。自動スケーリングとモニタリングをサポートし、具体的な需要量に応じてリソースを動的に調整します。<br>Vertex AI Model Monitoring：モデルのパフォーマンスと精度を監視するためのツールです。オンライン予測リクエストの動作の変化を検出します。<br>Cloud Composer：オープンソースのApache Airflowを利用して、複雑なワークフローを作成・スケジューリングし、管理するフルマネージドなサービスです。<br>BigQuery ML：BigQueryのデータを使用して機械学習モデルをビルドし、予測を行うサービスです。<br>App Engine：自動でスケールするウェブアプリケーションとモバイルバックエンドを開発、デプロイ、スケールするためのフルマネージドなサービスです。<br>正解についての説明：<br>（選択肢）<br>・Vertex AI Pipelines、Vertex AIによる予測、Vertex AI Model Monitoring<br>この選択肢が正解の理由は以下の通りです。<br>まず、Vertex AI Pipelinesは、一連のデータの前処理、モデルの訓練、モデルの検証といった機械学習ワークロードのパイプラインを作成・実行する機能を提供します。<br>また、パイプラインはスケジュール可能なので、定期的なモデルの再訓練を容易に実現できます。Dockerコンテナが利用可能であるため、カスタムコードやパッケージの実行も容易です。<br>次に、Vertex AI Predictionは、モデルをデプロイしてオンラインでの予測を行うためのサービスです。オートスケーリング機能が付属しているため、予測リクエストの負荷に応じてリソースが自動的に調整されます。これにより、効率的なリソース使用と高い可用性が実現されます。<br>最後に、Vertex AI Model Monitoringは、デプロイされた機械学習モデルのパフォーマンスと品質を継続的に監視する機能を提供します。これにより、予期しないパフォーマンス低下やドリフトを発見・対処する能力が得られます。<br>これらの理由から、上記の要件を満たすためには、Vertex AI Pipelines、Vertex AI Prediction、Vertex AI Model Monitoringの組み合わせが最適な選択です。<br>不正解の選択肢についての説明：<br>選択肢：Vertex AI Pipelines、App Engine<br>この選択肢が正しくない理由は以下の通りです。<br>App Engineはアプリケーションをホストし、自動的にスケールするためのPaaSであり、モデルの再トレーニングのスケジュールやオンライン予測要求の自動スケーリング、モニタリングをサポートするには適していません。<br>一方、Vertex AIによる予測とVertex AI Model Monitoringはモデルのデプロイ、自動スケーリング、モニタリングをサポートします。<br>選択肢：Cloud Composer、BigQuery ML、Vertex AIによる予測<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Composerはワークフローオーケストレーションに役立ちますが、スケジュールされたモデルの再トレーニングに対応したプロセスは提供しません。BigQuery MLはモデル作成と予測を支えますが、Dockerコンテナのサポートや自動スケーリング、モニタリングの機能はないため、要求内容を満たしません。これに対し正解の選択肢はこれら全てをカバーしています。<br>選択肢：Cloud Composer、カスタムコンテナによるVertex AIトレーニング、App Engine<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud ComposerとApp Engineはワークフローオーケストレーションとアプリケーションホスティングを行うためのサービスであり、スケジュールされたモデルの再トレーニングやモニタリングを本質的にサポートするものではありません。<br>それに対して、Vertex AI Pipelinesはモデルの再トレーニングのスケジューリングを、Vertex AIによる予測はオンライン予測リクエストの自動スケーリングを、Vertex AI Model Monitoringはモデルのモニタリングを本質的にサポートする機能を持っています。'>
<div class='choice'> Cloud Composer、カスタムコンテナによるVertex AIトレーニング、App Engine</div>
<div class='choice'> Vertex AI Pipelines、App Engine</div>
<div class='choice'> Vertex AI Pipelines、Vertex AIによる予測、Vertex AI Model Monitoring</div>
<div class='choice'> Cloud Composer、BigQuery ML、Vertex AIによる予測</div>
</div>

<div class='question' data-multiple='false' data-question='問題31<br>あなたはGoogle Kubernetes Engine上でKubeflow Pipelinesを開発しています。パイプラインの最初のステップは、BigQueryに対してクエリを発行することです。そのクエリの結果をパイプラインの次のステップの入力として使用する予定です。これを可能な限り簡単な方法で実現したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「GitHub上のKubeflow Pipelinesリポジトリを探します。BigQuery Query Componentを見つけ、そのコンポーネントのURLをコピーし、それを使用してコンポーネントをパイプラインにロードします。コンポーネントを使用して、BigQueryに対してクエリを実行します」です。<br>この問題では、Google Kubernetes Engine上でKubeflow Pipelinesを開発しており、そのパイプラインの最初のステップはBigQueryに対してクエリを発行するという設定です。そして、そのクエリの結果を次のステップの入力として利用することが求められています。問題となるのは、その方針を実現する方法を"可能な限り簡単に"見つけることです。選択肢からは公式のリポジトリを活用する方法、APIやライブラリを利用してスクリプトを記述する方法、または一旦結果を別テーブルに保存するという方法などが考えられます。選択肢と問題文の"可能な限り簡単に"という要求を照らし合わせながら、最も簡潔かつ効率的な手法を選ぶことが求められています。<br>基本的な概念や原則：<br>Google Kubernetes Engine（GKE）：Google Cloudが提供する完全マネージドのKubernetesサービスです。Kubernetesアプリケーションのデプロイ、スケーリング、管理を簡素化します。<br>Kubeflow Pipelines：機械学習ワークフローを構築、デプロイ、管理するためのプラットフォームで、Kubernetes上で動作します。<br>BigQuery：Google Cloudの高速でフルマネージドなビッグデータ分析サービスです。SQLクエリを使用して大量のデータをリアルタイムに分析することができます。<br>Kubeflow Pipelinesリポジトリ：Kubeflow Pipelinesのコードとドキュメンテーションが保存されているGitHubのリポジトリです。パイプライン構築のためのさまざまなコンポーネントが提供されています。<br>Kubeflow Pipelinesのコンポーネント：パイプラインの一部として機能する再利用可能な構造です。特定のステップを抽象化し、再利用と共有を容易にします。<br>BigQuery Query Component：BigQueryに対してクエリを実行するためのKubeflow Pipelinesコンポーネントです。クエリ結果をパイプラインの他のステップに渡すことができます。<br>BigQueryコンソール：BigQueryサービスを直接操作できるWebベースのインターフェースです。直接クエリを実行したり、データを視覚化することができます。<br>正解についての説明：<br>（選択肢）<br>・GitHub上のKubeflow Pipelinesリポジトリを探します。BigQuery Query Componentを見つけ、そのコンポーネントのURLをコピーし、それを使用してコンポーネントをパイプラインにロードします。コンポーネントを使用して、BigQueryに対してクエリを実行します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Kubeflow Pipelinesは、Google Kubernetes Engineと共に使うことによって、分散型の機械学習ワークロードを自動化し、再現性のあるパイプラインを構築できるよう設計されています。これらのパイプラインの作成と管理を支援するために、Kubeflow Pipelinesは多くの既製のコンポーネントを提供しています。<br>次に、このパイプラインの一部としてBigQueryからのデータフェッチというニーズに関しては、すでに用意されているBigQuery Query Componentを活用することで、簡単に実現できます。このコンポーネントはGitHub上のKubeflow Pipelinesリポジトリから見つけて使用可能で、このコンポーネントのURLをコピーすることで、パイプライン内でその機能を利用できます。<br>最後に、BigQuery Query Componentの使用により、必要なクエリを実行し、その結果を次のパイプラインステップに渡すといった事が簡単に実現できます。<br>したがって、これにより問題の要件を簡単に満たすことが出来ます。<br>不正解の選択肢についての説明：<br>選択肢：BigQueryコンソールを使用してクエリを実行し、クエリ結果を新しいBigQueryテーブルに保存します<br>この選択肢が正しくない理由は以下の通りです。<br>要件はKubeflow Pipelines内で直接BigQueryをクエリすることですが、BigQueryコンソールを使用するとなると、パイプラインから外れ、手動で操作する必要が生じてしまいます。<br>また、結果を新しいテーブルに保存すると、次のステップでそのデータを参照するための追加の操作が必要になります。これは要求されている"可能な限り簡単な方法"からは程遠い対応となってしまいます。<br>選択肢：BigQuery APIを使用してBigQueryに対してクエリを実行するPythonスクリプトを記述します。このスクリプトをKubeflow Pipelinesの最初のステップとして実行します<br>この選択肢が正しくない理由は以下の通りです。<br>BigQuery APIを使用してPythonスクリプトを記述する選択肢はより手間がかかり、実現性的にも複雑です。<br>一方、Kubeflow Pipelinesにすでに存在するBigQuery Query Componentを使用することで、簡単かつ効率的に要件を満たすことができます。<br>選択肢：Kubeflow Pipelinesドメイン固有言語を使用して、Python BigQueryクライアントライブラリを使用してクエリを実行するカスタムコンポーネントを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>カスタムコンポーネントを作成することは可能ですが、既存のBigQuery Query Componentを使用する方が要求を満たすための"可能な限り簡単な方法"です。カスタムコンポーネントを作成すると、実装とメンテナンスにより多くのリソースが必要になるため、このケースでは適切ではありません。'>
<div class='choice'> BigQueryコンソールを使用してクエリを実行し、クエリ結果を新しいBigQueryテーブルに保存します</div>
<div class='choice'> BigQuery APIを使用してBigQueryに対してクエリを実行するPythonスクリプトを記述します。このスクリプトをKubeflow Pipelinesの最初のステップとして実行します</div>
<div class='choice'> GitHub上のKubeflow Pipelinesリポジトリを探します。BigQuery Query Componentを見つけ、そのコンポーネントのURLをコピーし、それを使用してコンポーネントをパイプラインにロードします。コンポーネントを使用して、BigQueryに対してクエリを実行します</div>
<div class='choice'> Kubeflow Pipelinesドメイン固有言語を使用して、Python BigQueryクライアントライブラリを使用してクエリを実行するカスタムコンポーネントを作成します</div>
</div>

<div class='question' data-multiple='false' data-question='問題32<br>あなたは旅行会社のMLエンジニアです。あなたは長年顧客の旅行行動を研究し、顧客の休暇パターンを予測するモデルを導入してきました。あなたは、顧客の休暇先が季節性と休日に基づいて変化することを観察しました。あなたは、モデルのバージョンとパフォーマンスの統計情報を迅速かつ容易に保存し、年度間で比較したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「Vertex ML Metadataのイベントとして季節と年を使用し、モデルの各バージョンのパフォーマンス統計を保存します。スライス間で結果を比較します」です。<br>この問題では、旅行会社のMLエンジニアとして、季節性と休日に基づいて変化する顧客の休暇パターン予測モデルのバージョンとパフォーマンス統計情報を保存し、横断的に評価するための方法を問われています。問題はGoogle Cloudのサービスを使って、モデルのパフォーマンス統計を効率よく保存し、異なる時期・モデル間で比較できる解決策を求めています。それぞれの選択肢が提案する解決策の適切さを、要件に即した形で理解し評価する必要があります。問題文からも分かるように、特に季節性と年度間の比較を容易に行うソリューションが重要です。<br>基本的な概念や原則：<br>Vertex ML Metadata：機械学習ワークフローのメタデータを管理するGoogle Cloudのツールです。学習ジョブの実行履歴やモデルのバージョン管理など、機械学習ワークフローに関する重要な情報を追跡、分析、可視化することができます。<br>予測モデルのパフォーマンス統計：機械学習モデルの予測性能を評価するための数値です。モデルの精度、再現性、適合性などの指標を含みます。<br>モデルバージョニング：機械学習モデルの異なるバージョンを保存し、過去のバージョンと比較することができる概念です。これにより、モデルのパフォーマンスが時間とともにどのように変化するかを理解することができます。<br>Cloud SQL：フルマネージドで高耐久性のリレーショナルデータベースサービスです。しかし、機械学習モデルのパフォーマンス統計を保存する用途には必ずしも適していない可能性があります。<br>Vertex AI：モデルを作成、訓練、デプロイするための統合されたアイドロネーション環境です。しかし、異なるバージョンのモデルのパフォーマンスを比較する機能は限定的です。<br>Kubeflow：機械学習ワークフローを簡易化するためのオープンソースツールキットです。Kubeflow自体は機械学習のパイプラインを作成、実行することが可能ですが、モデルのパフォーマンス統計を保存し、比較する機能までは提供していません。<br>正解についての説明：<br>（選択肢）<br>・Vertex ML Metadataのイベントとして季節と年を使用し、モデルの各バージョンのパフォーマンス統計を保存します。スライス間で結果を比較します<br>この選択肢が正解の理由は以下の通りです。<br>Google CloudのVertex AIは各種のデータを管理し、学習したモデルのパフォーマンスを追跡する能力を持つ機能で、これにはVertex ML Metadataが含まれます。これにより、重要な情報（ここでは季節と年）をイベントとして追加し、モデルの複数のバージョンでの学習結果（パフォーマンス統計）をストアできます。<br>また、モデル間で結果を比較する機能も提供しています。<br>したがって、季節性と休日に基づいて顧客の休暇先が変化するといった事業の要件に対応するために、Vertex ML Metadataがイベントとして季節と年を使用し、モデルの各バージョンのパフォーマンス統計を保存することは優れた選択肢であると言えます。これにより、各バージョンの精度を比較し、時間とともにパフォーマンスがどのように変化したかを理解することが可能になります。これは、長年にわたる顧客旅行行動の研究により最適化を図る旅行会社のMLエンジニアにとって、非常に有用で強力なツールです。<br>不正解の選択肢についての説明：<br>選択肢：パフォーマンス統計をCloud SQLに保存します。そのデータベースをクエリして、モデルのバージョン間でパフォーマンス統計を比較します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud SQLでは、パフォーマンスの統計情報に特化した機能が提供されておらず、MLのモデルバージョン間のパフォーマンス統計の比較には不適切です。<br>一方、Vertex ML Metadataは、モデルのバージョンやパフォーマンス統計を管理するための特化した機能を提供しているため、より適切です。<br>選択肢：Vertex AIで各シーズンのモデルを作成します。Vertex AI UIのEvaluateタブでモデル間のパフォーマンス統計を比較します<br>この選択肢が正しくない理由は以下の通りです。<br>Vertex AIでは各シーズンごとにモデルを作成するというアプローチは、モデルのバージョン管理やパフォーマンスの比較が非効率的です。<br>また、長期間にわたるパフォーマンス統計の保存や簡単な比較はVertex AI UIだけでは困難です。<br>それに対し、Vertex ML Metadataを利用すればパフォーマンス統計を簡単に保存し比較することができます。<br>選択肢：Kubeflowで実行される各パイプラインのパフォーマンス統計を、年間各季節の実験の下に保存します。Kubeflow UIで実験全体の結果を比較します<br>この選択肢が正しくない理由は以下の通りです。<br>Kubeflowを使用したパフォーマンス統計の保存はそれ自体が有効な方法ですが、Vertex ML Metadataと比べて、より簡単に統計情報を保存し、分析する機能が提供されていません。<br>また、実験の結果を比較する機能も限定的です。よって、要件を最も効率よく満たすのはVertex ML Metadataを使用する方法です。'>
<div class='choice'> Vertex AIで各シーズンのモデルを作成します。Vertex AI UIのEvaluateタブでモデル間のパフォーマンス統計を比較します</div>
<div class='choice'> Vertex ML Metadataのイベントとして季節と年を使用し、モデルの各バージョンのパフォーマンス統計を保存します。スライス間で結果を比較します</div>
<div class='choice'> パフォーマンス統計をCloud SQLに保存します。そのデータベースをクエリして、モデルのバージョン間でパフォーマンス統計を比較します</div>
<div class='choice'> Kubeflowで実行される各パイプラインのパフォーマンス統計を、年間各季節の実験の下に保存します。Kubeflow UIで実験全体の結果を比較します</div>
</div>

<div class='question' data-multiple='false' data-question='問題33<br>あなたはカスタムライブラリを必要とするKubeflow Pipelineのユニットテストを書きました。Cloud Source Repositoriesの開発ブランチへの新しいプッシュごとにユニットテストの実行を自動化したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「Cloud Buildを使用して、変更が開発ブランチにプッシュされたときにユニットテストを実行する自動トリガーを設定します」です。<br>この問題では、Kubeflow Pipelineのユニットテストを書き、それをCloud Source Repositoriesの開発ブランチへの新しいプッシュ毎に自動的に実行する方法について問われています。ユニットテストを自動化したいという要件から、ソースリポジトリへのプッシュをトリガーとしてユニットテストが実行される仕組みを考える必要があります。また、カスタムライブラリを必要とすることから、テスト実行環境がそのライブラリを含むこと、またはインストールできることも重要になります。これを実現するにはGoogle Cloudのどのサービスが最適か、その中のどの機能が適しているかを選ぶことが課題です。<br>基本的な概念や原則：<br>Cloud Build：Google Cloudの継続的インテグレーションとデリバリー（CI/CD）プラットフォームです。コード変更のトリガーによるユニットテストの自動実行やビルドの自動化が可能です。<br>Kubeflow：機械学習ワークロードを簡素化するためのKubernetesベースのプラットフォームです。パイプラインを使用すると、様々なワークフローを一貫した方法で実行できます。<br>Cloud Source Repositories：Google CloudのプライベートGitリポジトリです。コードとその履歴を安全に保存できます。開発ブランチへのプッシュをトリガーに、自動的なアクションを設定することができます。<br>Cloud Run：完全マネージドのサーバレスプラットフォームで、コンテナイメージからアプリケーションを直接デプロイできます。ただし、プッシュ時の自動テスト実行という要件を満たすためには、Cloud BuildのようなCI/CDツールを使う方が適しています。<br>Cloud Logging：Google Cloudのログ管理サービスです。しかし、ログを標準出力に流すだけでは、適切なユニットテストを実行できません。<br>Cloud Functions：イベント駆動型のサーバレスコンピューティングソリューションで、Google Cloudが発生したイベントをトリガーにコードを自動で実行できます。しかし、ユニットテストの実行にはCloud Buildを選択する方が適切です。<br>正解についての説明：<br>（選択肢）<br>・Cloud Buildを使用して、変更が開発ブランチにプッシュされたときにユニットテストを実行する自動トリガーを設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Cloud Buildを使用することで、ソースコードの変更に応じて自動的にテストやビルドを行うことができます。特に、Cloud Buildではトリガーの設定で特定のブランチへのプッシュを検知することができます。これにより、開発ブランチに新しい変更がプッシュされたときにユニットテストを自動的に実行することができます。<br>また、Cloud Buildはカスタムビルドステップを使用して、特定のライブラリを必要とする環境でテストを実行することも可能です。これは、Kubeflow Pipelineのユニットテストにカスタムライブラリが必要という要件を満たします。このような機能により、Cloud Buildを使用することで要件を満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：開発ブランチへのプッシュを順次実行し、Cloud Runでユニットテストを実行するスクリプトを記述します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Runは一連のタスクを実行するためのサービスであり、ユニットテストを自動的にトリガーする機能はありません。<br>一方、Cloud Buildは自動トリガーを設定して変更に対応するため、要件を満たすのに適しています。<br>選択肢：Cloud Source RepositoriesとのインタラクションをキャプチャするPub/SubトピックにCloud Loggingシンクを設定します。Cloud Run用のPub/Subトリガーを設定し、Cloud Run上でユニットテストを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud LoggingシンクとPub/Subトリガーはリアルタイムのデータ処理に便利ですが、コードの変更があった際のユニットテストの自動実行にはCloud Buildが適しています。Cloud Buildはリポジトリの変更に基づいて自動的にトリガーしてくれるため、より直接的かつ簡単な解決策です。<br>選択肢：Cloud Source RepositoriesとのインタラクションをキャプチャするPub/SubトピックにCloud Loggingシンクをセットアップします。Pub/Subトピックにメッセージが送信されたときにトリガーされるCloud Functionsを使用してユニットテストを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud LoggingシンクとPub/Subトピックを使用してユニットテストをトリガーする方法は技術的に可能ですが、設定が複雑で手間がかかります。<br>それに対して、Cloud Buildはコード変更に対し自動的にビルドとテストを実行する機能を提供しており、要件を満たす最も簡単で効率的な方法です。'>
<div class='choice'> Cloud Buildを使用して、変更が開発ブランチにプッシュされたときにユニットテストを実行する自動トリガーを設定します</div>
<div class='choice'> 開発ブランチへのプッシュを順次実行し、Cloud Runでユニットテストを実行するスクリプトを記述します</div>
<div class='choice'> Cloud Source RepositoriesとのインタラクションをキャプチャするPub/SubトピックにCloud Loggingシンクを設定します。Cloud Run用のPub/Subトリガーを設定し、Cloud Run上でユニットテストを実行します</div>
<div class='choice'> Cloud Source RepositoriesとのインタラクションをキャプチャするPub/SubトピックにCloud Loggingシンクをセットアップします。Pub/Subトピックにメッセージが送信されたときにトリガーされるCloud Functionsを使用してユニットテストを実行します</div>
</div>


            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>