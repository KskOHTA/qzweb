<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Professional Machine Learning Engneer問題集 01</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">


<div class='question' data-multiple='false' data-question='問題1<br>あなたは、カスタマーサポートのメールを分類するモデルを開発しています。TensorFlow Estimatorsを使用して、オンプレミスシステム上の小規模なデータセットを使用してモデルを作成しましたが、高いパフォーマンスを確保するために、大規模なデータセットを使用してモデルをトレーニングする必要があります。モデルをGoogle Cloudに移植する予定ですが、オンプレミスからクラウドへの移行を容易にするために、コードのリファクタリングとインフラのオーバーヘッドを最小限に抑えたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「分散トレーニングにAI Platformを使用します」です。<br>この問題では、モデルの大規模な訓練データを高性能で処理しつつ、同時にオンプレミスからクラウドへの移行を可能な限り容易にするソリューションを選ぶことが求められています。そのためには、選択肢を評価する際にオーバーヘッドの少なさ、コードのリファクタリングの必要性、大規模なデータセットへの対応力、ならびに分散処理の可否を考慮する必要があります。<br>基本的な概念や原則：<br>AI Platform：Google Cloudのマネージドサービスで、機械学習モデルのトレーニングとデプロイを一元管理します。特に大規模なデータセットでのトレーニングに対応しており、オンプレミスからの移行を容易にします。<br>TensorFlow Estimators：TensorFlowに組み込まれた高レベルの機械学習APIです。独自のモデルを作成したり、既存のモデルを修正したりするためのフレームワークを提供します。<br>Dataproc：Google Cloudのフルマネージドクラウドベースのビッグデータ分析サービスです。Apache SparkとApache Hadoopエコシステムをサポートしていますが、AIのモデルトレーニングへの直接の対応はありません。<br>マネージドインスタンスグループ：Compute Engine上のインスタンスの自動スケーリングと管理を行うサービスです。MLモデルのトレーニングへの直接の対応はありません。<br>Kubeflow Pipelines：機械学習のワークフローを管理するためのツールです。Google Kubernetes Engine（GKE）上で動作しますが、必ずしも最小限のリファクタリングとインフラオーバーヘッドで移行できるわけではありません。<br>正解についての説明：<br>（選択肢）<br>・分散トレーニングにAI Platformを使用します<br>この選択肢が正解の理由は以下の通りです。<br>まず、AI Platformは、分散学習を行う上で非常に有用なサービスであり、大規模なデータセットに対して高いパフォーマンスを発揮します。そのため、オンプレミスで小規模なデータセットでトレーニングしていたモデルを、大規模なデータセットに対してトレーニングするためには、このAI Platformを使用することが最適な解答です。<br>また、コードのリファクタリングやインフラのオーバーヘッドを最小限に抑える要件についてもAI Platformは適合します。AI PlatformはTensorFlow Estimatorsと直接統合されており、既存のTensorFlow Estimatorモデルをそのまま移植することができます。この直接的な互換性があるため、コードの大規模な変更なしにオンプレミスのシステムからクラウドへと移行することが可能になります。<br>さらに、AI Platformは完全マネージドなサービスであり、インフラストラクチャの管理にかかるオーバーヘッドを大きく減らすことができます。<br>不正解の選択肢についての説明：<br>選択肢：トレーニング用にDataproc上にクラスターを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>DataprocはHadoopやSparkなどの大量データを用いたバッチ処理を行うサービスで、TensorFlow Estimatorsのモデルトレーニングとは目的が異なります。<br>それに対して、AI PlatformはTensorFlowや他の機械学習フレームワークのモデルをトレーニングするためのGoogle Cloudの管理型サービスであり、インフラの管理を最小限に抑えてコードのリファクタリングを容易にします。<br>選択肢：オートスケーリング機能付きのマネージドインスタンスグループを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>オートスケーリング機能付きのマネージドインスタンスグループを作成するとはいえ、その後の環境設定やメンテナンスが容易でないため、インフラのオーバーヘッドを最小限に抑える目的には適していません。<br>それに対して、AI Platformはモデルのトレーニングとデプロイを容易に行え、オーバーヘッドも抑えられます。<br>選択肢：Kubeflow Pipelinesを使用して、Google Kubernetes Engineクラスターでトレーニングを行います<br>この選択肢が正しくない理由は以下の通りです。<br>Kubeflow Pipelinesを用いてGoogle Kubernetes Engineクラスターでトレーニングを行う方法は移植性が高く、複雑なワークフローを扱うことができますが、設問の要件である"コードのリファクタリングとインフラのオーバーヘッドを最小限に抑えること"を実現するためには不適切です。<br>それに対し、AI PlatformはTensorFlow Estimatorsを直接受け入れ、分散トレーニングを容易に行うことができ、そのためのコードの変更や、インフラ管理の必要性がほとんどありません。'>
<div class='choice'> Kubeflow Pipelinesを使用して、Google Kubernetes Engineクラスターでトレーニングを行います</div>
<div class='choice'> オートスケーリング機能付きのマネージドインスタンスグループを作成します</div>
<div class='choice'> 分散トレーニングにAI Platformを使用します</div>
<div class='choice'> トレーニング用にDataproc上にクラスターを作成します</div>
</div>

<div class='question' data-multiple='false' data-question='問題2<br>あなたは毎日の気温を予測するモデルを構築しています。データをランダムに分割し、トレーニングデータセットとテストデータセットを変換します。モデル学習用の気温データは毎時アップロードされます。テスト中、あなたのモデルは97%の精度で動作しました。しかし、本番環境にデプロイした後、モデルの精度は66%に低下しました。<br>本番モデルの精度を上げるにはどうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「リークを避けるために、ランダムな分割ではなく、時間に基づいてトレーニングデータとテストデータを分割します」です。<br>この問題では、機械学習モデルの精度がトレーニング中と本番環境で異なる理由と、それをどのように解決するかを理解する必要があります。モデルの精度が低下した理由を探って問題を解決をするのが求められます。本番モデルの精度がトレーニング時と比べて低下する一因として、データの時間的な流れを無視したランダムなデータ分割が考えられます。選択肢を選ぶ際には、その原因を解消しそうなものを選ぶ必要があります。<br>基本的な概念や原則：<br>データリーク：モデル訓練中にテストデータが間接的に使用されてしまい、モデルの評価が正確でなくなる問題です。これは真の汎化能力を過大評価してしまうため、避けるべきです。<br>データ分割：データを訓練用、検証用、テスト用に分割するプロセスです。これによりモデルが一部のデータに過剰に最適化してしまう（過学習）ことを防ぎます。<br>時間に基づくデータ分割：時間系列データを扱う際に用いられるデータ分割の方法です。ランダムな分割ではなく、特定の時間を境に分割を行うことで、未来のデータへのリークを防ぎます。<br>モデル評価：モデルがどれだけ予測性能があるかを評価するプロセスです。検証データセットやテストデータセットを使って行います。<br>正規化：データの範囲を一定の範囲に収めるために行う処理です。主にモデルの学習を安定させる目的で行われます。データセット間で異なる正規化を適用すると、予測性能が低下する恐れがあります。<br>交差検証：モデル評価の一手法で、データを複数のグループに分けて繰り返し学習と評価を行います。モデルの汎化能力の評価に有用です。<br>正解についての説明：<br>（選択肢）<br>・リークを避けるために、ランダムな分割ではなく、時間に基づいてトレーニングデータとテストデータを分割します<br>この選択肢が正解の理由は以下の通りです。<br>まず、気温予測のような時系列データでモデルを作成する場合、データのランダムな分割には問題があります。その理由は、未来のデータが過去のデータのトレーニングで用いられ、モデルに未来の情報がリークしてしまい、過剰に最適化されてしまうためです。これは時間に依存性があるデータの特性上、避けられない問題です。<br>したがって、時間に基づいてトレーニングデータとテストデータを分割するというのは理にかなっています。これにより、モデルは過去のデータから未来のデータを効果的に予測する能力を身に付けることができます。モデルの性能は、訓練データとテストデータの分割方法に大きく依存していることを覚えておくことが重要です。ですから、時間に基づいてデータを分割することで、本番環境におけるモデルの精度は上がるでしょう。<br>不正解の選択肢についての説明：<br>選択肢：トレーニングデータセットとテストデータセットのデータを、2つの別々のステップとして正規化します<br>この選択肢が正しくない理由は以下の通りです。<br>トレーニングデータセットとテストデータセットを2つの別々のステップで正規化すると、実際にはデータが異なる分布を持つ可能性があり、これがモデルの性能にネガティブな影響を与えます。<br>一方、時間に基づいてデータを分割すると、時間の経過とともに変化するデータの傾向を反映することができ、これがモデルの本番環境での性能向上に寄与します。<br>選択肢：テストセットにさらにデータを追加して、テスト用のサンプルを公平に配布できるようにします<br>この選択肢が正しくない理由は以下の通りです。<br>テストセットに更なるデータを追加しても、精度の低下が改善するわけではありません。問題は訓練とテストのデータ分割がランダムであるため、時間の流れに従ったパターンを学べていない点です。そのため、時間に基づいてデータを分割するべきです。<br>選択肢：分割する前にデータ変換を適用し、変換がトレーニングセットとテストセットの両方に適用されていることを確認するために交差検証を行います<br>この選択肢が正しくない理由は以下の通りです。<br>時間に基づいてデータがアップロードされているため、ランダムな分割では過去のデータから未来のデータを予測するかのような状況をうまくシミュレートできなりません。<br>一方、正解選択肢では時間軸に沿ってデータを分割することで、この問題を解決しています。'>
<div class='choice'> 分割する前にデータ変換を適用し、変換がトレーニングセットとテストセットの両方に適用されていることを確認するために交差検証を行います</div>
<div class='choice'> トレーニングデータセットとテストデータセットのデータを、2つの別々のステップとして正規化します</div>
<div class='choice'> テストセットにさらにデータを追加して、テスト用のサンプルを公平に配布できるようにします</div>
<div class='choice'> リークを避けるために、ランダムな分割ではなく、時間に基づいてトレーニングデータとテストデータを分割します</div>
</div>

<div class='question' data-multiple='false' data-question='問題3<br>あなたは、ソーシャルメディア上のスパム投稿にフラグを立て、非表示にするアンチスパムサービスを提供する会社に勤めています。あなたの会社は現在、スパムの疑いのある投稿を特定するために20万個のキーワードのリストを使用しています。投稿にこれらのキーワードが数個以上含まれている場合、その投稿はスパムとして識別されます。機械学習を使ってスパム投稿にフラグを立て、人間によるレビューを受けさせたいと考えています。<br>このビジネスケースで機械学習を導入する主な利点は何ですか？' data-answer='3' data-explanation='解説<br>正解は「スパム投稿で新たな問題のあるフレーズが特定することができます」です。<br>この問題では、現在のアプローチと導入を検討している新技術（機械学習）の比較を元に、主要な利点を探す必要があります。注目すべき点は、キーワードリストを用いた過去の方法と異なり、機械学習を用いることで新しいフレーズやパターンの発見が可能になることです。選択肢を検討する際、より効率的な方法だけでなく、新しい能力や可能性をもたらすものを重視すべきです。<br>基本的な概念や原則：<br>機械学習：アルゴリズムや統計学的モデルを使用して、人間の介入なしに特定のタスクを改善するコンピューターシステムです。未知のデータや状況に対する予測力と柔軟性が特徴です。<br>スパム検出：機械学習が特に有用とされる領域の1つです。定義を超えた新たなパターンやフレーズを識別して、スパム対策を進化させることができます。<br>キーワードリスト：あらかじめ定義されたフレーズや語句のリストです。一般的には、機械学習アルゴリズムだけではなく、ルールベースのシステムでも使用されます。一方、分析対象となるデータの内容がキーワードリストの範囲を超える場合、その効果は制限されます。<br>人間によるレビュー：機械が完全に信頼できない場合や最終的な確認を必要とするタスクに使用されます。機械学習の恩恵により、人間が行うべきタスクの集中度や精度を向上させることができます。<br>正解についての説明：<br>（選択肢）<br>・スパム投稿で新たな問題のあるフレーズが特定することができます<br>この選択肢が正解の理由は以下の通りです。<br>機械学習は、人間が明示的にプログラムしなくても、データから自動的にパターンやルールを学習する能力を持っています。<br>従って、インプットされるデータに基づいて新たなスパム投稿のパターンや問題のあるフレーズを特定することができます。現行のシステムでは、スパム判定の基準となるキーワードを人間がリスト化しているので、新たなスパムパターンが生まれても迅速に対応するのが困難となる可能性があります。<br>一方、機械学習を導入することで、これらの新たなパターンを自動で検知し、逐次システムを改善することが可能になります。これにより、スパム対策の効率と効果性を大幅に向上させることができます。<br>不正解の選択肢についての説明：<br>選択肢：投稿をキーワードリストとより迅速に比較できます<br>この選択肢が正しくない理由は以下の通りです。<br>キーワードリストとの早い比較は機械学習の利点ではありますが、これは既存のキーワード検索でも達成できます。機械学習の真の利点は新たな問題のあるフレーズを特定できる点であり、この能力がスパム対策の可能性を広げてくれます。<br>選択肢：スパム投稿にフラグを立てるために、はるかに長いキーワードリストを使用できます<br>この選択肢が正しくない理由は以下の通りです。<br>機械学習を導入する主な目的は、単に長いキーワードリストを使用することではなく、新たな問題を特定し、未知のパターンを抽出する能力にあります。<br>したがって、選択肢は機械学習のメリットとは異なります。機械学習はそれ自体で新たな問題のあるフレーズを抽出する能力を持ち、新たなキーワードリストを作成する必要がなりません。<br>選択肢：スパム投稿には、はるかに少ないキーワードでフラグを立てることができます<br>この選択肢が正しくない理由は以下の通りです。<br>機械学習を導入する目的はキーワードの数を減らすことではなく、新たなスパム攻撃のパターンを検出し、それらを識別することです。キーワードの数を減らすと、スパム攻撃の検出が不十分になる可能性があります。そのため、新たな問題のあるフレーズを特定する能力が機械学習の主な利点です。'>
<div class='choice'> スパム投稿にフラグを立てるために、はるかに長いキーワードリストを使用できます</div>
<div class='choice'> 投稿をキーワードリストとより迅速に比較できます</div>
<div class='choice'> スパム投稿には、はるかに少ないキーワードでフラグを立てることができます</div>
<div class='choice'> スパム投稿で新たな問題のあるフレーズが特定することができます</div>
</div>

<div class='question' data-multiple='false' data-question='問題4<br>カスタムTensorFlow DNN回帰モデルを使用して、BigQueryテーブルの1億レコードに対してバッチ予測を実行し、予測結果をBigQueryテーブルに格納する必要があります。この推論パイプラインの構築に必要な労力を最小限に抑えたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「BigQuery MLでTensorFlowモデルをインポートし、ml.predict関数を実行します」です。<br>この問題では、大量のデータに対してTensorFlowで予測を行い、その結果をBigQueryに格納する作業を効率的に行う方法を考えています。要件に重視されているのは"労力の最小限化"であり、つまり、必要な作業量（コーディング、設定など）を最小限に抑えることが求められています。そのため、一連の作業をシンプルに連携でき、かつバッチ処理が可能なサービスあるいはサービスの組み合わせを選択することが重要です。選択肢の中からデータ読み込みから結果の書き込みまでを効率的に行える最適なサービスを見つけることが問題解決の鍵です。<br>基本的な概念や原則：<br>BigQuery：Google Cloudのフルマネージド、サーバレスのスケーラブルなデータウェアハウスです。SQLを用いて大量のデータを迅速に分析できます。<br>TensorFlow：Googleが開発したオープンソースのディープラーニングフレームワークです。ニューラルネットワークの設計と学習を容易にします。<br>BigQuery ML：BigQuery内部で機械学習モデルを作成、学習、および予測を行うことができる機能です。TensorFlowモデルをBigQuery MLに直接インポートしてml.predict関数を通じて予測を行うことができます。<br>TFRecords：TensorFlowで使用できるデータ形式であり、TensorFlowのデータパイプラインのパフォーマンスを最適化するために設計されています。<br>Dataflow：Google Cloudのフルマネージドなデータ処理サービスです。並行処理分析に最適化された遅延性とスケーラビリティを持つストリームとバッチ処理を提供します。<br>Vertex AI：Google Cloudの統一されたプラットフォームであり、機械学習モデルの作成からデプロイまでのワークフローを単一のフレームワーク内で統合して管理できます。<br>SavedModel：TensorFlowで使用するモデルの永続的なシリアライゼーション形式で、モデルの構造とパラメータを含みます。<br>正解についての説明：<br>（選択肢）<br>・BigQuery MLでTensorFlowモデルをインポートし、ml.predict関数を実行します<br>この選択肢が正解の理由は以下の通りです。<br>まず、BigQuery MLはBigQueryテーブルのデータに直接機械学習モデルを適用することができるツールで、複雑なデータ準備とモデルトレーニングプロセスを大幅に簡略化することができます。TensorFlowモデルをインポートする機能は、BigQuery MLが提供する機能の一部であり、この機能を使用することでカスタムTensorFlowモデルを素早く簡単にBigQuery MLに導入することができます。<br>次に、ml.predict関数はBigQuery MLが提供する関数で、予測を生成するために使用されます。これにより、大量のデータセットに対して容易に予測を実行し、結果をBigQueryテーブルに保存することが可能になります。<br>最後に、これらの手段を利用することにより、推論パイプラインの構築に必要な労力を大幅に軽減できるため、この選択肢が最適な解答です。<br>不正解の選択肢についての説明：<br>選択肢：TensorFlow BigQueryリーダーを使ってデータを読み込み、BigQuery APIを使って結果をBigQueryに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>TensorFlow BigQueryリーダーとBigQuery APIを使用すると、データの読み込みと書き込みに関して手動で操作を行う必要があり、推論パイプラインの構築に必要な労力を最小限に抑えるという要件を満たす方法ではありません。<br>一方、BigQuery MLではTensorFlowモデルを直接インポートし、ml.predict関数を使うことで自動的に予測を実行できます。<br>選択肢：BigQueryのデータをTFRecordsに変換するDataflowパイプラインを作成します。Vertex AI Predictionでバッチ推論を実行し、結果をBigQueryに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>確かにDataflowとVertex AIを使う方法でもバッチ予測は可能ですが、この方法はBigQuery MLを用いる方法と比較すると設定や管理の労力が大きくなります。そのため、"労力を最小限に抑えたい"という要件を満たせていません。<br>選択肢：TensorFlowのSavedModelをDataflowパイプラインにロードします。パイプライン内で推論を実行するカスタム関数でBigQuery I/Oコネクタを使用し、結果をBigQueryに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>TensorFlowのSavedModelをDataflowパイプラインにロードして推論を実行し、BigQuery I/Oコネクタを使用して結果を書き込む手法は、実装の労力が大きいからです。<br>対照的に、BigQuery MLを使用してTensorFlowモデルをインポートし、ml.predict関数を実行すると推論と格納が一度に行われ、労力を最小限に抑えられます。'>
<div class='choice'> BigQuery MLでTensorFlowモデルをインポートし、ml.predict関数を実行します</div>
<div class='choice'> TensorFlowのSavedModelをDataflowパイプラインにロードします。パイプライン内で推論を実行するカスタム関数でBigQuery I/Oコネクタを使用し、結果をBigQueryに書き込みます</div>
<div class='choice'> BigQueryのデータをTFRecordsに変換するDataflowパイプラインを作成します。Vertex AI Predictionでバッチ推論を実行し、結果をBigQueryに書き込みます</div>
<div class='choice'> TensorFlow BigQueryリーダーを使ってデータを読み込み、BigQuery APIを使って結果をBigQueryに書き込みます</div>
</div>

<div class='question' data-multiple='false' data-question='問題5<br>あなたは小売企業のリードMLエンジニアです。あなたは、MLのメタデータを一元的に追跡・管理し、チームが成果物を生成して再現可能な実験を行えるようにしたいと考えています。<br>どの管理ソリューションをチームに勧めるべきですか？' data-answer='3' data-explanation='解説<br>正解は「Vertex MLメタデータでMLワークフローを管理します」です。<br>この問題では、ML（機械学習）のメタデータを追跡・管理し、再現可能な実験を行えるようにするソリューションを選びます。この選択肢を選ぶ際には、メタデータ管理に特化したツールで、かつ、MLの実験過程や成果物を視覚的に追跡管理できる機能を提供しているかどうかを重視することが求められています。また、MLメタデータを一元的に管理する要件から、分散管理ではなく一元管理が可能なソリューションを選ぶことが重要であると考えられます。<br>基本的な概念や原則：<br>Vertex MLメタデータ：Google Cloud上でMLのメタデータを一元管理するサービスです。ワークフローの追跡や管理を可能にし、再現可能な実験のための成果物生成を支援します。<br>tf.logging：TensorFlowライブラリの一部であり、トレーニングや推論の際のログ情報を出力します。詳細なデバッグ情報が提供されますが、一元的なメタデータ管理はサポートしていません。<br>BigQuery：Google Cloudのフルマネージド、伸縮性のあるエンタープライズ向けデータウェアハウスです。大量のデータを高速に分析するためのSQLクエリをサポートしていますが、直接的なMLメタデータ管理はサポートしていません。<br>ハイブメタストア：Apache Hive用のデータベースメタデータリポジトリであり、Hadoopエコシステム内のデータベーススキーマとテーブルの構造を保存します。MLメタデータの専用管理には対応していません。<br>Google Cloud Operations Suite：Google Cloudリソースの監視、デバッグ、診断のためのソフトウェアスイートです。その中でもGoogle Cloud Loggingはログデータの分析とアラートを行うことができますが、MLのメタデータ管理には適していません。<br>正解についての説明：<br>（選択肢）<br>・Vertex MLメタデータでMLワークフローを管理します<br>この選択肢が正解の理由は以下の通りです。<br>Vertex AIのMLメタデータ管理機能は、機械学習ワークフロー全体でのメタデータの一元的な追跡・管理を可能にします。これは、データセット、モデル、メトリクス、ハイパーパラメータ、実験結果などの各種エンティティ及びエンティティ間の関係性に対するメタデータを指します。具体的には、Vertex MLメタデータは、アーティファクトと実行の間の名前付きエッジで結ばれたグラフとしてMLワークフローを表現します。これにより、チームは結果の再現性を保証しつつ、生成物とワークフローを追跡・管理できます。過去の実験について詳細な情報を取得することで、改善のヒントを得ることや問題のトラブルシューティングが容易になります。<br>したがって、Vertex MLメタデータでMLワークフローを管理することは、効率的かつ組織的なML資産管理を実現する強力な手段です。<br>不正解の選択肢についての説明：<br>選択肢：tf.loggingのデータをBigQueryに保存します<br>この選択肢が正しくない理由は以下の通りです。<br>tf.loggingのデータをBigQueryに保存すると、MLのメタデータを一元的に追跡・管理できますが、実験の再現可能性の管理はサポートしていません。<br>一方、Vertex MLメタデータはメタデータの管理だけでなく、成果物生成や実験再現性のトラッキングもサポートしています。<br>選択肢：ハイブメタストアのすべてのリレーショナルエンティティを管理します<br>この選択肢が正しくない理由は以下の通りです。<br>ハイブメタストアは大規模なデータセットを管理し、クエリ実行を行うものであり、MLのメタデータの追跡や管理には向いていません。そのため、MLの再現可能性や追跡を向上させる目的には不適切です。<br>一方、Vertex MLメタデータはこれらの機能を提供し、MLワークフローの管理に適したサービスです。<br>選択肢：すべてのMLメタデータをGoogle Cloud Operations Suiteに保存します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloud Operations Suiteは、アプリケーションやインフラストラクチャのパフォーマンス監視、トラブルシューティング、デバッグを支援するためのものであり、MLのメタデータ管理に専門的な機能を提供するものではありません。<br>一方、Vertex MLメタデータは、MLワークフローを管理するための専用サービスであり、メタデータの一元管理と再現可能な実験を可能にします。'>
<div class='choice'> tf.loggingのデータをBigQueryに保存します</div>
<div class='choice'> ハイブメタストアのすべてのリレーショナルエンティティを管理します</div>
<div class='choice'> すべてのMLメタデータをGoogle Cloud Operations Suiteに保存します</div>
<div class='choice'> Vertex MLメタデータでMLワークフローを管理します</div>
</div>

<div class='question' data-multiple='false' data-question='問題6<br>あなたは、ビジュアル検索エンジンを作成しているオンライン小売企業に勤めています。Google Cloud上にエンドツーエンドのMLパイプラインをセットアップし、画像に自社製品が含まれているかどうかを分類しています。近い将来、新製品がリリースされることを期待して、新しいデータをMLモデルに投入できるように、パイプラインに再トレーニング機能を設定しました。また、AI Platformの継続的な評価サービスを使用して、テストデータセットでモデルが高い精度を持つことを確認したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「再トレーニングに導入された新しい製品の画像でテストデータセットを拡張します」です。<br>この問題では、オンライン小売企業のMLパイプラインの再トレーニングと継続的な評価の手段を理解することが求められています。重要なのは、新製品のリリースが予想され、その新しいデータをモデルに順次投入するよう設定した状況に対応することです。また、継続的な評価サービスを通じてモデルの精度を確認したいという要求も理解する必要があります。選択肢を評価する際には、新製品のデータの扱いと継続的な評価の実施方法に注意を払うことが重要です。<br>基本的な概念や原則：<br>MLパイプライン：機械学習のワークフローを自動化し、再現可能にするためのプロセス管理手法です。データの前処理から学習、モデルの評価、更新までを一貫して管理します。<br>AI Platform：Google Cloudの統合機械学習プラットフォームで、データの前処理から学習、予測までの一連の作業を一元的に管理できます。継続的な評価サービスも提供しています。<br>再トレーニング：新しいデータを用いて既存の機械学習モデルを更新する行為です。新製品や変化する環境にモデルを適用させるために用いられます。<br>テストデータセット：機械学習モデルの性能を評価するためのデータセットです。モデルが未知のデータにどれだけうまく対応できるかを把握するために使用します。モデルの学習には使われません。<br>正解についての説明：<br>（選択肢）<br>・再トレーニングに導入された新しい製品の画像でテストデータセットを拡張します<br>この選択肢が正解の理由は以下の通りです。<br>MLモデルは、データに存在するパターンを学習し、新しい未見のデータに対して予測を行うためのものです。モデルの性能を評価する際は、未見のデータ、つまりモデルが学習段階で見ていないデータを用いる必要があります。もし新しい製品の画像を何もせずにモデルに導入すると、モデルは新製品に対する予測能力を持っていないため、うまく分類できません。<br>そこで、新製品がリリースされる度に、その製品の画像を含むテストデータセットを作成・追加し、モデルに再学習させることで、モデルは新製品のデータを学習し、新製品に対する分類能力を獲得することができます。<br>したがって、新製品の画像でテストデータセットを拡張することは、新製品の分類精度を向上させるための適切な方法と言えます。<br>不正解の選択肢についての説明：<br>選択肢：新しい製品を再トレーニングに組み込んでも、元のテストデータセットは変更しません<br>この選択肢が正しくない理由は以下の通りです。<br>新製品を再トレーニングに組み込むだけで、元のテストデータセットを変更しないと、その新製品に対するモデルの精度を確認する手段がありません。新製品の画像でテストデータセットを拡張することで、新製品に対するモデルの性能を評価できます。<br>選択肢：テストデータセットを、再トレーニングに導入された新しい製品の画像に置き換えます<br>この選択肢が正しくない理由は以下の通りです。<br>テストデータセットを新しい製品の画像に置き換えると、以前の製品の画像を認識できる能力を評価できなくなります。そのため、テストデータセットを置き換えるのではなく、新しい製品の画像を追加して拡張することで、モデルの全体的な性能を網羅的に評価できます。<br>選択肢：評価指標が事前に決めた閾値を下回った場合、テストデータセットを新しい製品の画像で更新します<br>この選択肢が正しくない理由は以下の通りです。<br>評価指標が閾値を下回った場合に初めてテストデータセットを更新するというアプローチでは、問題が発生した後でしか新しいデータをモデルに反映できません。<br>一方、正解選択肢のように新しい製品の画像でテストデータセットを常に更新しておく方が新製品の追加への対応がスムーズになります。'>
<div class='choice'> テストデータセットを、再トレーニングに導入された新しい製品の画像に置き換えます</div>
<div class='choice'> 再トレーニングに導入された新しい製品の画像でテストデータセットを拡張します</div>
<div class='choice'> 評価指標が事前に決めた閾値を下回った場合、テストデータセットを新しい製品の画像で更新します</div>
<div class='choice'> 新しい製品を再トレーニングに組み込んでも、元のテストデータセットは変更しません</div>
</div>

<div class='question' data-multiple='false' data-question='問題7<br>あなたは自動車会社のAIチームで働いており、TensorFlowとKerasを使用して視覚的欠陥検出モデルを開発しています。モデルのパフォーマンスを向上させるには、変換、トリミング、コントラスト調整などの画像拡張機能を組み込む必要があります。これらの関数を各トレーニングバッチにランダムに適用します。実行時とコンピューティングリソースの使用率を考慮してデータ処理パイプラインを最適化したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「拡張関数をtf.Dataパイプラインに動的に組み込みます」です。<br>この問題では、画像拡張機能を含むモデル開発とデータ処理パイプラインの最適化が求められています。画像拡張機能がトレーニングバッチに動的に適用され、実行時とリソース使用率を考慮した最適化が求められています。選択肢を見ると、動的というキーワードも注目すべきです。これを踏まえて選択肢を精査し、何が最適なパイプライン最適化方法かを考える必要があります。<br>基本的な概念や原則：<br>tf.Dataパイプライン：TensorFlowで使用するデータを効率的に処理するためのツールです。データの読み込みや前処理を最適化し、トレーニングのパフォーマンスを向上させます。<br>画像拡張：画像にランダムな変換を適用してデータセットを拡張する手法です。これにより、モデルの汎化性能を向上させることができます。<br>Kerasジェネレータ：Kerasでトレーニングデータを効率的に使用するためのツールです。大量のデータをメモリにロードせずにバッチ単位で処理することができますが、tf.Dataのような最適化機能は持っていません。<br>TensorFlow：ディープラーニングモデルの作成とトレーニングを支援するオープンソースのライブラリです。多様なAPIとツールが提供されており、高度にスケーラブルでパフォーマンスが高いです。<br>TFRecords：TensorFlowで利用する大規模なデータセットを効率的に処理するためのフォーマットです。データの読み込み速度を向上させることができますが、全ての可能なデータ拡張をあらかじめ作成すると大量のストレージが必要となる可能性があります。<br>Dataflow：Google Cloudのデータ処理サービスであり、大量のデータを効率的に処理することができます。ストリーミングとバッチデータの両方をサポートしていますが、トレーニング中のデータ拡張には不適しています。<br>正解についての説明：<br>（選択肢）<br>・拡張関数をtf.Dataパイプラインに動的に組み込みます<br>この選択肢が正解の理由は以下の通りです。<br>まず、TensorFlowのtf.Data APIは、大規模で複雑な入力パイプラインを構築するための強力なツールです。それにより、データの前処理、シャッフル、バッチ化などの一般的なデータ処理タスクを効率的に実行することが可能になります。<br>また、tf.Dataパイプラインを使用すると、TensorFlowの遅延実行機能を活用してデータの処理とモデルの訓練を並行して行うことができます。これにより、CPUとGPUの使用率のバランスを取ることができ、全体的なパフォーマンスを最適化することができます。<br>次に、拡張関数をランダムに適用するためには、これらの関数を動的にtf.Dataパイプラインに組み込むことが理想的です。これにより、各トレーニングバッチで異なる拡張を確率的に適用することが可能になり、モデルの汎用性を高めるのに役立ちます。以上から、拡張関数をtf.Dataパイプラインに動的に組み込むことは、最適な解決策と言えます。<br>不正解の選択肢についての説明：<br>選択肢：拡張関数をKerasジェネレータの一部として動的に埋め込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Kerasジェネレータを使用すると、拡張関数を動的に埋め込むことが可能ですが、必要なコンピューティングリソースが高くなる場合があります。反対にtf.Dataパイプラインを使用すると、ランタイム効率とリソース使用率を最適化し、拡張機能を動的に適用することが容易になります。<br>選択肢：Dataflowを使用して、すべての可能なオーグメンテーションを作成し、それらをTFRecordsとして格納します<br>この選択肢が正しくない理由は以下の通りです。<br>Dataflowを使用してすべての可能なオーグメンテーションを事前に作成し、TFRecordsとして格納すると、ストレージと計算リソースの大量消費となり、資源が無駄になります。<br>一方、tf.Dataパイプラインに動的に拡張関数を組み込むとランタイムでのリソース使用率が最適化され、パフォーマンスが向上します。<br>選択肢：Dataflowを使用して、トレーニング実行ごとにオーグメンテーションを動的に作成し、TFRecordsとしてステージングします<br>この選択肢が正しくない理由は以下の通りです。<br>Dataflowを使用してオーグメンテーションを行い、TFRecordsとしてステージングすると、かえって実行時間が長くなり、コンピューティングリソースの使用率も上昇します。<br>一方、tf.dataパイプラインを使用すると動的に拡張を行いながらトレーニングを進行できるため、効率が良くなります。'>
<div class='choice'> Dataflowを使用して、すべての可能なオーグメンテーションを作成し、それらをTFRecordsとして格納します</div>
<div class='choice'> Dataflowを使用して、トレーニング実行ごとにオーグメンテーションを動的に作成し、TFRecordsとしてステージングします</div>
<div class='choice'> 拡張関数をtf.Dataパイプラインに動的に組み込みます</div>
<div class='choice'> 拡張関数をKerasジェネレータの一部として動的に埋め込みます</div>
</div>

<div class='question' data-multiple='false' data-question='問題8<br>あなたは大企業のデータサイエンスチームのリーダーで、データサイエンスチームは最近、トレーニングパイプラインをオーケストレーションするためにKubeflow Pipelines SDKを使い始めました。あなたのチームはカスタムPythonコードをKubeflow Pipelines SDKに統合するのに苦労しています。<br>彼らのコードをKubeflow Pipelines SDKに迅速に統合するためには、どのように進めるように指示すべきですか？' data-answer='2' data-explanation='解説<br>正解は「Pythonコードからカスタムコンポーネントを作成するために、func_to_container_op関数を使用します」です。<br>この問題では、PythonコードをKubeflow Pipelines SDKに統合する方法について問われています。チームはPythonコードの統合に苦労していると述べられているので、その解決策が求められています。正解選択肢や誤解答選択肢からは、カスタムコードの統合方法についてKubeflowの機能を理解しているかどうかを確認されます。そのため、Kubeflowで提供される機能やメソッドを理解することがこの問題を解くためには必要です。具体的には、Kubeflowが提供するfunc_to_container_op関数、Kubeflowの他の機能やDocker、Cloud Functionsとそれらをどのように組み合わせるかを理解することが重要です。<br>基本的な概念や原則：<br>Kubeflow Pipelines SDK：Kubeflow Pipelinesを構築し、デプロイするための開発者向けツールキットです。機械学習ワークフローの作成と管理を簡易化します。<br>カスタムコンポーネント：既存のコンポーネントにない特定の処理を実現するためにユーザーが作成するコンポーネントです。これは、ユーザー独自のPythonコードをKubeflow Pipelinesに統合するために使用されます。<br>func_to_container_op関数：Pythonの関数からKubeflow Pipelinesのコンポーネントを作成するための関数です。これにより、Pythonコードを直接パイプラインに組み込むことができます。<br>Dataproc：Google CloudのフルマネージドのHadoopとSparkの環境を提供するサービスです。大量のデータを高速に処理することが可能ですが、カスタムPythonコードの統合には不適切です。<br>load_component_from_file関数：ローカルファイルやURLからKubeflow Pipelinesのコンポーネントをロードするための関数です。ただし、これはDockerコンテナのパイプラインへのインポートに使用し、Pythonコード自体の統合には使用しません。<br>Cloud Functions：Google Cloudのサーバレス実行環境です。HTTPリクエストやCloudストレージのイベントなどに反応して動作しますが、Kubeflow Pipelinesのコードの統合には使用しないのが一般的です。<br>正解についての説明：<br>（選択肢）<br>・Pythonコードからカスタムコンポーネントを作成するために、func_to_container_op関数を使用します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Kubeflow Pipelines SDKには、Pythonの関数からコンテナを作成するための`func_to_container_op`という関数が提供されています。Pythonで書かれた既存のコードをKubeflow Pipelines SDKに統合するときに役立つのがこの関数です。そのため、チームが既にPythonコードを持っている状況では、この関数を使うことで迅速にコードの統合を進めることができます。<br>したがって、`func_to_container_op`関数を使用してPythonコードからカスタムコンポーネントを作成するようチームに指示するのが最善の手段です。使用方法はSDKのドキュメントに詳しく記載されているので、それを参照して進めることが理想的です。<br>不正解の選択肢についての説明：<br>選択肢：Kubeflow Pipelines SDKで利用可能な定義済みコンポーネントを使用してDataprocにアクセスし、そこでカスタムコードを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>カスタムPythonコードをKubeflow Pipelines SDKに統合するために、Dataprocにアクセスしてカスタムコードを実行するという操作は必要ありません。直接、func_to_container_op関数を使用してカスタムコンポーネントを作成することで、より直接的に問題を解決できます。このオプションは追加のステップと複雑さを導入し、実際には必要ない操作を提案しています。<br>選択肢：カスタムPythonコードをDockerコンテナにパッケージし、load_component_from_file関数を使ってコンテナをパイプラインにインポートします<br>この選択肢が正しくない理由は以下の通りです。<br>カスタムPythonコードをDockerコンテナにパッケージし、load_component_from_file関数を使用する方法は技術的に可能ですが、これは迅速な統合を目指すという問題の要件には対応していません。Dockerコンテナの作成や管理は時間と労力を必要とするプロセスであり、func_to_container_op関数を使用すればカスタムPythonコードの統合をより迅速に行うことができます。<br>選択肢：カスタムPythonコードをCloud Functionsにデプロイし、Kubeflow Pipelinesを使ってCloud Functionをトリガーします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Functionsを使用すると、Kubeflow Pipelinesと連携するための追加のステップや管理作業が必要です。<br>また、直接Pythonコードを統合するよりもコストが高くなり、統合が迅速に行えない可能性があります。正解の選択肢であるfunc_to_container_op関数を使う方がより直接的で効率的です。'>
<div class='choice'> カスタムPythonコードをCloud Functionsにデプロイし、Kubeflow Pipelinesを使ってCloud Functionをトリガーします</div>
<div class='choice'> Kubeflow Pipelines SDKで利用可能な定義済みコンポーネントを使用してDataprocにアクセスし、そこでカスタムコードを実行します</div>
<div class='choice'> Pythonコードからカスタムコンポーネントを作成するために、func_to_container_op関数を使用します</div>
<div class='choice'> カスタムPythonコードをDockerコンテナにパッケージし、load_component_from_file関数を使ってコンテナをパイプラインにインポートします</div>
</div>

<div class='question' data-multiple='false' data-question='問題9<br>あなたは、Kerasを使用して構築された概念実証MLモデルのプロダクション化を依頼されました。モデルはデータサイエンテストのローカルマシン上のJupyterノートブックで学習されました。ノートブックには、データ検証を行うセルとモデル分析を行うセルが含まれています。ノートブックに含まれるステップをオーケストレーションし、毎週の再トレーニングのためにこれらのステップの実行を自動化する必要があります。将来的には、さらに多くのトレーニングデータが必要になることが予想されます。コストを最小限に抑えながら、マネージドサービスを活用できるソリューションにしたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「Vertex AI PipelinesでオーケストレーションされたTensorFlow Extended（TFX）パイプラインとしてコードを記述します。データ検証とモデル分析には標準的なTFXコンポーネントを使用し、モデルの再トレーニングにはVertex AI Pipelinesを使用します」です。<br>この問題では、概念実証MLモデルのプロダクション化にあたり、Jupyterノートブックのステップを自動化し、再トレーニングをマネージドサービスを使用しつつコストを抑えて行う方法が求められています。注意すべき要素としては、使用されている技術（ここではKerasとJupyterノートブック）、求められている操作（データ検証とモデル分析）、マネージドサービスの利用、コスト管理、そしてスケジュールによる自動化があります。これらを考慮し、適切なGoogle Cloudのサービスを選ぶことが解決策の中心です。<br>基本的な概念や原則：<br>Keras：Pythonで書かれたオープンソースのニューラルネットワークライブラリで、TensorFlowのディープラーニングAPIを簡単におこなうことができます。<br>Jupyterノートブック：インタラクティブなコーディングを支援するオープンソースのWebアプリケーションです。データクレンジング、統計モデリング、機械学習など、多様なデータ解析作業を実行することができます。<br>オーケストレーション：複数のタスクや作業を効率的に組織化、調整、管理することです。<br>Vertex AI Pipelines：Google Cloudのサービスで、機械学習モデルの作成、トレーニング、デプロイに関するワークフローをオーケストレーションすることができます。<br>TensorFlow Extended（TFX）：Googleが開発したエンドツーエンドの機械学習プラットフォームで、データ検証やモデル分析など、機械学習の各ステップを実行するためのコンポーネントを提供します。<br>Apache Spark：大規模データ処理のためのオープンソースの分散コンピューティングシステムで、機械学習、ストリーミング処理、グラフ処理などをサポートしています。<br>Apache Airflow：ワークフローをプログラム的に作成、スケジュール、監視するためのプラットフォームです。Pythonを用いてワークフローを記述でき、タスクの依存関係を視覚的に確認できます。<br>正解についての説明：<br>（選択肢）<br>・Vertex AI PipelinesでオーケストレーションされたTensorFlow Extended（TFX）パイプラインとしてコードを記述します。データ検証とモデル分析には標準的なTFXコンポーネントを使用し、モデルの再トレーニングにはVertex AI Pipelinesを使用します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Vertex AI Pipelinesは、機械学習のワークフローを自動化するためのマネージドサービスであり、Jupyterノートブック上の複数のステップを効率的にオーケストレーションできます。<br>また、再トレーニングの自動化もサポートしています。TensorFlow Extended（TFX）はTensorFlowのエコシステムの一部であり、Kerasモデルと互換性があります。TFXパイプラインは、データ検証やモデル分析などの一連の機械学習ワークフローをまとめ、再現性とトレーサビリティを提供します。標準的なTFXコンポーネントを使用することで、データ検証とモデル分析を効率的に行うことができます。データが増えてくると予想されるシナリオにも柔軟に対応できます。これらの機能により、マネージドサービスを活用しながらもコストを最小限に抑えることができます。<br>不正解の選択肢についての説明：<br>選択肢：Jupyterノートブックを最大のN2マシンタイプ上のNotebooksインスタンスに移動し、Cloud Schedulerを使ってNotebooksインスタンス内のステップの実行をスケジュールします<br>この選択肢が正しくない理由は以下の通りです。<br>最大のN2マシンタイプを使用すると、コストを最小限に抑えるという要件に反します。<br>また、Cloud Schedulerを使ってノートブックのステップをスケジュールするのは手間がかかり、マネージドサービスを活用するという要件にも合致しません。<br>これに対して、正解のVertex AI Pipelinesはオーケストレーションが容易で、自動化が可能です。<br>選択肢：JupyterノートブックのステップをApache Sparkジョブとして書き直し、Cloud Schedulerを使用してエフェメラルDataprocクラスター上でジョブの実行をスケジュールします<br>この選択肢が正しくない理由は以下の通りです。<br>Apache Sparkは主に大規模データ処理に使用される一方、MLモデルのプロダクション化や再トレーニングではなく、扱うデータの規模が大きなときには有効ですが、問題文にそのような要件は出ていません。<br>また、Cloud SchedulerとDataprocを使用すると、管理オーバーヘッドが高まりますが、一方でVertex AI Pipelinesはマネージドサービスなので管理の面倒が少ないです。<br>選択肢：Jupyterノートブックに含まれるステップをPythonスクリプトとして抽出し、各スクリプトをApache Airflow BashOperatorでラップし、得られた有向非巡回グラフ（DAG）をCloud Composerで実行します<br>この選択肢が正しくない理由は以下の通りです。<br>Apache AirflowとCloud Composerを使用すると自動化とオーケストレーションは可能ですが、この選択肢はマネージドサービスの活用や規模の拡大に対する柔軟性に欠けます。<br>さらに、Scala Opeartorを使用してPythonスクリプトをラップする手法はコストが増大する可能性があります。これに比べ、Vertex AI Pipelinesを用いると、自動化、オーケストレーション、拡張性、コスト効率の全てを満たすことができます。'>
<div class='choice'> JupyterノートブックのステップをApache Sparkジョブとして書き直し、Cloud Schedulerを使用してエフェメラルDataprocクラスター上でジョブの実行をスケジュールします</div>
<div class='choice'> Jupyterノートブックを最大のN2マシンタイプ上のNotebooksインスタンスに移動し、Cloud Schedulerを使ってNotebooksインスタンス内のステップの実行をスケジュールします</div>
<div class='choice'> Vertex AI PipelinesでオーケストレーションされたTensorFlow Extended（TFX）パイプラインとしてコードを記述します。データ検証とモデル分析には標準的なTFXコンポーネントを使用し、モデルの再トレーニングにはVertex AI Pipelinesを使用します</div>
<div class='choice'> Jupyterノートブックに含まれるステップをPythonスクリプトとして抽出し、各スクリプトをApache Airflow BashOperatorでラップし、得られた有向非巡回グラフ（DAG）をCloud Composerで実行します</div>
</div>

<div class='question' data-multiple='false' data-question='問題10<br>あなたは、会社のソーシャルメディアページ上のユーザーの投稿の感情を検出して機能停止やバグを特定するMLモデルを開発しました。Dataflowを使用して、Pub/Subから取り込まれたデータに対してリアルタイムの予測を提供しています。モデルに対して複数のトレーニングイテレーションを行い、実行のたびに最新の2つのバージョンをライブ状態に保つことを計画しています。トラフィックをバージョン間で80:20の比率で分割し、最新モデルがトラフィックの大部分を取得するとします。必要な管理を最小限に抑え、パイプラインを可能な限りシンプルに保ちたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「--traffic-split=NEW_MODEL_ID=80, PREVIOUS_MODEL_ID=20 の設定を使用して、モデルをVertex AIエンドポイントにデプロイします」です。<br>この問題では、MLモデルの複数のバージョンをリアルタイムで運用し、それらのトラフィック分布を調整することがテーマとなっています。また、管理を最小限に抑え、パイプラインを可能な限りシンプルに保つことが求められています。これは一般的にモデルのA/Bテストや漸進的なロールアウトにおけるトラフィックの制御を指します。具体的には、2つのバージョンのモデルをリアルタイムに適用し、その分配を80:20で制御することが求められています。そのため、解答はこれらを可能にするGoogle Cloudのサービスとその設定方法に焦点を当てて選ぶべきです。<br>基本的な概念や原則：<br>Dataflow：Google Cloudのリアルタイムとバッチの両方のデータ処理を提供するフルマネージドサービスです。スケーラブルで信頼性が高く、高いパフォーマンスを持ちます。<br>Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。大量のメッセージをリアルタイムで受け取り、そのメッセージを利用してアプリケーションやサービス間でデータを共有します。<br>MLモデル：機械学習アルゴリズムがデータから学習した結果を表現したものです。MLモデルは予測や分類などのタスクを行うために使用されます。<br>Vertex AI：Google Cloudのフルマネージド機械学習サービスです。モデルのトレーニング、評価、予測などの機能を提供します。<br>トラフィックスプリット：アプリケーションやサービスの異なるバージョン間でトラフィックを分散する機能です。新旧のバージョンを平行して運用するのに役立ちます。<br>App Engine：Google Cloudのフルマネージドアプリケーションプラットフォームです。アプリケーションのデプロイ、スケーリング、管理を自動化しますが、本問の要件には不適切です。<br>Cloud Run：コンテナ化されたアプリケーションをフルマネージドで実行するGoogle Cloudのサービスです。しかし、MLモデルをラップするために使用するために、過剰な管理が求められる可能性があります。<br>正解についての説明：<br>（選択肢）<br>・--traffic-split=NEW_MODEL_ID=80, PREVIOUS_MODEL_ID=20 の設定を使用して、モデルをVertex AIエンドポイントにデプロイします<br>この選択肢が正解の理由は以下の通りです。<br>トラフィックの分割を行うには、Google CloudのVertex AIが提供するエンドポイントを使用します。Vertex AIエンドポイントは複数のモデルバージョンをホストでき、特定のパーセンテージのトラフィックを各モデルに割り当てるオプションを提供します。この場合、あなたは新しいモデルに80％、以前のモデルに20％のトラフィックを割り当てたいと考えているので、トラフィック分割オプションで正確にこれを実現したいと考えています。<br>また、この選択はMLモデルのトレーニングとデプロイに関する管理作業を最小限に抑えることができます。新規と既存の双方のモデルをそれぞれ一つのエンドポイントにデプロイすることで、エンドポイントの管理やトラフィックの調整を効率的に行うことができます。これは、シンプルで効果的な解決策を求めているあなたのニーズにぴったり合っています。<br>したがって、モデルをVertex AIエンドポイントにデプロイし、--traffic-splitオプションを使用して、新旧のモデルに対するトラフィックの割り当てを制御することが、正解の選択肢です。<br>不正解の選択肢についての説明：<br>選択肢：--splits PREVIOUS_VERSION=0.2, NEW_VERSION=0.8構成を使用して、App Engineアプリケーション内にモデルをラップします<br>この選択肢が正しくない理由は以下の通りです。<br>App EngineはMLモデルのデプロイやバージョン管理で使用する一般的なサービスではありません。指定された要件はMLモデルの管理と予測を容易にするためのVertex AIの特性により適しており、そのため選択肢は相応しくありません。<br>選択肢：REVISION1=20, REVISION2=80のリビジョン構成を使用して、モデルをCloud Runコンテナ内にラップします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Runはリアルタイムの予測を提供するためのツールですが、Machine Learning（ML）モデルのバージョニングやトラフィックのスプリットなどの高度な機能は提供していません。<br>一方で、Vertex AIはMLモデルのバージョニングとトラフィックスプリットをサポートしており、このシナリオではより適した選択肢です。<br>また、Cloud Runでは必要な管理も増えるため、管理を最小限に抑えたい要件からも外れます。<br>選択肢：beam.Partition()を使用して、Vertex AIエンドポイントを呼び出すパーティション関数を使用して、Dataflowにランダム分割を実装します<br>この選択肢が正しくない理由は以下の通りです。<br>beam.Partition()を使用してランダム分割を実装すると、管理が複雑化し、パイプラインが不必要に複雑化します。<br>一方、トラフィックスプリットオプションを使用すると、簡単にトラフィック分割を管理でき、パイプラインをシンプルに保つことができます。'>
<div class='choice'> --traffic-split=NEW_MODEL_ID=80, PREVIOUS_MODEL_ID=20 の設定を使用して、モデルをVertex AIエンドポイントにデプロイします</div>
<div class='choice'> REVISION1=20, REVISION2=80のリビジョン構成を使用して、モデルをCloud Runコンテナ内にラップします</div>
<div class='choice'> --splits PREVIOUS_VERSION=0.2, NEW_VERSION=0.8構成を使用して、App Engineアプリケーション内にモデルをラップします</div>
<div class='choice'> beam.Partition()を使用して、Vertex AIエンドポイントを呼び出すパーティション関数を使用して、Dataflowにランダム分割を実装します</div>
</div>

<div class='question' data-multiple='false' data-question='問題11<br>データサイエンスチームは、様々な機能、モデルアーキテクチャ、ハイパーパラメータを迅速に実験する必要があります。様々な実験の精度メトリクスを追跡し、APIを使用して経時的にメトリクスを照会する必要があります。<br>手作業を最小限に抑えながら実験を追跡し、報告するために何を使うべきですか？' data-answer='1' data-explanation='解説<br>正解は「Kubeflow Pipelinesを使って実験を実行します。メトリクスファイルをエクスポートし、Kubeflow Pipelines APIを使用して結果を照会します」です。<br>この問題では、データサイエンスチームが手作業を最小限に抑えながら、機能、モデル、ハイパーパラメータの各種実験結果（メトリクス）を追跡し報告するための最適なツールや手段を選ぶ問題です。ヒントとなるのは"手作業を最小限に抑え、迅速に実験を行い、APIを使用して経時的にメトリクスを照会する"という部分で、これにより全ての処理を効率的かつ自動化可能なプラットフォーム上で実行することが必要だと読み取れます。それぞれの選択肢が、この条件をどの程度満たしているかを評価することが求められています。<br>基本的な概念や原則：<br>Kubeflow Pipelines：機械学習のエンドツーエンドのワークフローを組成、デプロイ、管理するためのプラットフォームです。再現性と実験管理を容易にします。<br>メトリクス：評価指標であり、モデルのパフォーマンスを測定するために使用されます。<br>ハイパーパラメータ：学習プロセスにおけるパラメータで、学習前に設定されます。例えば、学習率やエポック数などがそれに該当します。<br>API：Application Programming Interfaceの略称で、アプリケーションソフトウェアの機能を共有して使用するための規格です。<br>AI Platform Training：Google Cloudの全管理型機械学習モデルトレーニングサービスで、大規模なデータセットを用いてモデルのトレーニングやバージョニングを行います。<br>BigQuery：Google Cloudの高速でスケーラブルなフルマネージドデータウェアハウスサービスです。<br>Cloud Monitoring：Google Cloudの監視、診断、通知を一元化するサービスです。<br>AI Platform Notebooks：Google CloudのJupyter Notebook環境を提供するマネージドサービスです。データ分析と機械学習開発のためのツールです。<br>正解についての説明：<br>（選択肢）<br>・Kubeflow Pipelinesを使って実験を実行します。メトリクスファイルをエクスポートし、Kubeflow Pipelines APIを使用して結果を照会します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Kubeflow Pipelinesは、機能の実験や機械学習モデルのパイプラインを作成、組み合わせ、共有し、再利用するためのツールです。エンドツーエンドの機械学習ワークフローを扱うことができるため、様々な機能、モデルアーキテクチャ、ハイパーパラメータを迅速に実験するデータサイエンスチームのニーズを満たすことができます。<br>また、メトリクスファイルをエクスポートすることで、実験の精度メトリクスを追跡することができます。<br>さらに、Kubeflow Pipelines APIを使用すれば、それらのメトリクスをプログラム的に照会し、それぞれの実験がどのようにパフォーマンスを発揮しているかどうかを確認することができます。このため、この選択肢が最も適切な解答です。<br>不正解の選択肢についての説明：<br>選択肢：AI Platform Trainingを使用して実験を実行します。精度メトリクスをBigQueryに書き込み、BigQuery APIを使用して結果をクエリします<br>この選択肢が正しくない理由は以下の通りです。<br>AI Platform TrainingとBigQueryを使う選択肢は、手作業を最小限に抑えるという要件を満たさない可能性があります。特に、各精度メトリクスをBigQueryに書き込むのは手間がかかります。対してKubeflow Pipelinesでは、メトリクスの追跡と経時的な照会を一元化し効率的に行うことができます。<br>選択肢：AI Platform Trainingを使用して実験を実行します。精度メトリクスをCloud Monitoringに書き込み、Monitoring APIを使って結果をクエリします<br>この選択肢が正しくない理由は以下の通りです。<br>AI Platform Trainingは、様々な特性やハイパーパラメータでの即座の実験の実行や追跡を容易にする組み込みの機能がありません。Kubeflow Pipelinesは、これらの要件に対応するフレキシブルなパイプラインを構築し、管理することができます。<br>また、Cloud Monitoringはデータサイエンスのチームが実験のメトリクスを追跡する目的には適していません。<br>選択肢：AI Platform Notebooksを使って実験を実行します。結果を共有のGoogle Sheetsファイルに収集し、Google Sheets APIを使用して結果を照会します<br>この選択肢が正しくない理由は以下の通りです。<br>AI Platform NotebooksとGoogle Sheetsの組み合わせは、実験の追跡や結果の照会自動化には適していません。Kubeflow Pipelinesは、実験の追跡、実行、そして結果の照会の自動化に適しているため、手作業を最小限に抑える要求を満たす最適な選択肢とします。'>
<div class='choice'> AI Platform Trainingを使用して実験を実行します。精度メトリクスをCloud Monitoringに書き込み、Monitoring APIを使って結果をクエリします</div>
<div class='choice'> Kubeflow Pipelinesを使って実験を実行します。メトリクスファイルをエクスポートし、Kubeflow Pipelines APIを使用して結果を照会します</div>
<div class='choice'> AI Platform Notebooksを使って実験を実行します。結果を共有のGoogle Sheetsファイルに収集し、Google Sheets APIを使用して結果を照会します</div>
<div class='choice'> AI Platform Trainingを使用して実験を実行します。精度メトリクスをBigQueryに書き込み、BigQuery APIを使用して結果をクエリします</div>
</div>

<div class='question' data-multiple='false' data-question='問題12<br>あなたの会社のモバイルアプリケーションからユーザーのアクティビティデータを分析する必要があります。チームはデータ分析、変換、MLアルゴリズムの実験にBigQueryを使用します。また、ユーザアクティビティデータをリアルタイムでBigQueryに取り込む必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「Pub/Subを設定してデータをBigQueryにストリーミングします」です。<br>この問題では、モバイルアプリケーションからのユーザー活動データをリアルタイムでBigQueryに取り込む最適な方法を選ぶことが求められています。ここで重要なのは、リアルタイムデータの取り込みとBigQueryへの連携が必要という部分です。選択肢は全てBigQueryへの取り込みを提案していますが、最も効率的でシンプルな方法を見つけることが大切です。各選択肢のサービスとロールを理解し、それらが要件とどのようにアライメントを取るかを検討することが求められます。<br>基本的な概念や原則：<br>Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。高いスケーラビリティと信頼性を持ち、データをリアルタイムで処理したり、BigQueryのような分析ツールにストリーミングすることができます。<br>BigQuery：Google Cloudのフルマネージドでスケーラブルなデータウェアハウスサービスです。大量のデータをSQLを使用して高速に分析できます。<br>Dataflow：Google Cloudのストリーミングとバッチデータ処理サービスです。Apache Beamベースのジョブを実行し、データをクリーニング、分析、変換するために使用されます。<br>Dataproc：Google CloudのフルマネージドHadoopとSparkのサービスです。大量のデータを高速で処理し、様々な分析タスクを実行することができます。<br>Apache Spark：大規模データ処理を高速化するオープンソースの分散コンピューティングシステムです。ストリーミングデータ処理にも対応しています。<br>正解についての説明：<br>（選択肢）<br>・Pub/Subを設定してデータをBigQueryにストリーミングします<br>この選択肢が正解の理由は以下の通りです。<br>まず、リアルタイムでのデータ取り込みをする必要がある場合、Pub/Subはその要求を満たすための優れたツールです。Pub/SubはGoogle Cloudのリアルタイムメッセージングサービスで、データをリアルタイムにプロデューサから消費者に配信します。この場合、モバイルアプリケーションがプロデューサで、BigQueryが消費者です。<br>Pub/Subが生成するメッセージは、そのままBigQueryにストリーミングすることができます。これにより、データの複製や待機時間を大幅に削減し、データがリアルタイムにBigQueryに取り込まれ、迅速な分析や処理が可能になります。<br>さらに、構造化、半構造化問わずあらゆるタイプのデータ、それがどれだけ大量であったとしても、Pub/Subはそれをシームレスにハンドリングできます。そのため、ユーザーアクティビティデータといった様々な形式のデータを素早く、信頼性高く処理するのに役立ちます。<br>このように、Pub/Subを設定してデータをBigQueryにストリーミングすることで、ユーザーアクティビティデータをリアルタイムでBigQueryに取り込む要件を満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：Dataproc上でApache Sparkストリーミングジョブを実行し、データをBigQueryに取り込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Apache SparkストリーミングジョブをDataprocで実行する方法はバッチ処理に向いており、要求されているリアルタイムのデータ取り込みには最適ではありません。<br>それに対して、Pub/Subを使用するとリアルタイムにデータをBigQueryにストリーミングできます。<br>選択肢：Dataflowストリーミングジョブを実行し、データをBigQueryに取り込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Dataflowは、大量のデータを高度に変換または加工するためのツールで、リアルタイムのデータ取り込みには過剰なサービスです。<br>一方、Pub/Subはリアルタイムのメッセージングサービスで、ユーザアクティビティデータのリアルタイムストリーミングには最適です。<br>選択肢：Pub/SubとDataflowストリーミングジョブを設定して、データをBigQueryに取り込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Pub/SubとDataflowストリーミングジョブを設定してデータをBigQueryに取り込む方法は、データの前処理や変換が必要な場合に適しています。<br>しかし、本問ではそのような要件は示されておらず、ただ単にリアルタイムのデータをBigQueryに取り込むだけであれば、Pub/Subのみで十分に対応可能です。'>
<div class='choice'> Pub/Subを設定してデータをBigQueryにストリーミングします</div>
<div class='choice'> Dataproc上でApache Sparkストリーミングジョブを実行し、データをBigQueryに取り込みます</div>
<div class='choice'> Dataflowストリーミングジョブを実行し、データをBigQueryに取り込みます</div>
<div class='choice'> Pub/SubとDataflowストリーミングジョブを設定して、データをBigQueryに取り込みます</div>
</div>

<div class='question' data-multiple='false' data-question='問題13<br>あなたは銀行のデータサイエンスチームに所属し、ローンのデフォルトリスクを予測するMLモデルを作成しています。あなたは、BigQueryテーブルに数億レコード分のトレーニングデータを収集し、クリーニングしました。あなたは今、TensorFlowとVertex AIを使用して、このデータで複数のモデルを開発し、比較したいと考えています。スケーラビリティを考慮しつつ、データ取り込み時のボトルネックを最小限に抑えたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「データを直接読み込むには、TensorFlow I/OのBigQuery Readerを使用します」です。<br>この問題では、大量のデータを使用して機械学習モデルを開発する際の賢いデータ取り込み方法について考えます。ここで注目すべきは、データの規模と"ボトルネックを最小限に抑えつつスケーラビリティを考慮したい"という要求です。この状況では、データの効率的な読み込みと処理が重要なポイントで、それに最適なツールやフォーマットを選ぶ事がカギとなります。したがって、データソース（BigQuery）を直接利用できる方法や、データを一度にどの程度読み込めるか等が問われます。<br>基本的な概念や原則：<br>BigQuery：Google Cloudのフルマネージド型大規模データウェアハウスサービスで、SQLクエリを用いて大規模データに対する分析が可能です。<br>TensorFlow I/O：TensorFlowの拡張ライブラリで、一部の特化したデータソースをサポートしています。BigQuery Readerを使用することで、BigQueryのテーブルデータを直接TensorFlowに読み込むことができます。<br>Vertex AI：Google Cloudの統合型MLプラットフォームで、モデル開発から運用までのワークフローを支援します。<br>BigQueryクライアントライブラリ：BigQuery APIを簡単に利用するためのライブラリですが、大量データの取り込みには限界があります。<br>tf.data.Dataset.from_tensor_slices()：TensorFlowのAPIで、メモリに収まる量のデータを読み込むのに適していますが、数億レコードとなるとボトルネックが発生します。<br>Cloud Storage：大量のデータを安全に保管できるGoogle Cloudのストレージサービスです。データをCSVにエクスポートしてから読み込むことも可能ですが、処理が複雑になります。<br>TFRecord：TensorFlowでデータを効率的に読み込むためのバイナリ形式です。しかし、BigQueryのデータをTFRecordsに変換する工程は時間とコストがかかります。<br>正解についての説明：<br>（選択肢）<br>・データを直接読み込むには、TensorFlow I/OのBigQuery Readerを使用します<br>この選択肢が正解の理由は以下の通りです。<br>TensorFlow I/OのBigQuery Readerを使用すると、BigQueryテーブルからデータを直接TensorFlowにフィードすることができます。これは、データをその場で読み込み、データのダウンロードやローカルストレージへのエクスポートなどの時間を節約するための優れた手法です。一般的にTensorFlowは大量のデータを処理する能力があり、BigQuery Readerを通じて提供されるストリームデータの一部を一度に読み取ることで、効率的にデータを取り込むことができます。<br>また、数億レコードのデータを扱う際には、スケーラビリティを考慮する必要があります。BigQuery Readerを使用することで、読み込むデータの量を柔軟にスケーリングすることができます。結果として、これによりボトルネックを最小限に抑えることができます。以上から、この選択肢は問題の要件を最も適切に満たすと言えます。<br>不正解の選択肢についての説明：<br>選択肢：BigQueryクライアントライブラリを使用してデータをデータフレームにロードし、tf.data.Dataset.from_tensor_slices()を使用してデータを読み込みます<br>この選択肢が正しくない理由は以下の通りです。<br>BigQueryクライアントライブラリを使用してデータをロードすると、データがメモリに全て読み込まれるため、大量のデータを扱う際にはボトルネックになります。<br>それに対し、TensorFlow I/OのBigQuery Readerはデータをバッチで直接読み込むことが可能で、スケーラビリティやパフォーマンスを担保できます。<br>選択肢：データをCloud StorageのCSVファイルにエクスポートし、tf.data.テキストLineDataset()を使って読み込みます<br>この選択肢が正しくない理由は以下の通りです。<br>BigQueryのデータをCloud StorageのCSVファイルへエクスポートするという手順は、データの取り込み時に余計な時間とリソースを消費します。<br>一方、TensorFlow I/OのBigQuery Readerを使用すればボトルネックを最小限に抑えつつデータを直接読み込むことができます。<br>選択肢：データをTFRecordsに変換し、tf.data.TFRecordDataset() を使用して読み込みます<br>この選択肢が正しくない理由は以下の通りです。<br>TFRecordsに変換し、tf.data.TFRecordDataset() を使用する方法はスケーラブルではありますが、データ取り込み時のボトルネックを最小限に抑えるという要件を満たしません。これは、このプロセスはBigQueryからデータをエクスポートし、TFRecordsに変換し、その後ロードするという時間とリソースを必要とします。対してTensorFlow I/OのBigQuery Readerを使用すると、データを直接読み込むことができ、取り込み時間を大幅に短縮します。'>
<div class='choice'> データをTFRecordsに変換し、tf.data.TFRecordDataset() を使用して読み込みます</div>
<div class='choice'> データをCloud StorageのCSVファイルにエクスポートし、tf.data.テキストLineDataset()を使って読み込みます</div>
<div class='choice'> BigQueryクライアントライブラリを使用してデータをデータフレームにロードし、tf.data.Dataset.from_tensor_slices()を使用してデータを読み込みます</div>
<div class='choice'> データを直接読み込むには、TensorFlow I/OのBigQuery Readerを使用します</div>
</div>

<div class='question' data-multiple='false' data-question='問題14<br>Vertex Alでモデル学習パイプラインを実行しているときに、メモリ不足エラーが原因で評価ステップが失敗していることに気づきました。現在、評価ステップに標準のEvaluator TensorFlow Extended（TFX）パイプラインコンポーネントを使用したTensorFlow Model Analysis（TFMA）を使用しています。インフラストラクチャのオーバーヘッドを最小限に抑えながら、評価品質を落とすことなくパイプラインを安定させたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「beam_pipeline_argsに--runner=DataflowRunnerフラグを指定すると、Dataflow上で評価ステップが実行されます」です。<br>この問題では、Vertex AIで実行しているモデル学習パイプラインの中で評価ステップがメモリ不足エラーで失敗すること象に対する対策を問われています。ここで求められているのは、パイプラインを安定化させつつもインフラストラクチャのオーバーヘッドを抑える方法です。一方で評価品質を保ったまま対策を立てることを求められているため、メトリクス数を制限するような手段は適切ではありません。このあたりを注意深く読み取りながら解答に取り組むことが求められます。<br>基本的な概念や原則：<br>Vertex AI：Google CloudのAI Platformです。モデル学習や予測を行うためのパイプラインを提供し、自動化をサポートします。<br>TensorFlow Extended（TFX）：本番環境での機械学習システムのエンドツーエンドの構築をサポートするライブラリです。パイプラインの作成に用いられます。<br>TensorFlow Model Analysis（TFMA）：TensorFlow Extendedの一部であり、モデルの評価を補助します。<br>Dataflow：Google Cloudのデータ処理サービスであり、無限かつバッチワイズなデータストリームに対する操作を可能にします。<br>Compute Engine：Google CloudのIaaS型で提供される仮想マシン（VM）サービスです。カスタムVMを作成し、必要な仕様で実行することができます。<br>Google Kubernetes Engine：Google Cloudが提供するKubernetes環境です。複数のコンテナを横断的に管理します。<br>データ処理の分散・並列化：データ処理において、オーバーヘッドを最小限に抑えながら、スケーラビリティと低コストを実現するための手法です。例えばDataflowRunnerなどで理想的に達成できます。<br>正解についての説明：<br>（選択肢）<br>・beam_pipeline_argsに--runner=DataflowRunnerフラグを指定すると、Dataflow上で評価ステップが実行されます<br>この選択肢が正解の理由は以下の通りです。<br>まず、メモリ不足によるエラーは、一般的にリソースが不足している場合に発生します。そのため、より大きなリソースプールを持つランナーを指定することで解消できます。Dataflowは、ビッグデータ分析用のGoogle Cloudのフルマネージド型サービスで、大量のデータを効率的に処理できます。ここでのbeam_pipeline_argsは、TFXパイプラインの実行に関連するApache Beamの引数を指定するためのもので、この中で--runner=DataflowRunnerと指定することで、データの処理がDataflow上で行われるようになります。これにより、ローカルマシンの限られたリソースを超えてスケーリングし、大規模なデータセットに対してメモリ不足エラーを解消できます。<br>また、Cloud Dataflowはサーバレスなサービスであるため、インフラストラクチャ管理の手間を大幅に軽減できます。このことが、インフラストラクチャのオーバーヘッドを最小限に抑える要件に対応します。<br>さらに、Dataflow上で評価ステップを行うことで、評価品質が落ちることなくパイプラインを安定化させることができます。この理由で、--runner=DataflowRunnerフラグを指定する選択肢が最も適切な解決策と考えられます。<br>不正解の選択肢についての説明：<br>選択肢：評価ステップをパイプラインから移動し、十分なメモリを持つカスタムCompute Engine VMで実行します<br>この選択肢が正しくない理由は以下の通りです。<br>カスタムCompute Engine VMで評価ステップを行うと、インフラストラクチャのオーバーヘッドは逆に増え、コストも増加します。<br>対照的に、DataflowRunnerを使用すると、必要に応じてスケールアップ・ダウンし、オーバーヘッドとコストを抑えることができます。<br>選択肢：パイプラインをGoogle Kubernetes Engine上でホストされているKubeflowに移行し、評価ステップに適切なノードパラメータを指定します<br>この選択肢が正しくない理由は以下の通りです。<br>パイプラインをKubeflowに移行すると、インフラストラクチャのオーバーヘッドが増えてしまう可能性があります。<br>さらに、評価ステップのメモリ不足問題を解決するためにはスケーラブルなリソースが必要であり、その点でDataflowRunnerの使用が適しています。<br>選択肢：tfma.MetricsSpec()を追加して、評価ステップのメトリクス数を制限します<br>この選択肢が正しくない理由は以下の通りです。<br>tfma.MetricsSpec()を追加してメトリクス数を制限すると、評価の品質が落ちてしまう可能性があります。<br>一方で、正解の選択肢のようにDataflowRunnerを使用することで、必要なリソースを適切に割り当てることが可能になります。'>
<div class='choice'> beam_pipeline_argsに--runner=DataflowRunnerフラグを指定すると、Dataflow上で評価ステップが実行されます</div>
<div class='choice'> 評価ステップをパイプラインから移動し、十分なメモリを持つカスタムCompute Engine VMで実行します</div>
<div class='choice'> パイプラインをGoogle Kubernetes Engine上でホストされているKubeflowに移行し、評価ステップに適切なノードパラメータを指定します</div>
<div class='choice'> tfma.MetricsSpec()を追加して、評価ステップのメトリクス数を制限します</div>
</div>

<div class='question' data-multiple='false' data-question='問題15<br>計算コストの高い前処理を必要とするデータセットでモデルを学習しました。予測時にも同じ前処理を実行する必要があります。高スループットのオンライン予測用にAI Platformにモデルをデプロイしました。<br>どのアーキテクチャを使用すべきですか？' data-answer='2' data-explanation='解説<br>正解は「入ってくる予測リクエストをPub/Subトピックに送ります。Dataflowジョブを使用して受信データを変換します。変換されたデータを使ってAI Platformに予測リクエストを送信します。予測を送信Pub/Subキューに書き込みます」です。<br>この問題では、高い計算コストの前処理を伴うデータセットを用いて学習したモデルについて、同などの前処理が必要なオンライン予測を実行する最適なアーキテクチャを選択することが求められています。高スループットのオンライン予測を実現するためには、エンドユーザーから予測リクエストを受けた瞬間から予測結果を返すまでのタイムラグを最小限に保つ一方で、高い計算コストのデータ前処理も迅速かつ効率的に実行する必要があるため、そのアーキテクチャ選択は重要です。各選択肢のアーキテクチャが前処理の効率性とスループット要件をどのように兼ね備えているのか詳細に評価することが求められます。<br>基本的な概念や原則：<br>AI Platform：機械学習モデルのトレーニング、デプロイ、予測を行うためのGoogle Cloudの統合サービスです。<br>前処理：機械学習モデルのトレーニングや予測のパフォーマンスを向上させるために、データのクレンジングや変換を行う工程です。<br>Pub/Sub：Google Cloudのリアルタイムメッセージングサービスで、大量のメッセージを生産者から消費者へ安全かつ信頼性高くルーティングすることができます。<br>Dataflow：大規模データのバッチおよびストリーム処理を行うためのGoogle Cloudのサービスです。前処理、バッチ処理、ETLタスクなどに利用できます。<br>Cloud Spanner：Google Cloudのフルマネージドなリレーショナルデータベースサービスで、地理的に分散されたデータの一貫性を保つことができる特性があります。<br>Cloud Functions：イベント駆動型のサーバレスコンピューティングサービスです。Pub/Subメッセージの公開やCloud Storageへのファイルアップロードなどのイベントに応じて自動的に実行されます。<br>正解についての説明：<br>（選択肢）<br>・入ってくる予測リクエストをPub/Subトピックに送ります。Dataflowジョブを使用して受信データを変換します。変換されたデータを使ってAI Platformに予測リクエストを送信します。予測を送信Pub/Subキューに書き込みます<br>この選択肢が正解の理由は以下の通りです。<br>まず、高スループットの予測リクエストを処理するために、Pub/Subトピックにリクエストを送信することは、そのリクエストをエンキューして一定の速度で処理できるようにする有効な手段です。そのため、前処理が必要な高コストな計算を、リソースの使用率を最適化しながら確実に処理できます。<br>次に、Dataflowは大量のデータをパイプライン化し、スケーリングするためのサーバレスなフレームワークであり、前処理が必要な高コストな計算に対して十分なパフォーマンスを提供します。<br>最後に、変換されたデータをAI Platformに予測リクエストとして送り込むことで、学習されたモデルによる予測を得ることができます。その結果は、後続の処理のためにPub/Subキューに書き込むことができます。これにより、前処理と予測が非同期に行われ、全体のシステムのスループットが向上します。<br>不正解の選択肢についての説明：<br>選択肢：前処理したデータでトレーニングしたモデルの精度を検証します。生データを使用し、リアルタイムで利用可能な新しいモデルを作成します。新しいモデルをオンライン予測のためにAI Platformにデプロイします<br>この選択肢が正しくない理由は以下の通りです。<br>前処理のコストが高いため、新たに学習させるモデルを作成するために生データを使用することは、時間とコストの大幅な増加につながります。<br>また、オンライン予測では予測レンダリングの高速化が求められるため、毎回新しいモデルを作成しデプロイするアプローチは適していません。<br>選択肢：入ってくる予測リクエストをCloud Spannerにストリーミングします。前処理ロジックを抽象化するビューを作成します。ビューに新しいレコードを毎秒クエリします。変換されたデータを使ってAI Platformに予測リクエストを送信します。予測をアウトバウンドPub/Subキューに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Spannerは高スループットのオンライン予測ケースには適していません。<br>また、前処理ロジックを抽象化するビュー作成と新しいレコードへの秒間クエリは、コストも計算リソースも高くつくため、効率的ではありません。<br>一方、正答の方は、Pub/SubとDataflowを連携することで効率的にデータの変換と予測リクエストの処理が可能です。<br>選択肢：受信予測リクエストをPub/Subトピックに送信します。メッセージがPub/Subトピックに公開されたときにトリガーされるCloud Functionをセットアップします。Cloud Functionsに前処理ロジックを実装します。変換されたデータを使用してAI Platformに予測リクエストを送信します。予測を送信Pub/Subキューに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Functionsは短時間の実行に最適化されており、計算コストの高い前処理に対しては適していません。<br>一方、Dataflowは大量のデータ変換・処理を効率的に扱うことが可能で、高計算コストの前処理に対して優れています。'>
<div class='choice'> 前処理したデータでトレーニングしたモデルの精度を検証します。生データを使用し、リアルタイムで利用可能な新しいモデルを作成します。新しいモデルをオンライン予測のためにAI Platformにデプロイします</div>
<div class='choice'> 受信予測リクエストをPub/Subトピックに送信します。メッセージがPub/Subトピックに公開されたときにトリガーされるCloud Functionをセットアップします。Cloud Functionsに前処理ロジックを実装します。変換されたデータを使用してAI Platformに予測リクエストを送信します。予測を送信Pub/Subキューに書き込みます</div>
<div class='choice'> 入ってくる予測リクエストをPub/Subトピックに送ります。Dataflowジョブを使用して受信データを変換します。変換されたデータを使ってAI Platformに予測リクエストを送信します。予測を送信Pub/Subキューに書き込みます</div>
<div class='choice'> 入ってくる予測リクエストをCloud Spannerにストリーミングします。前処理ロジックを抽象化するビューを作成します。ビューに新しいレコードを毎秒クエリします。変換されたデータを使ってAI Platformに予測リクエストを送信します。予測をアウトバウンドPub/Subキューに書き込みます</div>
</div>

<div class='question' data-multiple='false' data-question='問題16<br>あなたは、TensorFlowモデルのトレーニング時間のパフォーマンスをプロファイリングしており、Cloud Storage上の5TBのCSVファイルデータセット1つに対して、入力データパイプラインの非効率性が原因となっているパフォーマンスの問題に気づきました。そのため、入力パイプラインのパフォーマンスを最適化する必要があります。<br>パイプラインの効率を上げるために、最初にどのアクションを試すべきですか？' data-answer='2' data-explanation='解説<br>正解は「複数のCSVファイルに分割し、パラレルインターリーブ変換を使用します」です。<br>この問題では、大量のファイルデータの入力データパイプラインのパフォーマンス問題の解決策を見つけることが求められています。そのため、解答を検討する際には、大量のデータに対して適切に機能するデータ処理手法を理解している必要があります。選択肢をみると、データの分割、前処理、トレーニングデータの選定、そしてデータのシャッフル方法についての操作が提示されています。そのため、これらの手法が大量の入力データのパフォーマンス向上にどのように寄与するかを把握し、それらの中から最も効果的な手法を選択することが必要です。<br>基本的な概念や原則：<br>パラレルインターリーブ変換：TensorFlowで使用する入力パイプラインの効率化手法の一つです。複数のファイルからサンプルを交互に取り出すことで、データの読み込みを並列化し、パフォーマンスを改善します。<br>TensorFlow：機械学習モデルの作成とトレーニングをサポートするオープンソースフレームワークです。<br>Cloud Storage：Google Cloudの持続的でスケーラブルなオブジェクトストレージサービスです。大量のデータを保管し、共有することができます。<br>TFRecordファイル：TensorFlowのデータ形式の一つで、バイナリフォーマットのファイルです。複数のデータを一つのファイルにまとめることが可能で、データの読み込み効率を改善するために使われることがあります。<br>tf.data.Dataset.shuffle：TensorFlowのデータセットAPIのメソッドの一つで、データセットの要素をランダムにシャッフルします。これにより、モデルのトレーニング中に過学習を防ぐことができます。<br>正解についての説明：<br>（選択肢）<br>・複数のCSVファイルに分割し、パラレルインターリーブ変換を使用します<br>この選択肢が正解の理由は以下の通りです。<br>まず、TensorFlowモデルの訓練において大規模なデータセットを効率的に利用するためには、データパイプラインの効率化が重要です。そのため、CSVファイルを複数に分割することで、データの読み取り速度を向上させることができます。<br>さらに、パラレルインターリーブ変換を採用することで、複数のファイルからデータを並行してロードすることができます。これは、データパイプラインの効率性を格段に向上させ、結果としてトレーニング時間を短縮することができます。<br>したがって、大規模なCSVファイルを効率的に処理するための最初の手段として、ファイル分割とパラレルインターリーブ変換の使用は最適な選択と言えます。<br>不正解の選択肢についての説明：<br>選択肢：入力CSVファイルをTFRecordファイルに前処理します<br>この選択肢が正しくない理由は以下の通りです。<br>入力CSVファイルをTFRecordファイルに前処理することは、データの読み込み効率を改善する手法の一つですが、これだけでパフォーマンスが向上するとは限りません。問題の状況では、Cloud Storage上の大容量の一つのCSVファイルを対象としているため、ファイルを分割して並行して読み込むことで、より効果的な改善が期待できます。<br>選択肢：10GBのデータのサブセットをランダムに選択し、モデルをトレーニングします<br>この選択肢が正しくない理由は以下の通りです。<br>10GBのデータのサブセットをランダムに選択してトレーニングする方法は、全体のデータ量を減らすことでトレーニング時間を節約するものですが、これは入力データパイプラインを最適化するという問題の解決策にはなりません。<br>一方、複数のCSVファイルに分割し、パラレルインターリーブ変換を使用する方法は、データの読み込み速度を向上させることでパイプラインのパフォーマンスを最適化します。<br>選択肢：tf.data.Dataset.shuffleメソッドのreshuffle_each_iterationパラメータをtrueに設定します<br>この選択肢が正しくない理由は以下の通りです。<br>tf.data.Dataset.shuffleメソッドのreshuffle_each_iterationパラメータをtrueに設定することは、全データを毎回シャッフルすることであって、パフォーマンスの向上とは関連がありません。<br>これに対し、複数のCSVファイルに分割し、パラレルインターリーブ変換を使用すると、データのロードと前処理を並列化し、パフォーマンスを向上させることができます。'>
<div class='choice'> 入力CSVファイルをTFRecordファイルに前処理します</div>
<div class='choice'> tf.data.Dataset.shuffleメソッドのreshuffle_each_iterationパラメータをtrueに設定します</div>
<div class='choice'> 複数のCSVファイルに分割し、パラレルインターリーブ変換を使用します</div>
<div class='choice'> 10GBのデータのサブセットをランダムに選択し、モデルをトレーニングします</div>
</div>

<div class='question' data-multiple='false' data-question='問題17<br>あなたは、データセットをクリーンにしてCloud Storageのバケットに保存するパイプラインを開発したデータエンジニアリングチームで働いています。あなたはMLモデルを作成し、新しいデータが利用可能になるとすぐにモデルをリフレッシュするためにデータを使用したいと考えています。CI/CDワークフローの一環として、Google Kubernetes Engine（GKE）上でKubeflow Pipelinesのトレーニングジョブを自動的に実行したいと考えています。<br>このワークフローはどのようにアーキテクチャーすべきですか？' data-answer='2' data-explanation='解説<br>正解は「ストレージバケットで新しいファイルが利用可能になったときに、Pub/Subトピックにメッセージを送信するようにCloud Storageトリガーを設定します。Pub/SubトリガーのCloud Functionsを使用して、GKEクラスター上でトレーニングジョブを開始します」です。<br>この問題では、MLモデルのリフレッシュというタスクを効率的に自動化するソリューションが求められています。その際、新たに利用可能になったデータを使いたいという要望と、GKE上のKubeflow Pipelinesのトレーニングジョブを自動的に実行するCI/CDワークフローの確立が要求されています。したがって、データが利用可能になる個々の瞬間を捉え、トリガーとしてMLモデルのトレーニングジョブを発火させるシステムを設計することがこれらの要件を満たす必要があります。そのため、Cloud StorageトリガーやPub/Subトピック、Cloud Functionsなど、Google Cloudの自動化と統合に関連するサービスの理解が必要です。<br>基本的な概念や原則：<br>Cloud Storage：Google Cloudが提供する、高耐久性で持続的に利用可能なオブジェクトストレージサービスです。任意の場所からデータにアクセスでき、大量のデータを安全に保存できます。<br>Kubeflow Pipelines：機械学習ワークフローの作成、実行、監視を行うためのオープンソース準拠のプラットフォームです。Google Kubernetes Engine（GKE）上で実行され、CI/CDワークフローの一部としてトレーニングジョブを自動化するために使用されます。<br>Google Kubernetes Engine（GKE）：Google Cloudのコンテナ化されたアプリケーションのデプロイメント、スケーリング、管理を行うフルマネージドサービスです。<br>Pub/Sub：Google Cloudが提供するリアルタイムのメッセージングサービスです。データの生産者と消費者を結びつけ、任意の規模で即時にメッセージを配信します。<br>Cloud Functions：Google Cloudのイベントドリブンなサーバレス実行環境です。特定のイベントをトリガーにして任意のコードを自動で実行します。<br>Cloud Storageトリガー：新しいデータがCloud Storageにアップロードされたり、既存のデータが変更されたりしたときに、Cloud Functionsを起動する機能です。<br>Google Dataflow：大量のデータをリアルタイムで処理するためのフルマネージドサービスです。エラー処理やリトライなどの機能を自動で提供します。<br>正解についての説明：<br>（選択肢）<br>・ストレージバケットで新しいファイルが利用可能になったときに、Pub/Subトピックにメッセージを送信するようにCloud Storageトリガーを設定します。Pub/SubトリガーのCloud Functionsを使用して、GKEクラスター上でトレーニングジョブを開始します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud Storageのトリガー機能は、新しいファイルがバケットに追加されたことを検知し、そのことを他のサービスに通知するための仕組みです。これを利用することで、新たにデータが利用可能になったらすぐにトレーニングジョブを開始できます。<br>次に、その通知対象となるサービスがPub/Subです。Pub/SubはGoogle Cloudのメッセージングサービスで、リアルタイムにメッセージを通知するために活用できます。<br>そして、Pub/Subがメッセージを受け取ったときに発火するCloud Functionを作成します。このCloud Functionは、実際のトレーニングジョブをGKEクラスター上で開始するロールを持ちます。<br>このように、新しいデータが利用可能になった瞬間にMLモデルのリフレッシュを行うという要求を満たすための適切な仕組みを組み合わせた物なので、この選択肢が最適で正解です。<br>不正解の選択肢についての説明：<br>選択肢：Dataflowでパイプラインを構成し、Cloud Storageにファイルを保存します。ファイルが保存されたら、GKEクラスター上でトレーニングジョブを開始します<br>この選択肢が正しくない理由は以下の通りです。<br>Dataflowを使用しても新しいファイルがCloud Storageに保存されたときにトリガーされる自動的な通知機能がありません。よって、モデルをすぐにリフレッシュするためには新しいファイルを即座に検知することが必要なため、不適切な選択肢です。正解の選択肢では、Pub/SubとCloud Functionsを利用してこの問題を解決しています。<br>選択肢：App Engineを使って、新しいファイルがないかCloud Storageを継続的にポーリングする軽量のPythonクライアントを作成します。ファイルが到着次第、トレーニングジョブを開始します<br>この選択肢が正しくない理由は以下の通りです。<br>App Engineを用いたポーリングは非効率的であり、コストもかかります。<br>また、新しいデータが即時利用可能になることを保証できません。<br>それに対して、Cloud StorageトリガーとPub/Subを使用する方が、新しいファイルが利用可能になった場合にすぐに反応でき、リアルタイムでトレーニングジョブを実行できます。<br>選択肢：Cloud Schedulerを使ってジョブを定期的にスケジュールします。ジョブの最初のステップでは、Cloud Storageバケット内のオブジェクトのタイムスタンプをチェックします。前回の実行から新しいファイルがない場合は、ジョブを中断します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Schedulerを使ったアプローチは、新しいデータが利用可能になった瞬間にモデルをリフレッシュする必要があるシナリオには最適ではありません。Cloud Schedulerは定期的にタスクを実行しますが、新しいデータが入手可能になるタイミングを正確に予測することが難しいため、タスクの頻度が高すぎてリソースを浪費したり、低すぎて新しいデータをうまく取り込めなかったりする可能性があります。正解の方がリアルタイム性の要求をより満たしています。'>
<div class='choice'> Dataflowでパイプラインを構成し、Cloud Storageにファイルを保存します。ファイルが保存されたら、GKEクラスター上でトレーニングジョブを開始します</div>
<div class='choice'> App Engineを使って、新しいファイルがないかCloud Storageを継続的にポーリングする軽量のPythonクライアントを作成します。ファイルが到着次第、トレーニングジョブを開始します</div>
<div class='choice'> ストレージバケットで新しいファイルが利用可能になったときに、Pub/Subトピックにメッセージを送信するようにCloud Storageトリガーを設定します。Pub/SubトリガーのCloud Functionsを使用して、GKEクラスター上でトレーニングジョブを開始します</div>
<div class='choice'> Cloud Schedulerを使ってジョブを定期的にスケジュールします。ジョブの最初のステップでは、Cloud Storageバケット内のオブジェクトのタイムスタンプをチェックします。前回の実行から新しいファイルがない場合は、ジョブを中断します</div>
</div>


            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>