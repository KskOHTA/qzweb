<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Professional Machine Learning Engneer問題集 01</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">


<div class='question' data-multiple='false' data-question='問題13<br>あなたは住宅価格を予測するMLモデルを開発しています。データを準備しているときに、あなたは、重要な予測変数である最寄りの学校からの距離がしばしば欠損しており、分散が大きくないことに気づきます。予測には、データ中のすべてのインスタンス（行）が重要です。<br>欠損データをどのように扱うべきですか？' data-answer='0' data-explanation='解説<br>正解は「線形回帰を用いて欠損値を予測します」です。<br>この問題では、データセットにおける欠損データの扱いについて問われています。特にすべてのインスタンス（行）が予測に重要とされており、結果を決定するのに欠かせない特徴（最寄りの学校からの距離）のデータがしばしば欠けている状況が設定されています。問題解答時には、これらの情報を考慮することが必要です。また選択肢を見るときに、欠損データを単純に削除したり、置き換えたりする方法だけでなく、欠損値を予測することも選択肢に含まれているので、それらを評価することも重要です。<br>基本的な概念や原則：<br>欠損値の取り扱い：データに欠損が存在する場合、その取り扱いの方法が結果に大きな影響を及ぼす可能性があります。データを削除、補完、またはそのまま扱うなど、複数の手法を選択できます。<br>線形回帰：連続値を予測するための統計学的モデリング方法です。線形の関係を元に欠損値を予測するのに使用されます。<br>特徴クロッシング：異なる特徴間の相互作用を表現する手法です。多くの場合、カテゴリ変数や順序変数の組み合わせに使用されます。<br>ゼロ補完：欠損値を0で置き換える方法です。ただし、この方法はオリジナルデータの分布を歪める可能性があるため、慎重に使用する必要があります。<br>正解についての説明：<br>（選択肢）<br>・線形回帰を用いて欠損値を予測します<br>この選択肢が正解の理由は以下の通りです。<br>まず、欠損データをどのように扱うかは一般的にそのデータの性質によります。ここでの問題文では、最寄りの学校からの距離という重要な予測変数がしばしば欠損していること、そしてその変数の分散が大きくないことが述べられています。欠損値が頻繁に存在するため一部のデータを削除することは望ましくないですし、また予測に全てのデータの行が重要とされていますので毎回平均値や中心値をせっていするといった欠損値の埋め方も適切ではありません。<br>したがって、線形回帰を使用して欠損値を予測すると、欠損が適切に補完され、全体的なデータの予測精度を維持することができます。特に分散が大きくないデータの場合、線形回帰は一定のパターンを捉えやすいため、欠損データをうまく予測することができます。<br>不正解の選択肢についての説明：<br>選択肢：欠損値のある行を削除します<br>この選択肢が正しくない理由は以下の通りです。<br>欠損値のある行を削除すると、データセット中の重要な情報が失われ、モデルの精度に影響を及ぼす可能性があります。一方線形回帰を用いて欠損値を予測することで、データの欠損を補完し精度を保つことができます。<br>選択肢：欠損値を持たない別の列と特徴クロッシングを適用します<br>この選択肢が正しくない理由は以下の通りです。<br>特徴クロッシングは、特徴間の関係を捉える手法ですが、欠損値の補完には適していません。その代わりに、線形回帰を使って欠損値を予測することで、他の変数の情報を基に欠損値を補うことができます。<br>選択肢：欠損値をゼロで置き換えます<br>この選択肢が正しくない理由は以下の通りです。<br>欠損値をゼロで置き換えると、データの本質的な意味が失われ、分析結果が大きく偏る可能性があります。<br>それに対して、線形回帰を用いて欠損値を予測することで、データの全体的な傾向に基づいた推定値を得ることができます。'>
<div class='choice'> 線形回帰を用いて欠損値を予測します</div>
<div class='choice'> 欠損値のある行を削除します</div>
<div class='choice'> 欠損値を持たない別の列と特徴クロッシングを適用します</div>
<div class='choice'> 欠損値をゼロで置き換えます</div>
</div>

<div class='question' data-multiple='true' data-question='問題14<br>あなたは最近MLモデルを導入しました。デプロイから3ヶ月後、あなたはモデルが特定のサブグループでパフォーマンスが低下していることに気づきました。この性能の偏りは、訓練データにおけるクラスの不均衡によるものだとあなたは考えていますが、さらにデータを収集することはできません。<br>この要件を満たすために、どうすればよいですか？（2つ選択）' data-answer='1, 2' data-explanation='解説<br>正解は以下の通りです。<br>・少数クラスでのエラーに対してモデルにペナルティを課す目的を追加し、モデルを再学習させます<br>・既存のトレーニングデータをアップサンプルまたは再重み付けし、モデルを再トレーニングします<br>この問題では、既存のMLモデルのパフォーマンス低下とその原因の推定、そして限られた状況下での特定条件に対する対策を問われています。特に、今回は訓練データの不均衡に起因すると考えられるパフォーマンスの偏りが見受けられ、その上で新たなデータ収集が許されていないという制約があるため、既存のデータとモデルの利用による最適化の方法を模索する必要があります。選択肢について考察する際には、再トレーニングのアプローチとその特定のテクニックとの適用可能性を評価することが求められます。<br>基本的な概念や原則：<br>クラスの不均衡：訓練データセットにおけるクラス（カテゴリ）のレコードが他のクラスに比べて過剰または不足している状態です。これはモデルの学習に影響を与え、特定のクラスの性能を低下させる可能性があります。<br>ペナルティ：モデルが特定のエラーを犯した場合に適用される罰則です。これは、モデルが望ましくない予測を出さないように調整するための手法です。<br>再学習：訓練データの新たなセット、または調整された訓練データを用いて既存のモデルを再度学習させることです。これは、モデルのパフォーマンスを改善するための一般的な手法です。<br>アップサンプリング：少数派クラスのレコードを増やすためにデータセット内で同じレコードを複製するプロセスです。これはクラスの不均衡を解消する一つの手法です。<br>再重み付け：特定のクラスのレコードに対して、それが学習過程で獲得できる重みを増加あるいは減少させるプロセスです。これにより、モデルは特定のクラスのレコードをより重視するように調整されます。<br>正解についての説明：<br>（選択肢）<br>・少数クラスでのエラーに対してモデルにペナルティを課す目的を追加し、モデルを再学習させます<br>・既存のトレーニングデータをアップサンプルまたは再重み付けし、モデルを再トレーニングします<br>この選択肢が正解の理由は以下の通りです。<br>まず、少数クラスでのエラーに対してモデルにペナルティを課す目的を追加し、モデルを再学習させることは、クラス不均衡に起因するパフォーマンスの低下を解消するために有効な手法です。不均衡なクラスのモデルは、多数クラスに偏向しやすいため、少数クラスの誤識別に対して重みを増すことで、少数クラスの識別能力を向上させることが期待できます。<br>さらに、既存のトレーニングデータをアップサンプルまたは再重み付けすることでもこの問題を解決できます。アップサンプリングは少数クラスのサンプルを増加させ、ダウンサンプリングは多数クラスのサンプルを減少させることでクラス間のバランスを改善します。<br>一方、再重み付けは、各クラスの重要性を変更することでクラス間の不均衡を緩和します。これらの技術は、データ収集が困難な場合や追加のデータが利用できない場合に特に有用です。これらの方法は既存のデータを再利用するため、追加のデータ収集やラベリングの必要がありません。<br>したがって、現状の状況を考慮したとき、これらの選択肢が最も適切と言えます。<br>不正解の選択肢についての説明：<br>選択肢：パフォーマンスの高いサブグループのトレーニング例を削除し、モデルを再トレーニングします<br>この選択肢が正しくない理由は以下の通りです。<br>パフォーマンスの高いサブグループのトレーニング例を削除すると、モデルはマイナスの影響を受け、その有用性と予測能力が低下します。正解選択肢は、データの不均衡を調整する方法である対照的に、このアプローチはデータセットから有益な情報を失う可能性があります。<br>選択肢：多数派クラスとの相関が最も高い特徴を取り除きます<br>この選択肢が正しくない理由は以下の通りです。<br>特定の特徴を取り除くことは、データの不均衡を解決する効果的な手段ではありません。<br>また、多数派クラスと相関が高い特徴を取り除くと、モデルの性能に重大な影響を及ぼす可能性があります。<br>代わりに、エラーに対するペナルティを課すか、データをアップサンプルまたは再重み付けすることで、不均衡なクラス分布を補正できます。<br>選択肢：モデルを再展開し、ユーザーにモデルの動作を説明するラベルを提供します<br>この選択肢が正しくない理由は以下の通りです。<br>モデルを再展開し、ユーザーにモデルの動作を説明するラベルを提供することは、モデルのパフォーマンスが低下している問題を解決しません。<br>対照的に、エラーに対するペナルティの追加やデータの再重み付け、アップサンプルは、特定のサブグループにおける不均衡を緩和するため、データを再活用する効果的な手段です。'>
<div class='choice'> 多数派クラスとの相関が最も高い特徴を取り除きます</div>
<div class='choice'> 既存のトレーニングデータをアップサンプルまたは再重み付けし、モデルを再トレーニングします</div>
<div class='choice'> 少数クラスでのエラーに対してモデルにペナルティを課す目的を追加し、モデルを再学習させます</div>
<div class='choice'> パフォーマンスの高いサブグループのトレーニング例を削除し、モデルを再トレーニングします</div>
<div class='choice'> モデルを再展開し、ユーザーにモデルの動作を説明するラベルを提供します</div>
</div>

<div class='question' data-multiple='false' data-question='問題15<br>あなたは、世界中の顧客に衣類を販売する小売店で働いています。あなたには、MLモデルが安全な方法で構築されていることを確認するという任務が与えられています。具体的には、モデルで使用される可能性のある顧客の機密データを保護する必要があります。データサイエンスチームが使用している機密データを含む4つのフィールド（AGE、IS_EXISTING_CUSTOMER、LATITUDE_LONGITUDE、SHIRT_SIZE）を特定しました。データサイエンスチームがトレーニング目的でデータを利用できるようにする前に、データをどうする必要がありますか？' data-answer='3' data-explanation='解説<br>正解は「ハッシュ化されたダミー値を使ってすべてのフィールドをトークン化し、実際の値を置き換えます」です。<br>この問題では、安全にMLモデルを構築するために機密情報をどのように保護すべきかを問われています。問題文から、4つの特定のフィールドに機密データが含まれているとわかります。そのため、これらのフィールドを適切に処理する方法を理解し選択することが重要です。ハッシュ化、PCA、丸め処理、データ削除など、いくつかの手法が出てきますが、それぞれがデータの保護レベルにどのような影響を及ぼすか、またその結果がデータ科学チームの作業にどう影響するかを考察しながら適切な手法を選択する必要があります。<br>基本的な概念や原則：<br>機密データ：個人や企業が非公開にしているデータのことです。保護を必要とするデータには、個人情報、顧客情報、企業の秘密情報などが含まれます。<br>トークン化：一定のルールに基づいて元のデータを別の表現に変換することです。機密データの保護のために使われ、元のデータを復元するための情報は別途管理されます。<br>ハッシュ化：データを一定の長さの数値や文字列に変換することです。元のデータから一定の値を生成しますが、その逆は通常不可能とされています。機密データの保護や、データの一貫性確認に利用されます。<br>ダミー値：本来の値に代わって使用する仮の値のことです。機密データの保護や、データ分析の際に存在しないデータを表現するために用いられます。<br>主成分分析（PCA）：多数の変数から共通となる主成分を抽出し、分散が最大となるような主成分を探す手法です。次元削減に用いられますが、元データの特性を保つことはできません。<br>データ丸め：データの精度を下げる手法であり、データの量を減らす目的で用いられます。データの機密性を保護するには不適切です。<br>データ削除：データの一部または全部を削除することです。データの機密性を保護するために使用されますが、削除後のデータの利用価値は下がります。<br>正解についての説明：<br>（選択肢）<br>・ハッシュ化されたダミー値を使ってすべてのフィールドをトークン化し、実際の値を置き換えます<br>この選択肢が正解の理由は以下の通りです。<br>まず、ハッシュ化されたダミーデータを使ってフィールドをトークン化するというアプローチにより、各フィールドの実際の値を置き換えて、元の顧客情報を識別できなくします。この置き換え作業が実行された後でも、機械学習のモデルは依然として個々の顧客レコードが一貫性を持つためトレーニングに利用することができます。この方法が適切なのは、モデルが結果を予測する際に顧客の実際のデータを必要としません。モデル訓練の目的は、入力データ（この場合、未知化された各フィールドの値）からパターンを学び、新しいデータに対する予測を行うことなので、この方法で問題はなく、同時に顧客の機密データも保護されます。<br>不正解の選択肢についての説明：<br>選択肢：主成分分析（PCA）を使用して、4つの敏感なフィールドを1つのPCAベクトルに減らします<br>この選択肢が正しくない理由は以下の通りです。<br>主成分分析（PCA）は複数の特徴を圧縮して新しい特徴を作り出しますが、その過程で敏感な個人情報を保護する機能がありません。PCAベクトルから元のデータを逆推定する可能性があります。<br>一方、ハッシュ化されたダミー値でトークン化すると、個人情報を適切に保護できます。<br>選択肢：AGEを分位数に入れてデータを粗くし、LATITUDE_LONGTTUDEを単精度に丸めます。他の2つのフィールドはすでに可能な限り粗くなっています<br>この選択肢が正しくない理由は以下の通りです。<br>AGEを分位数に入れて粗くしたり、LATITUDE_LONGITUDEを単精度に丸めたりしても、顧客の個人データを完全に匿名化するわけではありません。<br>一方、ハッシュ化されたダミー値を用いてフィールドをトークン化すると、実際の値を完全に置き換えることができ、情報漏洩のリスクを大幅に減らすことができます。<br>選択肢：センシティブなデータフィールドをすべて削除し、データサイエンスチームにセンシティブでないデータを使ってモデルを構築するよう依頼します<br>この選択肢が正しくない理由は以下の通りです。<br>フィールドを完全に削除すると、データサイエンスチームが予測モデルを構築する際に重要な情報が欠落し、モデルの性能に影響を与える可能性があります。その代わりに、ハッシュ化されたダミー値を使用してフィールドをトークン化すると、データの大まかなパターンを保持しながらセンシティブな情報を適切に保護できます。'>
<div class='choice'> センシティブなデータフィールドをすべて削除し、データサイエンスチームにセンシティブでないデータを使ってモデルを構築するよう依頼します</div>
<div class='choice'> 主成分分析（PCA）を使用して、4つの敏感なフィールドを1つのPCAベクトルに減らします</div>
<div class='choice'> AGEを分位数に入れてデータを粗くし、LATITUDE_LONGTTUDEを単精度に丸めます。他の2つのフィールドはすでに可能な限り粗くなっています</div>
<div class='choice'> ハッシュ化されたダミー値を使ってすべてのフィールドをトークン化し、実際の値を置き換えます</div>
</div>

<div class='question' data-multiple='false' data-question='問題16<br>あなたは規制対象の保険会社のMLエンジニアです。あなたは、潜在的な顧客からの保険申請を受け入れるか拒否するかを決定する保険承認モデルの開発を依頼されています。モデルを構築する前に、どのような要素を考慮すべきですか？' data-answer='3' data-explanation='解説<br>正解は「トレーサビリティ、再現性、説明可能性」です。<br>この問題では、規制対象の保険会社のMLエンジニアという特殊な状況と、モデル開発前に考慮すべき要素について理解することが求められています。規制対象という特性から、法律や規制へのコンプライアンスが重要になるでしょう。また、選択肢に出てくる概念全てが重要だと考えられますが、重要なのはその適用可能性で、これらを正しく理解し、制約と目標に照らし合わせることが必要です。<br>基本的な概念や原則：<br>トレーサビリティ：MLモデルの訓練データやパラメータ、バージョンを後から追跡できる能力です。正確さと信頼性を向上させるために必要です。<br>再現性：MLモデルが構築時と同じ環境とデータで同じ結果を出力する能力です。モデルの性能を評価し、調整する際に重要です。<br>説明可能性：MLモデルの挙動や予測理由を明確に説明できる度合いです。規制対象の業界では特に重要で、モデルの横断的な理解や監査を可能にします。<br>フェデレーテッドラーニング：データプライバシーを保ちながら、複数のデバイスまたはサーバー上のローカルデータでMLモデルを訓練する手法です。<br>差分プライバシー：データセットから特定の個人を特定できないようにするプライバシー保護手法です。統計的な結果を公開しつつ、個々のデータの秘密を保護します。<br>正解についての説明：<br>（選択肢）<br>・トレーサビリティ、再現性、説明可能性<br>この選択肢が正解の理由は以下の通りです。<br>保険業界などの規制対象の業界では、特にMLモデルの動作について透明性を確保し、各結果がどのように得られたかを説明することが必要です。そのため、トレーサビリティ、再現性、そして説明可能性といった要素が重視されます。<br>トレーサビリティは、MLモデルがなぜ特定の出力を生成したのかを後から辿ることができる能力を意味します。この要素が求められる理由は、判断を下すための根拠を明確にするとともに、予測が誤っていた場合に問題の原因を特定するためです。<br>再現性は、同じ入力を与えたときにMLモデルが同じ結果を出力すべきであるという原則を表しています。これにより、モデルの予測が信頼性と一貫性を持つことを保証します。<br>最後に説明可能性は、MLモデルの動作を非専門家に対しても理解しやすく説明できる能力を指します。規制対象の業界では、顧客や規制当局が要求する場合があり、その解釈や説明が求められます。こうした要素の考慮により、規制遵守に対するリスクを減らすことができます。<br>不正解の選択肢についての説明：<br>選択肢：次元削減、再現性、説明可能性<br>この選択肢が正しくない理由は以下の通りです。<br>レダクションは、重要な特徴量を抽出するという点では有効かもしれませんが、モデルの動作の透明性を確保する、という観点では関係がありません。<br>一方、トレーサビリティはモデルの動作とそれが生じた理由を追跡できる能力を指し、これは規制が関わる業界で重要です。再現性と説明可能性とともに、MLモデルの開発に必要な要素です。<br>選択肢：フェデレーテッドラーニング、再現性、説明可能性<br>この選択肢が正しくない理由は以下の通りです。<br>フェデレーテッドラーニングは分散型の機械学習技術であり、各デバイス上で計算を行う特性があります。<br>しかし、規制対象の保険会社の機械学習モデル開発では、元のデータが存在するデバイスに分散するような状況は想定されていないため、フェデレーテッドラーニングは必要ありません。<br>一方で、モデルの決定を説明し、忠実に再現するためには、トレーサビリティが必要です。<br>選択肢：差分プライバシー、フェデレーテッドラーニング、説明可能性<br>この選択肢が正しくない理由は以下の通りです。<br>差分プライバシーやフェデレーテッドラーニングは、データプライバシーの確保手段として由々しき重要性を持ちますが、規制対象の保険会社が保険承認モデルを開発するという特定の状況においては、トレーサビリティと再現性の考慮が必要です。これらは保険申請の承認や拒否の決定根拠を明確にし、適切に対応出来るようにするためです。'>
<div class='choice'> 次元削減、再現性、説明可能性</div>
<div class='choice'> フェデレーテッドラーニング、再現性、説明可能性</div>
<div class='choice'> 差分プライバシー、フェデレーテッドラーニング、説明可能性</div>
<div class='choice'> トレーサビリティ、再現性、説明可能性</div>
</div>

<div class='question' data-multiple='false' data-question='問題17<br>あなたの組織はオンライン掲示板を管理しています。数カ月前、掲示板で有害な言葉やいじめが増加していることを発見しました。あなたは、特定のコメントを有毒または有害なものとしてフラグを立てる自動テキスト分類器を導入しました。現在、一部のユーザーから、自分たちの宗教に言及した良識的なコメントが悪口として誤って分類されているという報告が寄せられています。さらに調べてみると、特定の代表的でない宗教グループに言及したコメントに対して、分類器の誤検出率が高いことがわかりました。あなたのチームには限られた予算しかなく、すでに過大な負担を強いられています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「これらのフレーズが無害な方法で使用されている合成トレーニングデータを追加します」です。<br>この問題では、テキスト分類器による特定の言及に対する誤検出という課題に対する解決方法を選ぶ必要があります。制限された予算やチームの負担を考慮に入れつつ、モデルの性能改善を図る必要があります。選択肢を検討する際には、現在のモデルの限界とそれを解決する戦略の効率性を考え、それゆえに単にモデルの閾値を調整したり、分類器自体を置き換えたりするのではなく、具体的な問題に対応するための方法を探す必要があります。<br>基本的な概念や原則：<br>自動テキスト分類器：テキストの内容を解析し、あらかじめ定義されたカテゴリに自動的に分類する機械学習ベースのシステムです。<br>合成トレーニングデータ：人工的に生成される教師データです。特定のシチュエーションや現象が元のデータセットに不足している場合に使用します。<br>機械学習モデルの誤検出に対する対策：モデルの誤った予測を修正するために、不適切な予測を引き起こす要素の例を教師データに追加します。これによりモデルの精度が向上します。<br>モデルの閾値調整：機械学習モデルの出力の解釈を調整する方法の一種で、特定の分類の予測を増やすか減らすことができます。ただし、一部の誤検出問題はこの方法だけで解決することは困難です。<br>正解についての説明：<br>（選択肢）<br>・これらのフレーズが無害な方法で使用されている合成トレーニングデータを追加します<br>この選択肢が正解の理由は以下の通りです。<br>自動テキスト分類器は、訓練データに基づいて評価を行います。もし訓練データに特定のフレーズや表現が偏って含まれている場合、それらのフレーズや表現を含むテキストは誤って"有害"または"不適切"として分類される可能性があります。<br>したがって、問題の特定の宗教への言及について誤って"有害"と判断される問題を解消するためには、分類器の訓練データにこれらのフレーズが無害な方法で使用されている例を追加することが有効です。これにより分類器は、これらの特定の表現が実際には有害でないことを学習します。ので、訓練データを増やすという選択肢は、予算内で実現可能であり、この問題を解決するには最適なステップです。<br>不正解の選択肢についての説明：<br>選択肢：モデルを削除し、人間によるモデレーションに置き換えます<br>この選択肢が正しくない理由は以下の通りです。<br>モデルを削除し、人間によるモデレーションに置き換えるという方法は、既に過大な負担を強いられているチームにさらなる負担を与えます。<br>一方、合成トレーニングデータを追加することで、モデルは問題のフレーズが無害な方法で使用されている場合を学習し、誤検出率を低減できます。<br>選択肢：モデルを別のテキスト分類器で置き換えます<br>この選択肢が正しくない理由は以下の通りです。<br>モデルを別のテキスト分類器で置き換えるというアプローチは、現在の問題を解決する保証がありません。<br>また、この方法は新しい分類器の導入や学習にコストがかかります。<br>それに対して、正解の選択肢の"合成トレーニングデータを追加する"方法は、既存のモデルを調整し、問題の特定の領域に対して改善を図ることを可能にします。<br>選択肢：有害または有害とみなされるコメントの閾値を引き上げます<br>この選択肢が正しくない理由は以下の通りです。<br>閾値を引き上げることで誤検出を減らすことは可能ですが、一方で真に有害なコメントを見逃すリスクが高まります。反対に、無害な方法で使用されているフレーズの合成トレーニングデータを追加すると、モデルはそれらのフレーズを正しく分類することを学習でき、誤検出の問題を解決できます。'>
<div class='choice'> これらのフレーズが無害な方法で使用されている合成トレーニングデータを追加します</div>
<div class='choice'> モデルを別のテキスト分類器で置き換えます</div>
<div class='choice'> 有害または有害とみなされるコメントの閾値を引き上げます</div>
<div class='choice'> モデルを削除し、人間によるモデレーションに置き換えます</div>
</div>

<div class='question' data-multiple='false' data-question='問題18<br>あなたは、クラウドベースのバックエンドシステムを使用してトレーニングジョブを実行するデータサイエンテストのチームを管理しています。このシステムは管理が非常に難しくなっており、代わりにマネージドサービスを使用したいと考えています。あなたが一緒に働いているデータサイエンテストは、Keras、PyTorch、theano、Scikit-learn、カスタムライブラリなど、さまざまなフレームワークを使用しています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「AI Platformのカスタムコンテナ機能を使用して、任意のフレームワークを使用してトレーニングジョブを受信します」です。<br>この問題では、データサイエンテストのチームが使っているさまざまなツールやフレームワークを扱える、管理が容易なクラウドベースのサービスを探すことが求められています。要件から、マネージドサービスであり、Keras、PyTorch、theano、Scikit-learn、カスタムライブラリなどの異なるフレームワークに対応できるものが必要であることがわかります。そのため、マネージドサービスであり、また各種フレームワークを扱えるものを選ぶ必要があります。選択肢の各サービスがこれらの要件をどの程度満たすかを評価することが問題解決の鍵です。<br>基本的な概念や原則：<br>AI Platform：Google Cloudの統合されたエンドツーエンドAIおよび機械学習（ML）プラットフォームです。データサイエンスとMLワークロードを迅速に開発、デプロイ、運用できます。<br>カスタムコンテナ：Google CloudのAI Platformで利用可能な機能で、様々なフレームワークを使用したトレーニングや予測モデルをデプロイすることができます。これにより、一貫性のある環境とコードの再利用性が向上します。<br>Kubeflow：MLワークロードをKubernetesで扱うためのオープンソースプロジェクトです。機械学習パイプラインの作成や管理を容易にしますが、セットアップや管理が複雑です。<br>Google Kubernetes Engine：Google CloudのマネージドKubernetesサービスです。コンテナ化されたアプリケーションを効率的にデプロイ、スケール、管理するための環境を提供します。<br>Compute Engine：Google Cloudの仮想マシンインスタンスを実行するIaaSプラットフォームです。独自のVMイメージライブラリを作成して公開することも可能ですが、管理が煩雑になる可能性があります。<br>Slurmワークロードマネージャー：オープンソースのジョブスケジューラーで、ワークロードを管理するためのフレームワークを提供します。クラウドリソース上での運用には設定と管理が必要です。<br>正解についての説明：<br>（選択肢）<br>・AI Platformのカスタムコンテナ機能を使用して、任意のフレームワークを使用してトレーニングジョブを受信します<br>この選択肢が正解の理由は以下の通りです。<br>AI Platformのカスタムコンテナ機能は、データサイエンテストが任意の機械学習フレームワークを使用してトレーニングジョブを実行することを可能にします。これは、指定された各種のフレームワーク、Keras、PyTorch、theano、Scikit-learn、カスタムライブラリをサポートすることを意味します。<br>さらに、AI Platformはマネージドサービスであり、それはクラウドベースのシステムよりもはるかに管理が容易であるという特性を持っています。フレームワークのデプロイ、スケーリング、メンテナンスなどの面倒なタスクをGoogle Cloudが自動的に処理するため、データサイエンテストはモデルの設計とトレーニングに集中できます。<br>したがって、AI Platformのカスタムコンテナの使用は、このシナリオに最適な解決策と言えます。<br>不正解の選択肢についての説明：<br>選択肢：KubeflowをGoogle Kubernetes Engine上で実行するように設定し、TF Jobを通じてトレーニングジョブを受け取ります<br>この選択肢が正しくない理由は以下の通りです。<br>KubeflowのTF Jobは主にTensorFlowのトレーニングジョブを扱うため、KerasやPyTorchなど他のフレームワークの使用が制限されます。<br>一方で、AI Platformのカスタムコンテナ機能を使えば、任意のフレームワークでトレーニングジョブを無理なく実行できます。つまり、必要なフレームワーク全てをカバーできる選択肢はAI Platformのカスタムコンテナ機能を使用することです。<br>選択肢：Compute Engine上にVMイメージのライブラリを作成し、これらのイメージを集中型リポジトリに公開します<br>この選択肢が正しくない理由は以下の通りです。<br>Compute Engine上にVMイメージのライブラリを作成しリポジトリに公開しても、その管理負担は軽減はされません。<br>したがって、マネージドサービスを希望している問題の要件を満たすことはできません。<br>また、正解のAI Platformのカスタムコンテナを活用することで、一元的に各種フレームワークの管理と運用が可能です。<br>選択肢：Slurmワークロードマネージャーをセットアップして、クラウドインフラ上で実行するようスケジュールできるジョブを受け取ります<br>この選択肢が正しくない理由は以下の通りです。<br>Slurmワークロードマネージャーはマネージドサービスではないため、管理が難しくなる問題を解決しません。<br>また、フレームワークの選択が自由でない可能性もあります。<br>一方、AI Platformのカスタムコンテナ機能は、任意のフレームワークを使用しマネージドサービスとして運用することができます。'>
<div class='choice'> AI Platformのカスタムコンテナ機能を使用して、任意のフレームワークを使用してトレーニングジョブを受信します</div>
<div class='choice'> Slurmワークロードマネージャーをセットアップして、クラウドインフラ上で実行するようスケジュールできるジョブを受け取ります</div>
<div class='choice'> Compute Engine上にVMイメージのライブラリを作成し、これらのイメージを集中型リポジトリに公開します</div>
<div class='choice'> KubeflowをGoogle Kubernetes Engine上で実行するように設定し、TF Jobを通じてトレーニングジョブを受け取ります</div>
</div>

<div class='question' data-multiple='false' data-question='問題19<br>あなたは世界的な靴店のMLエンジニアです。あなたは会社のウェブサイトのMLモデルを管理しています。あなたは、ユーザーの購買行動と他のユーザとの類似性に基づいて、ユーザに新しい商品を推薦するモデルを構築するよう求められています。<br>この要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「協調ベースのフィルタリングモデルを構築します」です。<br>この問題では、靴販売ウェブサイトのユーザーに対し、その人の購入行動と他のユーザーとの類似性に基づいて新商品を推薦するMLモデルを開発するという状況が提示されています。選択肢を評価する際、そのモデルがユーザーの行動と他のユーザーとの類似性を考慮できるもの、特にレコメンダシステムに一般的に使用されるアプローチが何かを思い浮かべてみると助けになるでしょう。<br>基本的な概念や原則：<br>協調フィルタリング：ユーザー間の類似性やアイテム間の類似性を計算することで推薦を行うアルゴリズムです。ユーザーの過去の行動や評価パターンを元に、他のユーザーとの類似性を見つけ出し、推薦を行います。<br>分類モデル：特定のクラスやカテゴリにデータを分類するためのモデルです。ユーザーの個々の購買行動を分類するのに使うことがありますが、ユーザー間の類似性に基づく推薦には適していません。<br>知識ベースのフィルタリング：専門家の意見や事前の知識を用いて推薦を行う方式です。ユーザーの購買行動や他のユーザーとの類似性に基づかないため、このケースには適していません。<br>回帰モデル：連続値の目的変数を予測するためのモデルです。ユーザー間の類似性に基づく商品推薦ではなく、変数間の関係性をベースに予測を行います。<br>正解についての説明：<br>（選択肢）<br>・協調ベースのフィルタリングモデルを構築します<br>この選択肢が正解の理由は以下の通りです。<br>協調ベースのフィルタリングモデルを構築すると、ユーザーの購買行動と他のユーザとの類似性に基づいて推薦する商品を推定することができます。協調ベースのフィルタリングは、過去のユーザーの行動や評価をもとに新しい推薦を行う手法であり、他のユーザーが購入や評価したアイテムに基づいて推薦を行います。この方法は、新しい商品についての情報が少ない場合や、ユーザーの詳細なプロファイル情報が利用できない場合でも、良質な推薦を提供することができます。<br>したがって、個々のユーザに新しい商品を推薦するという要件を満たすためには、協調ベースのフィルタリングモデルを構築する方が適しています。<br>不正解の選択肢についての説明：<br>選択肢：分類モデルの構築<br>この選択肢が正しくない理由は以下の通りです。<br>分類モデルは特定の事象を決定するのに適していますが、新商品の推薦のようなケースでは、他のユーザとの購買行動の類似性に基づいて推薦する必要があるため、協調ベースのフィルタリングモデルが適しています。このモデルはユーザ間の類似性を利用するため、購買行動に基づく商品推薦に最適です。<br>選択肢：知識ベースのフィルタリングモデルを構築します<br>この選択肢が正しくない理由は以下の通りです。<br>知識ベースのフィルタリングモデルは、推奨される商品がユーザーの指定した基準を満たすことを確認するために使用されます。これはユーザーの購買行動と他のユーザーとの類似性に基づいて推奨するという要件とは一致しません。逆に協調ベースのフィルタリングは、他の類似ユーザーの行動を基に推奨するため、要件を完全に満たします。<br>選択肢：予測変数として特徴を使用して回帰モデルを構築します<br>この選択肢が正しくない理由は以下の通りです。<br>回帰モデルは予測変数と目的変数の関係をモデル化しますが、ユーザ間の類似性に基づく商品推薦には適していません。<br>それに対して、協調フィルタリングモデルはユーザー間の類似性に基づく推薦を行うため、この問題の要件を適切に満たします。'>
<div class='choice'> 知識ベースのフィルタリングモデルを構築します</div>
<div class='choice'> 協調ベースのフィルタリングモデルを構築します</div>
<div class='choice'> 予測変数として特徴を使用して回帰モデルを構築します</div>
<div class='choice'> 分類モデルの構築</div>
</div>

<div class='question' data-multiple='false' data-question='問題20<br>Vertex AI Workbenchのユーザー管理型ノートブックで、組み込みの分散XGBoostモデルを実験しています。BigQueryを使用して、以下のクエリを使用してデータをトレーニングセットと検証セットに分割します：<br>CREATE OR REPLACE TABLE `myproject.mydataset.training` AS<br>(SELECT * FROM `myproject.mydataset.mytable` WHERE RAND() &lt;= 0.8);<br>CREATE OR REPLACE TABLE `myproject.mydataset.validation` AS<br>(SELECT * FROM `myproject.mydataset.mytable` WHERE RAND() &lt;= 0.2);<br>モデルを訓練した後、受信者動作特性曲線下面積（AUC ROC）値0.8を達成しましたが、モデルを実運用にデプロイした後、モデルの性能がAUC ROC値0.65に低下していることに気づきました。<br>どのような問題が発生している可能性が高いですか？' data-answer='3' data-explanation='解説<br>正解は「トレーニングレコードとバリデーションレコードを保持するために作成したテーブルは、いくつかのレコードを共有しており、最初のテーブルのすべてのデータを使用していない可能性があります」です。<br>この問題では、データ分析の領域で一般的に見られる現象を理解する能力が求められています。BigQueryでトレーニングデータセットと検証データセットを生成した後、モデルの性能がトレーニングと実運用で大きく変化した理由について問われています。モデルの評価指標であるAUC ROC値の大幅な変化が観測されたので、データ分割の方法が問題を引き起こしている可能性が示されています。データ分割時のランダム関数の挙動、トレーニングとテストデータの重複、データのバイアス、データ量の検討等、データセットの生成やモデルの性能の評価に関する知識を適用して解答を選ぶべきでしょう。<br>基本的な概念や原則：<br>BigQuery：Google Cloudのフルマネージドなビッグデータ分析サービスです。大量のデータに対してSQLクエリを使って高速な分析が可能です。<br>Vertex AI Workbench：Google CloudのAI開発プラットフォームです。統合されたJupyterLab環境で機械学習モデルの開発や分析が行えます。<br>XGBoost：勾配ブースティングに基づいた広く使用されている機械学習アルゴリズムで、効率性と予測性能が高いです。回帰、分類、ランキングなどの問題に適用できます。<br>RAND()関数：SQLにおいてランダムな数値を生成する関数です。通常は0から1までの範囲で浮動小数点数を生成します。<br>トレーニングデータとバリデーションデータ：機械学習モデルの訓練と評価に使用されるデータです。適切に分割しなければ、過学習やモデルの評価に影響を与える可能性があります。<br>受信者動作特性曲線下面積（AUC ROC）：機械学習モデルの評価指標で、モデルがランダムに選ばれた肯定的なインスタンスをランダムに選ばれた否定的なインスタンスよりも高くランク付けする確率を示します。値が1に近いほど、モデルの性能が良いと評価されます。<br>リーク：トレーニングデータとテストデータの間で情報が共有されることで、モデルの性能評価が実際よりも高く見積もられる現象です。この問題は一般的に、適切なデータ分割や交差検証の手法によって防止します。<br>正解についての説明：<br>（選択肢）<br>・トレーニングレコードとバリデーションレコードを保持するために作成したテーブルは、いくつかのレコードを共有しており、最初のテーブルのすべてのデータを使用していない可能性があります<br>この選択肢が正解の理由は以下の通りです。<br>まず、トレーニングデータとバリデーションデータを生成する際に使用されたクエリでは、`RAND()`関数がそれぞれのクエリで別々にランダムな値を生成します。<br>したがって、`0.8`以下の確率で選択されるトレーニングデータと、`0.2`以下の確率で選択される検証データとが一部重複する可能性があります。<br>これは問題で、一部のデータがトレーニングと検証の両方で使用されると、モデルはその特定のデータに対する予測性能が高くなり、過度に楽観的なバリデーション性能が出る可能性があります。その結果、AUC ROCが0.8と高く出る可能性があります。<br>しかし、未知のデータ、つまり本番環境での予測にはその性能が反映されないため、本番環境でのAUC ROCが0.65と低下する恐れがあります。<br>正しい方法は、元のテーブルから一度だけランダムにデータを抽出し、それを訓練用と検証用に分けることです。これにより、訓練用データと検証用データの重複を防ぐことができます。<br>不正解の選択肢についての説明：<br>選択肢：本番環境でトレーニングに偏りがあります<br>この選択肢が正しくない理由は以下の通りです。<br>問題文では本番環境でのトレーニングについて触れておらず、また問題の文脈から、データの分割に問題があることが主な原因であることが示唆されています。そのため、本番環境のトレーニング偏りが原因であるとするこの選択肢は問題の要旨と一致していません。<br>選択肢：十分な量のトレーニングデータがありません<br>この選択肢が正しくない理由は以下の通りです。<br>適切なトレーニングデータ量がないというのは、AUC ROCが0.8も出るとは思えないため、この選択肢は正しそうに思えます。<br>しかし、問題の説明からはデータ量が少ないということ実を裏付ける証拠はありません。正解の選択肢にあるように、問題はトレーニングとバリデーションセットでデータが重複していることによる可能性が高いです。<br>選択肢：RAND()関数は両方のケースで0.2より小さい数値を生成したので、検証テーブルのすべてのレコードはトレーニングテーブルにも存在しています<br>この選択肢が正しくない理由は以下の通りです。<br>RAND()関数は各レコードに対して別々に実行され、その結果は同じレコードの異なる呼び出し間で共有されません。<br>したがって、検証テーブルの全てのレコードがトレーニングテーブルに存在するとは限らないため、この選択肢は正しくないです。'>
<div class='choice'> RAND()関数は両方のケースで0.2より小さい数値を生成したので、検証テーブルのすべてのレコードはトレーニングテーブルにも存在しています</div>
<div class='choice'> 十分な量のトレーニングデータがありません</div>
<div class='choice'> 本番環境でトレーニングに偏りがあります</div>
<div class='choice'> トレーニングレコードとバリデーションレコードを保持するために作成したテーブルは、いくつかのレコードを共有しており、最初のテーブルのすべてのデータを使用していない可能性があります</div>
</div>

<div class='question' data-multiple='false' data-question='問題21<br>あなたは、6人1組で5分間の対戦を行う人気のオンラインマルチプレイヤーゲームを運営するゲーム会社に勤めています。毎日多くの新しいプレイヤーが登場します。あなたは、レディー状態のプレーヤーをリアルタイムで自動的にチームに割り当てるモデルを構築する必要があります。ユーザー調査によると、同じようなスキルレベルのプレイヤーで対戦した方がゲームを楽しめるようです。<br>モデルのパフォーマンスを測定するために、どのビジネス指標を追跡すべきですか？' data-answer='2' data-explanation='解説<br>正解は「ユーザー1人当たりの1日の対戦回数で測定されるユーザーエンゲージメント」です。<br>この問題では、オンラインマルチプレイヤーゲームの運営会社でプレイヤーを自動的にチームに割り当てるモデルを構築しているというシナリオが示されています。問題は、このモデルのパフォーマンスを測定するための最適なビジネス指標を選択することです。ここで重要なのは、ユーザーは"同じスキルレベルのプレイヤーとの対戦"が楽しいと感じているという調査結果です。これを念頭に置きながら、各選択肢がユーザーの楽しさやエンゲージメントをどのように反映しているかを考えることが重要です。<br>基本的な概念や原則：<br>ユーザーエンゲージメント：ユーザーが製品やサービスとどの程度積極的に関わっているかを測定する指標です。ユーザー1人当たりの1日の対戦回数は、ゲームプレイヤーのエンゲージメントを的確に測定します。<br>スキルレベル：ユーザーの技術や知識の水準を示します。ゲームの楽しさを高めるためには、同じスキルレベルのプレーヤー同士の対戦が重要です。<br>リアルタイム：即座に情報を提供することです。オンラインマルチプレイヤーゲームにおいては、リアルタイムのプレーヤー割り当てが重要です。<br>チーム割り当て：プレーヤーが対戦を行う単位を作成するプロセスです。同じスキルレベルのプレーヤーを同じチームに割り当てることが理想的です。<br>平均待ち時間：サービスへのリクエストからレスポンスが返るまでの時間です。適切なパフォーマンス指標ではありますが、このケースではユーザーエンゲージメントが最も重要です。<br>正解についての説明：<br>（選択肢）<br>・ユーザー1人当たりの1日の対戦回数で測定されるユーザーエンゲージメント<br>この選択肢が正解の理由は以下の通りです。<br>ユーザーエンゲージメントという指標を追跡することで、プレーヤーがゲームにどれほど参加しているかを定量化することができます。本問題の背景には、各プレーヤーが適切なスキルレベルの対戦相手とマッチングされると、一般的にゲーム体験が向上し、より多くの時間をゲームに投資するようになるという仮説があります。それゆえ、"ユーザー1人当たりの1日の対戦回数"という指標は、新しいマッチングモデルの性能を評価するのに適切な指標と言えます。これは、モデルが適切に機能し、プレーヤーがより良いマッチングを経験すると、その結果としてより多くの対戦を行うことになるからです。これによってユーザーエンゲージメントが向上することを確認できれば、新たなマッチングモデルが目的を達成したと評価できます。<br>不正解の選択肢についての説明：<br>選択肢：選手がチームに割り当てられるまでの平均待ち時間<br>この選択肢が正しくない理由は以下の通りです。<br>選手がチームに割り当てられるまでの平均待ち時間は、モデルのパフォーマンスを直接的に反映しません。仮に待ち時間が短くても、スキルレベルが合わないチームが繰り返し作られてはプレーヤーの満足度は向上しません。対して1日の対戦回数で測定されるユーザーエンゲージメントは、プレーヤーがゲームを繰り返しプレイしているかを直接反映します。<br>選択肢：予測能力と実際の能力に基づいて選手をチームに割り当てる際の精度と再現性<br>この選択肢が正しくない理由は以下の通りです。<br>選手をチームに割り当てる際の精度と再現性はモデルの性能指標であり、あくまで技術的な指標です。<br>一方で、ユーザーエンゲージメントはゲームがプレイヤーにとって楽しいかを直接的に反映し、ビジネス成功の最終目的を示すため、より適切なビジネス指標です。<br>選択肢：新たなモデルの開発コストを差し引いた追加収益によって測定される収益率<br>この選択肢が正しくない理由は以下の通りです。<br>ゲームの目的は新たなモデルの収益率ではなく、プレイヤーが楽しむことにあり、楽しむためには同じスキルレベルのプレイヤーとのマッチングが重要です。<br>従って、プレイヤーのゲームのエンゲージメントを測る"ユーザー1人当たりの1日の対戦回数"の指標が適切であり、追加収益によって測定される収益率は関連性が低いため不適切です。'>
<div class='choice'> 予測能力と実際の能力に基づいて選手をチームに割り当てる際の精度と再現性</div>
<div class='choice'> 新たなモデルの開発コストを差し引いた追加収益によって測定される収益率</div>
<div class='choice'> ユーザー1人当たりの1日の対戦回数で測定されるユーザーエンゲージメント</div>
<div class='choice'> 選手がチームに割り当てられるまでの平均待ち時間</div>
</div>

<div class='question' data-multiple='false' data-question='問題22<br>あなたは、中規模（～10GB）のBigQueryテーブルに格納されているデータセットを使用してモデルを構築するよう依頼されました。このデータがモデル開発に適しているかどうかを迅速に判断する必要があります。チーム内の他のMLエンジニアと共有するために、データ分布の有益な視覚化と、より高度な統計分析の両方を含む1回限りのレポートを作成したいと考えています。レポートの作成には最大限の柔軟性が必要です。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「Vertex AI Workbenchのユーザー管理型ノートブックを使用してレポートを作成します」です。<br>この問題では、指定されたデータセットの評価とレポート作成にどのツールを選択するかが求められています。BigQueryテーブルのデータを使ってモデルを構築し、迅速にデータがモデル開発に適しているか評価をすること、そしてその評価結果を視覚化と統計分析の形でレポートにまとめることが必要とされています。また、レポート作成には最大限の柔軟性が求められているので、多機能でカスタマイズ可能なツールが有利です。選択肢を検討する際には、それぞれのツールの機能と適用範囲を考慮に入れることが重要です。<br>基本的な概念や原則：<br>Vertex AI Workbench：Google Cloudのエンドツーエンド機械学習プラットフォームの一部で、データの探索、モデルの開発とトレーニング、そしてデプロイメントを行うためのユーザー管理型ノートブック環境を提供します。<br>BigQuery：Google Cloudのフルマネージド、大規模なデータウェアハウスサービスです。SQLクエリを用いてデータの読み書きや分析が可能です。<br>Data Studio：Google Cloudが提供するビジュアルデータエクスプローラーです。対話的なダッシュボードとレポートを作成し、共有することができます。<br>TensorFlow Data Validation（TFDV）：TensorFlow Extend（TFX）のライブラリの1つで、データセットの探索、可視化、統計情報の分析等を提供します。<br>Dataflow：Google Cloudのフルマネージド、高性能なデータ処理サービスです。ストリーミングとバッチデータ処理を続けて行えます。<br>Dataprep：Google Cloudのデータサービスで、データをクリーニング、変換、探索するためのビジュアルインターフェースを提供します。<br>正解についての説明：<br>（選択肢）<br>・Vertex AI Workbenchのユーザー管理型ノートブックを使用してレポートを作成します<br>この選択肢が正解の理由は以下の通りです。<br>Vertex AI Workbenchのユーザー管理型ノートブックは、各種データ分析や機械学習モデルの開発をするための環境を提供し、その中でBigQueryなどのデータソースから情報を取得し、解析に活用します。ノートブックはPythonベースのJupyter Notebookという形式で提供されるため、分析の過程を視覚化することも可能で、それらの内容はチーム内の他のMLエンジニアと共有することも容易にできます。<br>また、Jupyter Notebookはコードと結果を一緒に表示するため、レポート作成にも適しています。<br>さらに、データ分布の視覚化や統計分析だけでなく、より高度な機械学習モデルの開発や評価も一つのノートブック内で行うことができるため、最大限の柔軟性を持ったワークフローを実現できます。そのため、中規模のBigQueryテーブルに格納されているデータセットを使用してモデルを構築する際のレポート生成に、Vertex AI Workbenchのユーザー管理型ノートブックを使用するのが最適です。<br>不正解の選択肢についての説明：<br>選択肢：GoogleData Studioを使用してレポートを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Data Studioは視覚的なレポート作成には優れていますが、高度な統計分析やMLモデル構築の作業には適していません。<br>それに対して、Vertex AI Workbenchのユーザー管理型ノートブックはデータ分析、高度な統計処理からMLモデル構築まで一貫して行うことができ柔軟性が高いため、この問題の要件を満たします。<br>選択肢：TensorFlow Data Validation on Dataflowの出力を使用して、レポートを生成します<br>この選択肢が正しくない理由は以下の通りです。<br>TensorFlow Data Validation on Dataflowは深層学習モデルの検証用であり、中規模データセットの探索的データ分析やレポート作成には適していません。<br>それに対して、Vertex AI Workbenchのユーザー管理型ノートブックはデータ探索からMLモデル作成まで幅広い機能を提供し、レポート作成に特化しています。<br>選択肢：Dataprepを使用してレポートを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Dataprepはデータの前処理や探索的データ分析に使用できますが、モデル構築や高度な統計分析の実行、またレポート作成の柔軟性が限定的です。対してVertex AI Workbenchのユーザー管理型ノートブックは、データ探索から高度な分析、可視化までを一元的に行うことが可能で、柔軟なレポート作成が可能です。'>
<div class='choice'> TensorFlow Data Validation on Dataflowの出力を使用して、レポートを生成します</div>
<div class='choice'> GoogleData Studioを使用してレポートを作成します</div>
<div class='choice'> Dataprepを使用してレポートを作成します</div>
<div class='choice'> Vertex AI Workbenchのユーザー管理型ノートブックを使用してレポートを作成します</div>
</div>

<div class='question' data-multiple='false' data-question='問題23<br>あなたは最近、機械学習チームに参加しました。プロジェクトのリーダーとして、あなたはMLコンポーネントの実稼働準備が整っているかを判断するよう求められています。チームはすでに特徴とデータ、モデル開発、インフラストラクチャをテストしました。<br>チームに推奨すべき追加の準備状況チェックはどれですか？' data-answer='2' data-explanation='解説<br>正解は「モデルのパフォーマンスを確実に監視します」です。<br>この問題では、機械学習プロジェクトの実稼働準備に関連する重要な側面について問われており、特徴とデータの準備、モデルの開発、インフラの整備までは終えている場合に追加で何をすべきかという観点から考える必要があります。問題文から読み取れるように、これはモデルが実際に稼働する際の管理と監視に関連しているので、そこを意識しながら選択肢を見るとより有意義に解答に辿り着けるでしょう。<br>基本的な概念や原則：<br>モデルのパフォーマンス監視：機械学習モデルの性能を一定期間にわたって追跡し、評価するプロセスです。これにより、予測精度の低下、データの分布の変化、潜在的なバイアスなど、モデルの問題を早期に検出することができます。<br>トレーニングの再現性：同じデータセットとハイパーパラメータ設定を用いて機械学習モデルを再度トレーニングすると、同じ結果が得られることです。これは実験の透明性と信頼性を確保するための重要な要素です。<br>ハイパーパラメータチューニング：機械学習モデルの学習プロセスを制御するパラメータ（ハイパーパラメータ）の最適化を行うプロセスです。これにより、モデルの性能を改善することができます。<br>データスキーマ：データの構造や型、特徴についての明確な定義を提供します。これにより、データの品質と一貫性を保証したり、モデルのトレーニングや予測に使用する特徴を理解するためのフレームワークを提供します。<br>正解についての説明：<br>（選択肢）<br>・モデルのパフォーマンスを確実に監視します<br>この選択肢が正解の理由は以下の通りです。<br>機械学習モデルを実稼働環境で使用するとき、モデルのパフォーマンスを監視することが非常に重要です。これは、モデルが定期的に適切に機能していることを確認し、期待されるパフォーマンスを維持していることを保証するためです。<br>さらに、モデルパフォーマンスの監視を通じて、改善の余地や潜在的な問題を特定することができます。<br>したがって、モデルが未知のデータに対してどの程度効果的に予測を提供しているかを把握し、必要であればモデルの調整や再訓練を行うことができます。特徴とデータ、モデル開発、インフラストラクチャの準備が整っていても、もしパフォーマンスが期待通りでなければ、そのモデルが実稼働環境で適切に機能する保証は得られません。そのため、チームが推奨すべき追加の準備状況チェックとして、モデルのパフォーマンスの監視は最も重要な項目と言えます。<br>不正解の選択肢についての説明：<br>選択肢：トレーニングの再現性を確保します<br>この選択肢が正しくない理由は以下の通りです。<br>トレーニングの再現性は重要な要素ですが、既に特徴とデータ、モデル開発、インフラストラクチャのテストをしたなら、トレーニングの再現性は確保されているはずです。<br>一方、モデルのパフォーマンス監視は、モデルが新しいデータに対して正しく機能していることを確認するために重要です。<br>選択肢：すべてのハイパーパラメータが調整されていることを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>ハイパーパラメータの調整は、モデル開発の一環として既に行われているはずです。これは確認事項ではなく、既に終了しているプロセスです。<br>一方、モデルのパフォーマンス監視は、モデルが実運用環境で期待通りに機能するかを確認する重要なステップです。<br>選択肢：特徴への期待がスキーマに取り込まれていることを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>特徴への期待がスキーマに取り込まれているか確認するのは、モデル開発やデータのテストフェーズで行うべき事項です。だからチームは既にこのチェックを行っているはずです。<br>一方で、モデルのパフォーマンス監視は、実稼働に向けた追加の準備状況チェックとして新たに必要となる作業です。'>
<div class='choice'> トレーニングの再現性を確保します</div>
<div class='choice'> すべてのハイパーパラメータが調整されていることを確認します</div>
<div class='choice'> モデルのパフォーマンスを確実に監視します</div>
<div class='choice'> 特徴への期待がスキーマに取り込まれていることを確認します</div>
</div>


            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>