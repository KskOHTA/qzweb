<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Cloud Leader問題集 09</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">
<div class='question' data-multiple='FALSE' data-question='問題17<br>あなたは会社でCloud SQL MySQLデータベースを使用しています。監査目的で、データベースの月末コピーを3年間保持する必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「月初にエクスポートジョブを設定します。エクスポートファイルをArchiveクラスのCloud Storageバケットに書き込みます」です。<br>この問題では、Cloud SQL MySQLデータベースの月末コピーを3年間保存する方法について問われています。月末コピーという要求から、毎月データベースのスナップショットが必要であることが読み取れます。また、データを3年間保持するためには、コストの面で効率的な保存方法を選ぶことが重要で、これはArchiveクラスのCloud Storageバケットが役立ちます。しかし、適切なデータ保管方法だけでなく、適切なデータ抽出方法、つまりエクスポートジョブを設定することも重要な要素です。そのため、問題を解く際には、月末のデータベースコピーを効率的に抽出し、コスト効率の良い方法で保管する解決策を選ぶことが求められます。<br>基本的な概念や原則：<br>Cloud SQL：Google Cloudのフルマネージド型SQLデータベースサービスです。MySQL、PostgreSQL、SQL Serverなどのサポートがあります。<br>エクスポート/インポート：Cloud SQLでは、データベースのエクスポートやインポートが可能です。これを利用すると、データベースのスナップショットを作成してCloud Storageに保存したり、そこからのデータ復元が可能です。<br>Cloud Storage：Google Cloud上でデータを保存するサービスです。<br>Archiveストレージクラス：Cloud Storageのストレージクラスの一つで、長期的に保存することが必要で、頻繁にアクセスする必要がないデータを低コストで保存できます。<br>自動バックアップ：Cloud SQLの機能で、定期的なデータベースのバックアップを自動的に行うことができます。<br>Coldlineストレージクラス：Cloud Storageのストレージクラスの一つで、少ない頻度でアクセスするデータを低コストで保管できます。ただし、Archiveとは異なりリテンション期間の要件があります。<br>正解についての説明：<br>（選択肢）<br>・月初にエクスポートジョブを設定します。エクスポートファイルをArchiveクラスのCloud Storageバケットに書き込みます<br>この選択肢が正解の理由は以下の通りです。<br>まず、Cloud SQL MySQLデータベースのデータのエクスポートは、特定の時間でのデータのスナップショットを取るための一般的な方法です。月初にエクスポートジョブを設定することで、月末のデータベース状態のコピーを作成できます。この操作はCloud SQL内で設定可能で、定期的に行われるため操作負荷が軽減します。<br>また、エクスポートされたデータをArchiveクラスのCloud Storageバケットに保管することでコストを抑えながら、長期間の保管が可能です。Archiveクラスは、データのアクセス頻度が非常に低い場合を対象としたストレージクラスで、最もコストが抑えられるため、3年間という長期間での保管に最適です。これにより監査対象のデータを確実に、しかもコスト効率よく保管することができます。<br>不正解の選択肢についての説明：<br>選択肢：月初の自動バックアップを3年間保存します。アーカイブクラスのCloud Storageバケットにバックアップファイルを保存します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud SQLの自動バックアップは最大34日間しか保持できません。<br>したがって、自動バックアップを3年間保存することはできず、要件を満たしません。<br>一方で、エクスポートジョブを設定し、結果をCloud Storageのアーカイブクラスに保存することで、3年間の長期保管が可能なため、それが正解です。<br>選択肢：月初にオンデマンドバックアップを設定します。バックアップをArchiveクラスのCloud Storageバケットに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud SQLのオンデマンドバックアップから直接ArchiveクラスのCloud Storageバケットに書き込むことはできません。<br>これに対して、エクスポートジョブを設定しArchiveクラスのCloud Storageバケットにエクスポートすると、コスト効率的にデータを保管することができます。<br>選択肢：月初の自動バックアップをエクスポートファイルに変換します。エクスポートファイルをColdlineクラスのCloud Storageバケットに書き込みます<br>この選択肢が正しくない理由は以下の通りです。<br>ColdlineクラスのCloud Storageバケットは、データの取得頻度が低い、または予測不能なアクセスパターンの場合に適しています。<br>しかし、月初の自動バックアップが予測可能なアクセスパターンであり、Coldlineクラスは最低ストレージ期間の費用がかかるため、月初にエクスポートジョブを設定し、安価なArchiveクラスのCloud Storageバケットに書き込むのがより効率的です。'>
<div class='choice'> 月初にオンデマンドバックアップを設定します。バックアップをArchiveクラスのCloud Storageバケットに書き込みます</div>
<div class='choice'> 月初の自動バックアップをエクスポートファイルに変換します。エクスポートファイルをColdlineクラスのCloud Storageバケットに書き込みます</div>
<div class='choice'> 月初にエクスポートジョブを設定します。エクスポートファイルをArchiveクラスのCloud Storageバケットに書き込みます</div>
<div class='choice'> 月初の自動バックアップを3年間保存します。アーカイブクラスのCloud Storageバケットにバックアップファイルを保存します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題18<br>Cloud Storageのバケットに5TBの大きなAVROファイルが保存されています。アナリストはSQLにしか精通しておらず、このファイルに格納されたデータにアクセスする必要があります。あなたは、彼らの要求をできるだけ早く完了するためのコスト効率の良い方法を見つけたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「BigQueryでCloud Storageバケットを指す外部テーブルを作成し、これらの外部テーブルに対してSQLクエリを実行してリクエストを完了します」です。<br>この問題では、SQL専門のアナリストがCloud Storageの大容量のAVROファイルに速やかに、しかもコスト効率良くアクセスする方法が求められています。問題文から、アナリストが直接SQLを使用してデータにアクセスしたいことと、処理速度とコスト効率が重要であることが理解できます。つまり、大量のデータをどのように効率的に処理し、SQLによるアクセスを可能にするかが問われています。ここで考慮するべきは、データのロード方法、データの保存場所、使用するGoogle Cloudのサービス等です。選択肢から最も適したものを選び、要件に合致する最適な提案を見つけ出すことが求められています。<br>基本的な概念や原則：<br>BigQuery：Google Cloudのフルマネージドで低コストのエンタープライズデータウェアハウスで、大量のデータを素早く分析できます。SQLクエリを使用できます。<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスで、任意のサイズのデータを安全に保存し、いつでもどこからでもアクセスできます。<br>外部テーブル（BigQuery）：BigQueryでクエリを実行するためのデータソースの参照です。データ自体はCloud StorageやGoogle Driveなど、BigQuery外部に保存されます。<br>AVRO：JSONを基にしたデータ割り当て言語で、Big Dataの処理と通信によく使われます。大量のデータを効率的に処理できるように設計されています。<br>Cloud Datastore：NoSQLドキュメントデータベースで、モバイルアプリ、ウェブアプリなどのバックエンドに適しています。SQLクエリは利用できません。<br>Hadoop：分散ストレージと分散処理を扱うオープンソースのフレームワークです。Hadoopクラスターでは、大量のデータを分散し、並行して処理できます。ただし、セットアップとメンテナンスには手間とコストがかかります。<br>正解についての説明：<br>（選択肢）<br>・BigQueryでCloud Storageバケットを指す外部テーブルを作成し、これらの外部テーブルに対してSQLクエリを実行してリクエストを完了します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google BigQueryは大量のデータを扱うのに最適なフルマネージドな大規模データ分析サービスです。BigQueryはスケールに合わせて柔軟にリソースを追加することができ、5TBのAVROファイルを扱うのに十分な能力を持っています。<br>また、BigQueryは外部テーブルをサポートしています。外部テーブルは、Google Cloud Storageや他のソースにあるデータを直接クエリすることができます。この機能を使用すると、大量のデータをBigQueryにインポートする手間やコストをかけずに、アナリストがSQLクエリを実行してデータを分析することができます。<br>さらに、AVROフォーマットは、BigQueryにネイティブでサポートされています。これは、データを他の形式に変換する必要がなく、そのままクエリすることができるということを意味します。<br>以上の理由から、BigQueryを使用してCloud Storageバケットを指す外部テーブルを作成し、これらの外部テーブルに対してSQLクエリを実行することは、早くコスト効率的にこの要件を満たす最善の方法と言えます。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Datastoreにデータをロードし、それに対してSQLクエリを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud DatastoreはNoSQLのデータベースサービスであり、SQLクエリによるデータ操作が限定的であるため、SQLに精通しているアナリストの要求を満たすことができません。<br>また、5TBという大量のデータをロードするのにもコストがかかります。<br>一方、外部テーブルを使用するBigQueryなら、Cloud Storageのデータを直接参照しながらSQLクエリが可能で、より効率的です。<br>選択肢：BigQueryテーブルを作成し、BigQueryにデータをロードします。このテーブルでSQLクエリを実行し、要求が完了したらこのテーブルを削除します<br>この選択肢が正しくない理由は以下の通りです。<br>データをBigQueryに直接ロードすると、ロード時間とコストが発生します。<br>一方で、外部テーブルを使うとCloud Storageから直接データをクエリするため、ロード時間が不要になりユーザーの要求をより早く、コスト効率よく満たすことができます。<br>選択肢：Hadoopクラスターを作成し、AVROファイルを圧縮してNDFSにコピーします。そのファイルをハイブテーブルにロードし、アナリストがSQLクエリを実行できるようにアクセス権を提供します<br>この選択肢が正しくない理由は以下の通りです。<br>Hadoopクラスターを作成し、AVROファイルを圧縮してNDFSにコピーして、ハイブテーブルにロードするプロセスは時間がかかり、コストもかかります。<br>それに対して、BigQueryで外部テーブルを作成すると、直接SQLクエリを実行でき、速度もコストも効率的です。'>
<div class='choice'> BigQueryテーブルを作成し、BigQueryにデータをロードします。このテーブルでSQLクエリを実行し、要求が完了したらこのテーブルを削除します</div>
<div class='choice'> BigQueryでCloud Storageバケットを指す外部テーブルを作成し、これらの外部テーブルに対してSQLクエリを実行してリクエストを完了します</div>
<div class='choice'> Cloud Datastoreにデータをロードし、それに対してSQLクエリを実行します</div>
<div class='choice'> Hadoopクラスターを作成し、AVROファイルを圧縮してNDFSにコピーします。そのファイルをハイブテーブルにロードし、アナリストがSQLクエリを実行できるようにアクセス権を提供します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題19<br>あなたは、Compute Engine上のWebアプリケーションの責任者です。ユーザが5分以上の高レイテンシを経験した場合、サポートチームに自動的に通知してほしいと考えています。また、Googleが推奨する開発コストのかからないソリューションが必要です。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「HTTPレスポンスの待ち時間が指定した閾値を超えた場合に通知を送信するアラートポリシーを作成します」です。<br>この問題では、ユーザが高レイテンシを経験した場合の自動通知システムについて問われています。これを解決するためにCompute Engine上のWebアプリケーションを監視する手段を探すと考えます。また重要な制約として、Googleが推奨する開発コストのかからない方法を探すことが求められています。以上の情報を考慮に入れ、Google Cloud内の各種サービスから最も適切なものを選ぶことが問題解決に繋がります。<br>基本的な概念や原則：<br>HTTPレスポンスの待ち時間：Webアプリケーションのパフォーマンスを測定する一般的な指標です。アプリケーションがユーザーのリクエストに応答するまでの時間を表します。<br>アラートポリシー：特定の条件が満たされたときに通知を送信するための設定です。Google CloudのCloud Monitoringで設定でき、メトリクスの異常状態を検出してアラートをトリガーします。<br>Cloud Monitoring：Google Cloudの監視、ロギング、診断データの管理を提供するサービスです。アプリケーションのパフォーマンスやリソースの使用状況を追跡し、アップデートやトラブルシューティングを助けます。<br>BigQuery：Google Cloudのビッグデータと分析ツールです。大量のデータを迅速に分析し、洞察を得ることができます。<br>Looker Studio：データ視覚化と分析を提供するLookerの機能の一つです。ダッシュボードを使用してデータを視覚的に分析することができます。<br>Cloud Monitoring API：Cloud Monitoringデータにプログラムによるアクセスを提供するAPIです。メトリクスの読み取り、書き込み、確認が可能です。<br>App Engine：Google Cloudのサーバレスアプリケーションプラットフォームです。スケーリング、運用、セキュリティの管理を自動化します。<br>正解についての説明：<br>（選択肢）<br>・HTTPレスポンスの待ち時間が指定した閾値を超えた場合に通知を送信するアラートポリシーを作成します<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloudのモニタリングとアラーティング機能を使うことで、Compute Engine上のWebアプリケーションのレスポンスレイテンシを監視し、特定の条件を満たす（例えば、レスポンス待ち時間が5分を超える）ときに通知を自動的に送る設定を可能にします。この機能を利用することで、問題が発生した即時性に富む情報をサポートチームへ提供することができます。<br>また、これらの機能はGoogle Cloudの標準的な機能であるため、追加の開発コストをかけることなく、要件を満たすことができます。<br>したがって、HTTPレスポンスの待ち時間が指定した閾値を超えた場合に通知を送信するアラートポリシーを作成するという選択肢が、もっとも適切な解決策と言えます。<br>不正解の選択肢についての説明：<br>選択肢：Cloud MonitoringのメトリクスをBigQueryにエクスポートし、Looker Studioのダッシュボードを使用してWebアプリケーションのレイテンシを監視します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud MonitoringのメトリクスをBigQueryにエクスポートし、Looker Studioのダッシュボードを使用する方法は開発コストがかかります。開発作業が必要であること、そしてLooker Studioの使用料が発生するためです。<br>それに対して、HTTPレスポンスの待ち時間が閾値を超えた場合に通知を送信するアラートポリシーを作成する方法は無料で、即座にサポートチームに通知を送れます。<br>選択肢：Cloud Monitoring APIを呼び出し、異常が発生した場合に通知を送信するApp Engineサービスを実装します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Monitoring APIを呼び出し、異常が発生した場合に通知を送信するApp Engineサービスを実装する選択肢は、新たなサービスを開発する必要があります。そのため開発コストが発生します。<br>それに対して、HTTPレスポンスの待ち時間が指定した閾値を超えた場合に通知を送信するアラートポリシーを作成する選択肢は、既存のCloud Monitoring機能を利用し、開発コストがかからないため適切です。<br>選択肢：Cloud Monitoringダッシュボードを使用してレイテンシを観察し、応答レイテンシが指定された閾値を超えた場合に必要なアクションを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Monitoringダッシュボードを使用してレイテンシを観察しても、この選択肢では通知機能が明示されていません。<br>一方、正解の選択肢ではHTTPレスポンスの待ち時間が指定した閾値を超えた場合に自動的に通知を送信するアラートポリシーを作成することで、要求通りサポートチームに自動的に通知する機能が満たされています。'>
<div class='choice'> Cloud MonitoringのメトリクスをBigQueryにエクスポートし、Looker Studioのダッシュボードを使用してWebアプリケーションのレイテンシを監視します</div>
<div class='choice'> Cloud Monitoringダッシュボードを使用してレイテンシを観察し、応答レイテンシが指定された閾値を超えた場合に必要なアクションを実行します</div>
<div class='choice'> Cloud Monitoring APIを呼び出し、異常が発生した場合に通知を送信するApp Engineサービスを実装します</div>
<div class='choice'> HTTPレスポンスの待ち時間が指定した閾値を超えた場合に通知を送信するアラートポリシーを作成します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題20<br>ある従業員が解雇されましたが、Google Cloudへのアクセスが削除されたのは2週間後でした。この従業員が解雇後に顧客の機密情報にアクセスしたかどうかを調べる必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「Cloud Loggingでデータアクセスの監査ログを見ます。プリンシパルとしてユーザーの電子メールを検索します」です。<br>この問題では、解雇された従業員が解雇後に顧客の機密情報にアクセスしたかどうかを調査するためのアプローチを理解することが鍵です。従業員の行動を調査するためには適切なログ情報を追跡し、該当する従業員の情報を検索することが必要です。選択肢を見て、Google Cloud内でのデータアクセスの監査に最も適したツールは何かを見極めます。また、混乱を避けるために、システムイベントログやAdmin Activityログといった異なる種類のログの違いを理解することも重要です。<br>基本的な概念や原則：<br>Cloud Logging：Google Cloudのログ管理サービスです。ログデータを一元的に集め、分析、監視、出力が可能です。<br>データアクセス監査ログ：Cloud Loggingの一部で、Google CloudサービスのAPI呼び出しに関する記録です。特に機密情報などデータへの閲覧や変更が記録されます。<br>プリンシパル：セキュリティポリシーにおいて、パーミッションが与えられる主体（ユーザー、グループ、サービスアカウント）を指す用語です。<br>システムイベントログ：システムの操作や変更を記録したログです。データアクセスログとは異なり、データへの操作よりもシステムの状態に焦点を当てた情報が記録されます。<br>Admin Activityログ：Google Cloudの管理活動を記録したログです。設定の変更などの管理者による操作が記録されます。<br>サービスアカウント：アプリケーション認証とAPIアクセスのために使用される特殊なアカウント形式です。<br>正解についての説明：<br>（選択肢）<br>・Cloud Loggingでデータアクセスの監査ログを見ます。プリンシパルとしてユーザーの電子メールを検索します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google CloudのCloud Loggingはデータアクセスに関する詳細な監査ログを提供します。これらのログには特定のユーザーやAPIの操作に関する情報が含まれており、これを用いて特定の従業員が行った全てのアクティビティをトレースすることができます。<br>また、Cloud Loggingではプリンシパル（主体）としてユーザーの電子メールアドレスを検索することができます。つまり、解雇された従業員の電子メールアドレスを使用して、その従業員が解雇後にどのようなアクティビティを行ったかを詳細に調査することができます。<br>さらに、Cloud Loggingは過去のログデータにもアクセス可能であり、従って2週間前のアクティビティまで遡って調査することができます。<br>したがって、特定の従業員が解雇後に顧客の機密情報に不適切にアクセスしたかどうかを調査するために、Cloud Loggingでデータアクセスの監査ログを見るのが一番効果的です。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Loggingでシステムイベントログを見ます。プリンシパルとしてユーザーのメールを検索します<br>この選択肢が正しくない理由は以下の通りです。<br>システムイベントログはシステムレベルのアクションを記録しますが、個々のユーザーが特定のデータへアクセスしたかどうかを追跡する目的では適していません。そのため、具体的なデータへのアクセスを調査するためにはデータアクセスの監査ログを参照すべきです。<br>選択肢：Cloud Loggingでシステムイベントログを見ます。ユーザーに関連付けられているサービスアカウントを検索します<br>この選択肢が正しくない理由は以下の通りです。<br>システムイベントログはシステムによる操作を記録するものであり、特定のユーザーがデータにアクセスしたかどうかを把握するためには、データアクセスの監査ログを参照する必要があります。<br>また、サービスアカウントはアプリケーションやサービスがGoogle CloudのAPIを利用するためのものであり、特定のユーザーのアクセスを追跡するためにはユーザーのメールアドレスを検索した方が適切です。<br>選択肢：Cloud LoggingでAdmin Activityログを表示します。ユーザーに関連付けられているサービスアカウントを検索します<br>この選択肢が正しくない理由は以下の通りです。<br>Admin Activityログは管理活動を記録しますが、特定のユーザーが顧客の機密情報にアクセスしたか否かを調査するのに必要なデータアクセス情報を提供しません。<br>それに対して、データアクセスの監査ログではユーザーによるデータへの具体的なアクセス活動を追跡できます。'>
<div class='choice'> Cloud Loggingでデータアクセスの監査ログを見ます。プリンシパルとしてユーザーの電子メールを検索します</div>
<div class='choice'> Cloud LoggingでAdmin Activityログを表示します。ユーザーに関連付けられているサービスアカウントを検索します</div>
<div class='choice'> Cloud Loggingでシステムイベントログを見ます。プリンシパルとしてユーザーのメールを検索します</div>
<div class='choice'> Cloud Loggingでシステムイベントログを見ます。ユーザーに関連付けられているサービスアカウントを検索します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題21<br>32GBのデータを1つのファイルにして、Nearlineストレージバケットにアップロードする必要があります。使用しているWAN接続の定格は1Gbpsで、接続しているのはあなただけです。定格1Gbpsを可能な限り使用して、ファイルを高速転送したいと考えています。どのようにファイルをアップロードしますか？' data-answer='0' data-explanation='解説<br>正解は「ファイル転送でgsutilを使用して並列複合アップロードを有効にします」です。<br>この問題では、32GBの大きなファイルをGoogle CloudのNearlineストレージバケットに高速でアップロードする最適な方法を選択することが求められています。ここで重要なのは、指定されたネットワーク接続の帯域幅（1Gbps）を最大限に利用し、高速な転送を達成する方法を選ぶことです。また、出題の文脈であるネットワークの帯域幅やファイルサイズ、およびGoogle Cloudのストレージオプションを理解することが重要です。<br>基本的な概念や原則：<br>gsutil：Google Cloud Storageにファイルをアップロード、ダウンロードし、バケットを管理するためのコマンドラインツールです。大規模なデータ転送に適しています。<br>並列複合アップロード：非常に大きなファイルの転送時間を短縮するために、gsutilがファイルをより小さな部分に分割し、それぞれを個別にアップロードするプロセスです。<br>Google Cloud Console：Google Cloudのユーザーインターフェースです。ここでリソースの作成や管理、モニタリングなどが可能です。一部の高度なオプションについては、コマンドラインツールを使用した方がより適しています。<br>TCPウィンドウサイズ：転送中に一度に送られることができるデータ量を制御するパラメータです。ウィンドウサイズが大きすぎると、ネットワークの輻輳が引き起こされ、小さすぎると帯域幅が十分に活用されない可能性があります。<br>Nearlineストレージ：Google Cloud Storageの一部で、大量のデータを長期的に保存するための廉価なストレージオプションです。アクセス頻度が低いデータに適しています。<br>マルチリージョンストレージ：Google Cloud Storageの一部で、頻繁にアクセスされるデータに対して高い可用性と信頼性を提供します。価格はNearlineストレージと比較して高くなります。<br>正解についての説明：<br>（選択肢）<br>・ファイル転送でgsutilを使用して並列複合アップロードを有効にします<br>この選択肢が正解の理由は以下の通りです。<br>まず、gsutilはGoogle Cloud Storageへのファイル転送を管理するツールで、並列複合アップロードという機能を有しています。この機能は、大きなファイルを複数の小さな部分に分割し、それらを同時にアップロードするというものです。各部分は独立してアップロードされるため、全体のアップロード時間を大幅に短縮することができます。<br>さらに、gsutilの並列複合アップロードは、接続帯域をより効率的に使用し、1Gbpsの設定専用WAN接続の可能性を最大限に引き出す能力があります。<br>したがって、指定された接続速度を可能な限り使用してファイルを高速転送するために、gsutilを使用して並列複合アップロードを有効にするのが最適な選択肢です。<br>不正解の選択肢についての説明：<br>選択肢：ファイルを転送するために、gsutilの代わりにGoogle Cloud Consoleを使用します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloud Consoleのファイルアップロード機能は、単一スレッド、シングル接続使用のため、1GbpsのWAN接続の定格を十分活かす並列化を実現できません。<br>一方、gsutilを使った並列複合アップロードは多数のスレッドを使い、接続帯域を最大限利用してファイルを高速にアップロードできます。<br>選択肢：転送を開始するマシンのTCPウィンドウサイズを小さくします<br>この選択肢が正しくない理由は以下の通りです。<br>TCPウィンドウサイズを小さくするという選択肢は、実際にはネットワーク性能を低下させる可能性があります。データ転送の効率性とは逆行し、転送速度は遅くなります。<br>それに対して、正解の選択肢である並列複合アップロードを使用すると、複数のパートに分けてファイルをアップロードすることができ、全体的な転送速度を向上させる効果があります。<br>選択肢：バケットの保存クラスをNearlineからMulti-Regionalに変更します<br>この選択肢が正しくない理由は以下の通りです。<br>バケットの保存クラスをNearlineからMulti-Regionalに変更しても、ファイル転送速度には直接的な影響を与えません。正解の選択肢では、gsutilを使って並列複合アップロードを有効にすることで、接続速度を最大限に活用し高速なデータ転送が可能になります。'>
<div class='choice'> ファイル転送でgsutilを使用して並列複合アップロードを有効にします</div>
<div class='choice'> 転送を開始するマシンのTCPウィンドウサイズを小さくします</div>
<div class='choice'> ファイルを転送するために、gsutilの代わりにGoogle Cloud Consoleを使用します</div>
<div class='choice'> バケットの保存クラスをNearlineからMulti-Regionalに変更します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題22<br>あなたは、単一のプリエンプティブルノードプールを持つGoogle Kubernetes Engineクラスターに、2つのレプリカを持つデプロイメントを作成しました。数分後、kubectlを使用してポッドのステータスを調べたところ、以下のようにそのうちの1つがまだPendingステータスであることを確認しました：<br>$ kubectl get pods --l app=myapp<br>NAME READY STATUS RESTART AGE<br>myapp-deployment-11aabbb222-1a22b 0/1 Pending 0 9m<br>myapp-deployment-11aabbb222-tkpgz 1/1 Running 0 9m<br>最も可能性の高い原因は何ですか？' data-answer='0' data-explanation='解説<br>正解は「クラスター内で実行中のポッドが多すぎて、保留中のポッドをスケジュールするのに十分なリソースが残っていません」です。<br>この問題では、Google Kubernetes Engine（GKE）クラスター内で一部のポッドがPending状態になっている原因について問われています。GKEクラスター内でポッドのスケジューリングが適切に行われていない事象について理解し、その原因を解明することが求められています。キーポイントは、クラスターには単一のプリエンプティブルノードプールが存在し、2つのレプリカを持つデプロイメントが作成されているということ実です。これを踏まえ、クラスター内のリソース状況、コンテナイメージのプルに必要な権限、プリエンプティブルノードへのスケジューリングなどの要素を考慮して、原因を特定する必要があります。<br>基本的な概念や原則：<br>Google Kubernetes Engine（GKE）：Dockerコンテナのスケジューリングと管理を行うためのGoogle Cloudのサービスです。その中でポッドは一つ以上のコンテナをまとめた単位で扱われます。<br>プリエンプティブルノードプール：GKEクラスター内の仮想マシン（VM）インスタンスが保存されるプールで、この種のノードプールは24時間を超えるために確保することはできず、また任意の時間で終了する可能性があります。<br>kubectl：Kubernetesクラスターの管理に使われるコマンドラインツールです。kubectl get podsコマンドを使用して、プロジェクト内で実行中のポッドのリストを取得します。<br>ポッドのステータス：ポッドの状態を示すもので、次の4つのステータスがあります。"Pending"（ポッドがスケジュールされているが、まだどのノードにも割り当てられていない）、"Running"（ポッドがノードに割り当てられ、すべてのコンテナが作成され、1つ以上のコンテナが実行中）、などです。<br>リソース要求：Podに必要な最小のリソース（CPU、メモリ）を定義します。これが大きいとポッドをスケジュールする際に適切なスペースがないとスケジューリングできません。<br>サービスアカウント：Google Cloud上でアプリケーションやサービス同士が認証、認可されるための特殊なアカウントです。このアカウントを使うことで適切な権限を付与し、アクセス制御を行います。<br>正解についての説明：<br>（選択肢）<br>・クラスター内で実行中のポッドが多すぎて、保留中のポッドをスケジュールするのに十分なリソースが残っていません<br>この選択肢が正解の理由は以下の通りです。<br>プリエンプティブルノードプールは、プリエンプティブルVMが格納されるノードプールです。プリエンプティブルVMは、Google Cloudが非常に低い価格で提供していますが、所定の時間（最大24時間）が経過するか途中で停止させられることもあるVMです。それらは主にコストを抑えたいときや、中断可能な事前処理ジョブのような割り込まれても問題のないタスクなどに利用されます。<br>問題文によると、2つのレプリカが必要ですが、保留状態のままのレプリカが存在します。これは、十分なリソースがなく、上限に達したために保留となっている可能性が高いです。GKEクラスターのノードプールのリソース（CPUやメモリ、ディスク領域など）は有限であり、それらノードプール内で実行中のポッドの総数や各ポッドのリソース使用量により、新たなポッドを作成し実行することができなくなる場合があります。<br>したがって、クラスター内で実行されているポッドが多すぎて、新たなポッドをスケジュールするのに必要なリソースが残っていない可能性が高いです。<br>不正解の選択肢についての説明：<br>選択肢：保留中のポッドのリソース要求が大きすぎて、クラスターの単一ノードに収まりません<br>この選択肢が正しくない理由は以下の通りです。<br>問題文にて2つのレプリカを持つデプロイメントのうち、1つはすでに正常に動作しています。これはそのリソース要求が単一ノードに収まらないという状況を否定しています。<br>したがって、保留中のポッドのリソース要求がクラスターのノードに収まらないという選択肢は不正解です。<br>選択肢：保留中のポッドが使用するコンテナイメージをプルする権限を持っていないサービスアカウントで、ノードプールが構成されています<br>この選択肢が正しくない理由は以下の通りです。<br>コンテナイメージのプルに失敗した場合は、"ImagePullBackOff"または"ErrImagePull"などのエラーメッセージが表示され、"Pending"ステータスにはならないため、サービスアカウントの権限問題は保留中のポッドの原因ではありません。正解は、リソース不足が一番の可能性です。<br>選択肢：保留中のポッドは、もともとデプロイの作成からポッドのステータスを確認するまでの間に先取りされたノードにスケジュールされていました。現在、新しいノードで再スケジュール中です<br>この選択肢が正しくない理由は以下の通りです。<br>プリエンプティブルノードは、24時間以上ではなく30分以上後にシャットダウンされ、再スケジュールされます。<br>また、新しく起動されたノードがリソース確保を終えるとすぐに、未配置のポッドがスケジュールされます。数分の間にわたり、ポッドが保留中のままであるという現象は、リソースが不足していることの方が一般的です。'>
<div class='choice'> クラスター内で実行中のポッドが多すぎて、保留中のポッドをスケジュールするのに十分なリソースが残っていません</div>
<div class='choice'> 保留中のポッドが使用するコンテナイメージをプルする権限を持っていないサービスアカウントで、ノードプールが構成されています</div>
<div class='choice'> 保留中のポッドは、もともとデプロイの作成からポッドのステータスを確認するまでの間に先取りされたノードにスケジュールされていました。現在、新しいノードで再スケジュール中です</div>
<div class='choice'> 保留中のポッドのリソース要求が大きすぎて、クラスターの単一ノードに収まりません</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題23<br>あなたは3つの別々のプロジェクトからGoogle Cloudのサービスコストを分析しています。この情報を使用して、標準的なクエリ構文を使用して、今後6ヶ月間のサービスタイプ別、日次および月次のサービスコストの見積もりを作成したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「請求書をBigQueryデータセットにエクスポートし、分析用のタイムウィンドウベースのSQLクエリを記述します」です。<br>この問題では、Google Cloudのサービスコストを分析し、将来のコスト見積もりを作成する最適な方法を求めています。このようなビジネスインテリジェンス（BI）タスクに対する適切な解決策の選択には、データ分析の機能との整合性が重要です。また、大量の請求データを扱うため、スケーラビリティと効率的なデータ操作が可能なソリューションに焦点を当てる必要があります。選択肢を評価する際には、データ対応能力とクエリ機能、そして題材で与えられた要件の完全性を基準に考えるべきです。<br>基本的な概念や原則：<br>BigQuery：Google Cloudの高速な完全マネージドの企業向けデータウェアハウスです。標準的なSQLクエリを使用して、ペタバイト単位のデータに対する分析を迅速に実行することができます。<br>請求データのエクスポート：Google Cloudの請求データをBigQueryデータセットにエクスポートする機能です。請求情報を詳細に分析したり、カスタムレポートを作成したりするために利用できます。<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データのアップロード、ダウンロード、バケットからのエクスポートなどが可能です。<br>Cloud Bigtable：Google CloudのスケーラブルなNoSQLデータベースです。大量のデータをリアルタイムで解析するためのサービスです。<br>Google Sheets：Googleのオンラインスプレッドシートツールです。Google Cloudや他のGoogleサービスと統合して、データの編集や共有、分析が可能です。<br>正解についての説明：<br>（選択肢）<br>・請求書をBigQueryデータセットにエクスポートし、分析用のタイムウィンドウベースのSQLクエリを記述します<br>この選択肢が正解の理由は以下の通りです。<br>請求データをBigQueryデータセットにエクスポートすると、Google Cloudの標準的なSQLクエリ構文を使用して深度分析を行うことができます。これにより、プロジェクトごとに集約された複雑なデータを簡単に探索し、パターンや予測を特定することが可能になります。<br>また、BigQueryは大量のデータに対して高速にクエリを実行できるため、異なるプロジェクトからのコストデータを迅速に照合して分析を行うことができます。<br>そして、タイムウィンドウベースのSQLクエリを記述することにより、一定期間（今後6ヶ月間）や特定の日ごと、月ごとのコスト見積もりを得ることができます。<br>このように、Google Cloudの複数のプロジェクトのコストを分析するためには、BigQueryに請求情報をエクスポートし、SQLクエリを用いて分析するのが最適な解決策です。<br>不正解の選択肢についての説明：<br>選択肢：請求書をCloud Storageバケットにエクスポートし、分析のためにCloud Bigtableにインポートします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud StorageからCloud Bigtableにデータをインポートする方法は、タイムウィンドウベースのクエリ分析の実装には適していません。Bigtableは大量のデータを素早く読み書きするのに効果的ですが、複雑なSQLクエリや集計機能への対応が限られています。そのため、日次および月次のコスト見積もりを作成するには適していません。<br>一方、BigQueryは複雑なクエリ構文をサポートし、SQLでの分析が可能であり、このシナリオに適しています。<br>選択肢：請求書をCloud Storageのバケットにエクスポートし、分析のためにGoogle Sheetsにインポートします<br>この選択肢が正しくない理由は以下の通りです。<br>請求書をCloud Storageにエクスポートし、Google Sheetsにインポートする方法では、標準的なクエリ構文を使用して複雑な分析を行うのは困難であり、大量のデータを扱うには制限があります。<br>一方、BigQueryを使用すればSQLクエリによる精密な分析が可能で大量データも容易に扱えます。<br>選択肢：トランザクションをローカルファイルにエクスポートし、デスクトップツールで分析を実行します<br>この選択肢が正しくない理由は以下の通りです。<br>ローカルファイルにエクスポートしてデスクトップツールで分析する方法は、Google Cloudのサービスコストの定量的・時間的な分析には不向きです。<br>一方、BigQueryは大規模なデータセットに対する高速な分析を提供し、標準的なSQLクエリを使用した柔軟な分析が可能なため良い選択です。'>
<div class='choice'> 請求書をBigQueryデータセットにエクスポートし、分析用のタイムウィンドウベースのSQLクエリを記述します</div>
<div class='choice'> 請求書をCloud Storageのバケットにエクスポートし、分析のためにGoogle Sheetsにインポートします</div>
<div class='choice'> 請求書をCloud Storageバケットにエクスポートし、分析のためにCloud Bigtableにインポートします</div>
<div class='choice'> トランザクションをローカルファイルにエクスポートし、デスクトップツールで分析を実行します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題24<br>あなたの会社では、Compute Engineインスタンス上で動作するApache Webサーバー上で大きなファイルを公開しています。Apache Webサーバーは、プロジェクトで実行されている唯一のアプリケーションではありません。Google Cloudによって測定された当月のサーバーのアウトバウンドネットワークコストが100ドルを超えたときに、電子メールを受け取りたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「請求データをBigQueryにエクスポートします。BigQueryを使用して、当月のApacheウェブサーバのエクスポートされた請求データのアウトバウンドネットワークコストを合計し、100ドルを超えた場合にメールを送信するCloud Functionsを実装します。Cloud Schedulerを使用して、1時間ごとに実行するようにCloud Functionsをスケジュールします」です。<br>この問題では、あなたの会社がCompute Engine上のApache Webサーバーで大きなファイルを公開し、それが一定のネットワークコストを超えたときに通知を希望しています。ここで注意すべき点は、通知のトリガーが特定のアプリケーションであるApache Webサーバーのアウトバウンドネットワークコストが一定量を超えたというものであることです。したがって、選択肢を見る際には、Apacheサーバーに限定したコストを把握し、その情報に基づいて通知を設定するためのパスがあるかを重視することが必要です。Cloudのサービスの組み合わせにより、各種データでの請求情報の追跡やアラートの管理が行えるのかを見極めることが求められます。<br>基本的な概念や原則：<br>Compute Engine：Google Cloudの仮想マシンインスタンスを提供するサービスです。様々な設定のインスタンスを使用して、ユーザーが定義したアプリケーションを実行できます。<br>Apache Webサーバー：オープンソースのWebサーバーソフトウェアで、インターネット上のウェブサイトのホストに広く使用されています。<br>BigQuery：Google Cloudのビッグデータ分析ツールです。大量のデータを高速にクエリすることが可能で、データウェアハウスとしても利用できます。<br>Cloud Functions：Google Cloudのイベント駆動型サーバレスコンピューティングサービスです。特定のイベントに応じてコードを自動的に実行することができます。<br>Cloud Scheduler：Google Cloudの完全マネージドのクロンジョブスケジューラーです。指定された時間または一定の間隔でCloud Functionなどのタスクを自動的に実行することができます。<br>請求データ：Google Cloudの利用費用に関するデータで、BigQueryにエクスポートして分析することができます。<br>予算アラート：Google Cloudの機能で、指定した予算を超えた際に通知を受け取ることができます。ただし、特定のサービスに対するコストだけを監視することはできません。<br>正解についての説明：<br>（選択肢）<br>・請求データをBigQueryにエクスポートします。BigQueryを使用して、当月のApacheウェブサーバのエクスポートされた請求データのアウトバウンドネットワークコストを合計し、100ドルを超えた場合にメールを送信するCloud Functionsを実装します。Cloud Schedulerを使用して、1時間ごとに実行するようにCloud Functionsをスケジュールします<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloudの請求に関する情報をBigQueryにエクスポートすれば、そのデータに対して様々な分析が可能になります。具体的には、Apache Webサーバーのアウトバウンドネットワークコストを特定し、それを当月の合計として算出することができます。<br>次に、Cloud Functionsを実装することで、合計コストが100ドルを超えたタイミングでのメール送信という自動化が可能になります。これは、イベント駆動型のサーバレスコンピューティング環境であるCloud Functionsの特性を活かすことで実現します。<br>最後に、Cloud Schedulerを用いることで、定期的に（ここでは1時間ごとに）このCloud Functionsを実行するスケジュールを設定できます。これにより、課金情報が定期的に確認され、設定した閾値を超えるとすぐに通知が行われるので、コストの管理が向上します。以上の要素が組み合わさることで、問題の要件を満たす解答です。<br>不正解の選択肢についての説明：<br>選択肢：プロジェクトに予算アラートを設定し、金額を100ドル、閾値を100％、通知タイプをemail.とします<br>この選択肢が正しくない理由は以下の通りです。<br>プロジェクト全体の予算アラートを設定すると、Apache Webサーバーのコストだけでなく、プロジェクトで実行されている他の全てのアプリケーションのコストも含まれるため、Apache Webサーバー単独のコストが100ドルを超えたかどうかを特定できません。<br>それに対して、正答の方は指定されたApacheサーバーのコストだけを抽出、分析することができます。<br>選択肢：請求アカウントに予算アラートを設定し、金額を100ドル、閾値を100％、通知タイプをemail.とします<br>この選択肢が正しくない理由は以下の通りです。<br>予算アラートの設定は特定のサービスやアプリケーションに対するコストを断定的に監視することはできません。つまり、Apacheサーバーのアウトバウンドネットワークコストだけを追跡するのではなく、全てのGoogle Cloudサービスに関するコストが計上されます。<br>したがって、この方法は特定のアプリケーションのコスト追跡には適していません。<br>選択肢：Cloud Logging Agentを使用して、ApacheウェブサーバのログをCloud Loggingにエクスポートします。BigQueryを使用してCloud LoggingのHTTPレスポンスログデータを当月分解析し、すべてのHTTPレスポンスのサイズに現在のGoogle Cloudのアウトバウンドネットワークコストを掛けた合計が100ドルを超えた場合にメールを送信するCloud Functionを作成します。Cloud Schedulerを使用して、1時間ごとに実行するようにCloud Functionsをスケジュールします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Logging Agentを使用するとApacheウェブサーバのログは取得できますが、それを用いてGoogle Cloudのアウトバウンドネットワークコストを正確に計算することは不可能です。これは、ネットワークコストは送信データ量だけでなく、その他の要因にも関連しているためです。<br>一方、正解の選択肢のように請求データを直接分析することで、正確なネットワークコストを得ることができます。'>
<div class='choice'> 請求データをBigQueryにエクスポートします。BigQueryを使用して、当月のApacheウェブサーバのエクスポートされた請求データのアウトバウンドネットワークコストを合計し、100ドルを超えた場合にメールを送信するCloud Functionsを実装します。Cloud Schedulerを使用して、1時間ごとに実行するようにCloud Functionsをスケジュールします</div>
<div class='choice'> 請求アカウントに予算アラートを設定し、金額を100ドル、閾値を100％、通知タイプをemail.とします</div>
<div class='choice'> プロジェクトに予算アラートを設定し、金額を100ドル、閾値を100％、通知タイプをemail.とします</div>
<div class='choice'> Cloud Logging Agentを使用して、ApacheウェブサーバのログをCloud Loggingにエクスポートします。BigQueryを使用してCloud LoggingのHTTPレスポンスログデータを当月分解析し、すべてのHTTPレスポンスのサイズに現在のGoogle Cloudのアウトバウンドネットワークコストを掛けた合計が100ドルを超えた場合にメールを送信するCloud Functionを作成します。Cloud Schedulerを使用して、1時間ごとに実行するようにCloud Functionsをスケジュールします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題25<br>管理インスタンスグループ内の複数の仮想マシンでアプリケーションを実行しており、オートスケーリングが有効になっています。オートスケーリングポリシーは、インスタンスのCPU使用率が80%を超えると、追加のインスタンスがグループに追加されるように構成されています。VMは、インスタンスグループが最大上限の5 VMに達するか、インスタンスのCPU使用率が80%に低下するまで追加されます。インスタンスに対するHTTPヘルスチェックの初期遅延は30秒に設定されています。<br>仮想マシンのインスタンスがユーザが利用できるようになるまで、約3分かかります。インスタンスグループのオートスケール時に、エンドユーザートラフィックのレベルをサポートするために必要なインスタンスが追加されることを確認する必要があります。あなたは、オートスケール時にインスタンスグループのサイズを適切に維持したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「HTTPヘルスチェックの初期遅延を200秒に増やします」です。<br>この問題では、オートスケーリングを行なっている管理インスタンスグループ内の仮想マシンの設定について問われています。オートスケーリングポリシーはCPU使用率が80%を超えるという条件付きですが、なお仮想マシンのインスタンスがユーザが利用できるようになるまで約3分かかり、その間にCPU使用率が下がる可能性があります。またHTTPヘルスチェックの初期遅延も問題の一部です。そのため、問題を解く際はオートスケーリングの仕組み、インスタンスの起動までの時間、そしてヘルスチェックの初期遅延それぞれを理解し、それらがオートスケーリング時のインスタンスの増減にどう影響するかを把握することが重要です。<br>基本的な概念や原則：<br>管理インスタンスグループ：Google Cloudの機能で、同一の設定を持つインスタンスを一緒に管理し、自動的にスケーリングしたり修復したりすることができます。<br>オートスケーリング：リソースの使用状況に応じて自動的にインスタンス数を調整する機能です。CPU使用率などの指標に基づいて、必要に応じて新しいインスタンスを起動したり既存のインスタンスを終了したりします。<br>オートスケーリングポリシー：オートスケーリングの動作を決定するルールのセットです。どのメトリクスを使用し、どの程度の値を超えた場合にスケーリングを行うかなどが定義されています。<br>HTTPヘルスチェック：アプリケーションのインスタンスが正常に動作しているかどうかを確認するためのチェック方法です。HTTPリクエストをインスタンスに送信し、HTTPステータスコード200が返されれば正常と判断します。<br>初期遅延：ヘルスチェックが開始されるまでの時間を指します。初期遅延を長く設定すると、新しいインスタンスが起動してからヘルスチェックが開始されるまでの時間が長くなります。<br>TCPヘルスチェック：アプリケーションのインスタンスが正常に動作しているかどうかを確認するためのチェック方法です。TCP接続をインスタンスに送信し、接続が成功すれば正常と判断します。HTTPヘルスチェックと比較して、接続の確立のみを確認するため、アプリケーションの動作が確認できない場合があります。<br>最大インスタンス数：オートスケーリングにおけるインスタンスグループの最大サイズです。これ以上のインスタンスはオートスケーリングによって追加されません。<br>正解についての説明：<br>（選択肢）<br>・HTTPヘルスチェックの初期遅延を200秒に増やします<br>この選択肢が正解の理由は以下の通りです。<br>まず、ヘルスチェックの初期遅延は、管理されたインスタンスグループが新しいインスタンスを作成したとき、そのインスタンスがヘルスチェックの対象になるまでの時間を定義します。この時間が短すぎると、アプリケーションの起動に時間がかかる場合、ヘルスチェックはインスタンスがまだ起動していないことを検出し、その結果、インスタンスはアンヘルシーとみなすことがあります。<br>その後、オートスケーラは、このインスタンスが壊れているとみなして新しいインスタンスを作成しようとします。これが繰り返されると、オートスケーラはVMの数を過剰に増やす可能性があります。<br>よって、3分（または180秒）かかるとされるVMの起動時間を考慮し、それに適合するようにHTTPヘルスチェックの初期遅延を200秒に増やすことで、不要なインスタンスの追加を避け、オートスケール時に適切なインスタンス数を維持することができます。<br>不正解の選択肢についての説明：<br>選択肢：インスタンスの最大数を1に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンスの最大数を1に設定すると、オートスケーリングの目的が満たしません。オートスケーリングは負荷に応じて機能を拡張するためのもので、最大値を1に設定するとこれができなくなります。エンドユーザートラフィックのレベルをサポートするためには、最大数は必要に応じて増やすべきです。<br>選択肢：インスタンスの最大数を3に減らします<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンスの最大数を減らすことは、トラフィックの需要に対応する能力を減らす結果です。ユーザーが利用可能になるまでの時間を短縮することは可能ですが、一度に取り扱うことができるトラフィックの量を制限します。正解では、初期遅延を長くすることでアプリケーションがユーザ利用可能になるまでの待ち時間を考慮しています。<br>選択肢：HTTPヘルスチェックの代わりにTCPヘルスチェックを使用します<br>この選択肢が正しくない理由は以下の通りです。<br>TCPヘルスチェックを使用すると、インスタンスがトラフィックを受け取る準備ができているかどうかを効果的に判断することはできません。HTTPヘルスチェックは、アプリケーションが実際にトラフィックを受けられるレスポンスを提供できるかどうかを確認します。正解は初期遅延時間を増やすことで、インスタンスが起動し、トラフィックを受け取る準備ができるまでの実際の時間を反映させるべきです。'>
<div class='choice'> インスタンスの最大数を1に設定します</div>
<div class='choice'> インスタンスの最大数を3に減らします</div>
<div class='choice'> HTTPヘルスチェックの初期遅延を200秒に増やします</div>
<div class='choice'> HTTPヘルスチェックの代わりにTCPヘルスチェックを使用します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題26<br>メンテナンスが発生したときに利用できるように、10台のCompute Engineインスタンスを構成したいと考えています。要件には、これらのインスタンスがクラッシュした場合、自動的に再起動を試みることが明記されています。また、インスタンスは、システムメンテナンス中も含めて高可用性でなければなりません。<br>この要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「インスタンス用のインスタンステンプレートを作成します。"自動再起動"をオンに設定します。"オンホストメンテナンス"を"VMインスタンスの移行"に設定します。インスタンステンプレートをインスタンスグループに追加します」です。<br>この問題では、メンテナンス中にも高可用性を維持し、クラッシュ時に自動的に再起動を行う環境を作る方法が問われています。メンテナンス中の高可用性及びインスタンスの自動再起動の設定はCompute Engineのインスタンステンプレートを通じて行うことができます。また、高可用性を確保するためにはインスタンステンプレートをインスタンスグループに追加することが必要です。特定の設定をオンにしたり、特定の操作を行ったりすることが求められているため、これら要件を理解しつつ選択肢を評価することが重要です。<br>基本的な概念や原則：<br>インスタンステンプレート：Google Compute EngineでVMインスタンスを作成するための基本設定です。作成したテンプレートを再利用することで、同じ設定を持つVMインスタンスを繰り返し作成することができます。<br>自動再起動：VMインスタンスがシャットダウンやクラッシュを発生した際に、自動的にインスタンスを再起動する機能です。要件によっては重要な設定です。<br>オンホストメンテナンス：プロジェクトで設定するオプションで、ホストシステムのメンテナンスが発生した際のVMインスタンスの取り扱いを指定します。"VMインスタンスの移行"を選択すれば、メンテナンス中もインスタンスの利用を続けることができます。<br>インスタンスグループ：Compute Engineで同じ設定を持つインスタンスをまとめるための機能です。"自動再起動"をオンに設定し、"オンホストメンテナンス"を"VMインスタンスの移行"に設定したインスタンステンプレートをインスタンスグループに含めることで、高可用性を確保できます。<br>Autohealing：Compute Engineの自動修復機能で、インスタンスが正常でないことを検出すると自動的に修復しようとします。しかし、この設定だけでは高可用性を確保できません。<br>高可用性：システムが常に動作し続けることを保証する特性です。冗長化やフェイルオーバーなどの手法を用いて、システム全体のダウンタイムを最小限に抑えます。<br>正解についての説明：<br>（選択肢）<br>・インスタンス用のインスタンステンプレートを作成します。"自動再起動"をオンに設定します。"オンホストメンテナンス"を"VMインスタンスの移行"に設定します。インスタンステンプレートをインスタンスグループに追加します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Compute Engineのインスタンステンプレートは、VMインスタンスのプロパティ設定を保存するためのリソースであり、一貫性と再利用性を確保します。これにより、インスタンスがクラッシュした場合に自動的に再起動を試みる設定を適用することができます。そのため、"自動再起動"オプションを有効にすることで要件を満たすことができます。<br>加えて、"オンホストメンテナンス"オプションを"VMインスタンスの移行"に設定することで、システムメンテナンス時の対応も準備されます。システムメンテナンスが発生すると、Google CloudはVMインスタンスを自動的に再起動します。その際の移行により、インスタンスは高可用性を保持しつつ移行を行います。<br>そして、作成したインスタンステンプレートをインスタンスグループに追加することで、自動的にスケーリングとロードバランシングを行い、更なる可用性と耐障害性を確保します。<br>したがって、要件を満たす最適解です。<br>不正解の選択肢についての説明：<br>選択肢：インスタンス用のインスタンステンプレートを作成します。"自動再起動"をオフに設定します。"オンホストメンテナンス"をVMインスタンスの終了に設定します。インスタンステンプレートをインスタンスグループに追加します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、"自動再起動"をオフにすると、インスタンスがクラッシュした際、自動的に再起動を試みることができません。<br>次に、"オンホストメンテナンス"を"VMインスタンスの終了"に設定すると、システムメンテナンス中にインスタンスが停止されてしまい、高可用性が維持できません。<br>選択肢：インスタンスのインスタンスグループを作成します。"Autohealing"ヘルスチェックをヘルシー（HTTP）に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、この選択肢では"Autohealing"ヘルスチェックを使用することを推奨していますが、これはシステムクラッシュ時の自動再起動ではなく、インスタンスが反応しないときに新しいインスタンスを作成する機能です。<br>また、この選択肢ではシステムメンテナンス中の高可用性の提供方法について触れておらず、この部分では正解の選択肢の通り"オンホストメンテナンス"を"VMインスタンスの移行"に設定"することが必要です。<br>選択肢：インスタンスのインスタンスグループを作成します。"Advanced creation options"の"do not retry machine creation"の設定がオフになっていることを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>do not retry machine creationの設定をオフにするだけでは問題の要件を満たすことはできません、なぜならこの設定はインスタンスの作成失敗時に再試行するかどうかを制御しますが、インスタンスがクラッシュした際の自動再起動やシステムメンテナンス中の高可用性とは無関係です。'>
<div class='choice'> インスタンスのインスタンスグループを作成します。"Advanced creation options"の"do not retry machine creation"の設定がオフになっていることを確認します</div>
<div class='choice'> インスタンス用のインスタンステンプレートを作成します。"自動再起動"をオンに設定します。"オンホストメンテナンス"を"VMインスタンスの移行"に設定します。インスタンステンプレートをインスタンスグループに追加します</div>
<div class='choice'> インスタンス用のインスタンステンプレートを作成します。"自動再起動"をオフに設定します。"オンホストメンテナンス"をVMインスタンスの終了に設定します。インスタンステンプレートをインスタンスグループに追加します</div>
<div class='choice'> インスタンスのインスタンスグループを作成します。"Autohealing"ヘルスチェックをヘルシー（HTTP）に設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題27<br>あなたはGoogle Cloudサービスアカウントが、特定の時間に作成されたことを確認する必要があります。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「アクティビティログをフィルタリングして、構成カテゴリを表示します。リソースタイプをサービスアカウントに絞り込みます」です。<br>この問題では、特定のGoogle Cloudサービスアカウントが作成された時期を確認する方法について問われています。具体的には、アクティビティログのフィルタリングにより特定の情報を探し出す能力が必要です。アクティビティログをフィルタリングする際には、対象となるリソースタイプやカテゴリを正確に選択することが必須です。この場合、リソースタイプとして"サービスアカウント"を選択することが求められています。<br>基本的な概念や原則：<br>アクティビティログ：Google Cloudで行われるすべてのAPI呼び出しとイベント情報をトラッキングするシステムです。サービスアカウントが特定の時間に作成されたか確認する際には、このログをフィルタリングして探します。<br>サービスアカウント：アプリケーションや仮想マシン（VM）によって使用される特別な種類のGoogleアカウントです。これは特定の権限を持ち、特定のAPIを呼び出すことができます。<br>構成カテゴリ：ログエントリのタイプの一つで、管理対象リソースの状態を変更するAPI呼び出しを表します。サービスアカウントの作成はこのカテゴリに分類されます。<br>設定カテゴリ：ログエントリのタイプの一つで、管理対象リソースのステータスを変更せずに確認するAPI呼び出しを表します。<br>データアクセスカテゴリ：ログエントリのタイプの一つで、ユーザーデータや構成データにアクセスするためのAPI呼び出しを表します。サービスアカウントの作成はこのカテゴリには含まれません。<br>正解についての説明：<br>（選択肢）<br>・アクティビティログをフィルタリングして、構成カテゴリを表示します。リソースタイプをサービスアカウントに絞り込みます<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloudのアクティビティログは、プロジェクトや組織内のリソースで発生した各種のイベントを詳細に記録します。これには、リソースの作成、変更、削除などの管理アクティビティが含まれます。特定の時間に作成されたサービスアカウントを特定するためには、このアクティビティログを利用し、構成カテゴリをフィルタリングしてリソースタイプをサービスアカウントに絞り込むのが効果的です。これにより、その期間中に誰がどのような操作を行ったか、何が起こったかを的確に把握することができます。その結果、求める情報を効率的に得ることができます。<br>不正解の選択肢についての説明：<br>選択肢：アクティビティログをフィルタリングして、設定カテゴリを表示します。リソースの種類をGoogleプロジェクトに絞り込みます<br>この選択肢が正しくない理由は以下の通りです。<br>サービスアカウントが作成された特定の時間を確認するためには、アクティビティログをフィルタリングし、リソースタイプをサービスアカウントに絞り込む必要があります。不正解の選択肢はリソースタイプをGoogleプロジェクトに絞り込むため、サービスアカウントの情報を取得できません。<br>選択肢：アクティビティログをフィルタリングして、データアクセスカテゴリーを表示します。リソースタイプをサービスアカウントにフィルタリングします<br>この選択肢が正しくない理由は以下の通りです。<br>データアクセスカテゴリーはデータへのアクセスを追跡するものであり、サービスアカウントがいつ作成されたかを特定する目的には適していません。<br>一方、構成カテゴリではサービスアカウントの作成や変更などの管理活動を追跡でき、必要な情報をフィルタリングすることができます。<br>選択肢：アクティビティログをフィルタリングして、データアクセスカテゴリを表示します。リソースの種類をGoogleプロジェクトに絞り込みます<br>この選択肢が正しくない理由は以下の通りです。<br>試験の設定では、特定のサービスアカウントの作成時間を確認する必要があるのに対し、この選択肢ではデータアクセスカテゴリとGoogleプロジェクトに絞り込むため、特定のサービスアカウントの作成時間を確認できません。<br>一方、正解の選択肢では、構成カテゴリとサービスアカウントに絞り込むことで、作成時間を確認できます。'>
<div class='choice'> アクティビティログをフィルタリングして、構成カテゴリを表示します。リソースタイプをサービスアカウントに絞り込みます</div>
<div class='choice'> アクティビティログをフィルタリングして、データアクセスカテゴリを表示します。リソースの種類をGoogleプロジェクトに絞り込みます</div>
<div class='choice'> アクティビティログをフィルタリングして、設定カテゴリを表示します。リソースの種類をGoogleプロジェクトに絞り込みます</div>
<div class='choice'> アクティビティログをフィルタリングして、データアクセスカテゴリーを表示します。リソースタイプをサービスアカウントにフィルタリングします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題28<br>あなたの会社はデータウェアハウスにBigQueryを使用しています。長い時間をかけて、社内のさまざまな事業部門が、何百ものプロジェクトにわたって1000以上のデータセットを作成しました。CIOは、employee_ssnカラムを含むテーブルを見つけるために、すべてのデータセットを調査するよう求めています。あなたは、このタスクを実行する際の労力を最小限に抑えたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「Data Catalogにアクセスし、検索ボックスでemployee_ssnを検索します」です。<br>この問題では、BigQueryを使用した大規模なデータウェアハウス環境で特定のカラムを含むテーブルを短時間で見つける方法を尋ねています。社内に多くのプロジェクトとデータセットが存在することや、特定のカラム（employee_ssn）を含むテーブルを探すという要件から、Google Cloudの各種サービスの中でどのツールを使用すれば効率的にこのタスクが達成できるか、という視点で問題に取り組むことが求められます。この問題はSQLクエリやスクリプトによる手動の検索とAIやメタデータ管理ツールによる自動検索を比較し、どちらが適切かを判断するための問題と言えます。<br>基本的な概念や原則：<br>BigQuery：Google Cloudのフルマネージド、サーバレスデータウェアハウスです。大量のデータに対する高速なSQLクエリが可能です。<br>Data Catalog：Google Cloudの完全マネージドのメタデータ管理サービスです。簡単な検索と組織全体のデータ資産へのアクセスを提供します。<br>bqコマンドラインツール：BigQueryの操作をコマンドラインから行うためのツールです。データのロード、エクスポート、クエリといった操作が可能です。<br>INFORMATION_SCHEMA：SQL標準の情報スキーマで、データベースのメタデータに関する情報を提供します。COLUMNSビューを使用すると、テーブルのカラムに関する情報を得ることができます。<br>Cloud Dataflow：Google Cloudの完全マネージドのストリームおよびバッチ処理サービスです。大量のデータ処理任務を効率的に処理できます。<br>正解についての説明：<br>（選択肢）<br>・Data Catalogにアクセスし、検索ボックスでemployee_ssnを検索します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google CloudのData Catalogは、Google Cloudのデータ資産（BigQueryテーブルやデータセットなど）に対するメタデータ管理サービスです。Data Catalogを用いることで、データセットやテーブル、ビュー、その他のデータソースに対する一元的な検索や視覚化が可能になります。<br>この問題では、数多くのデータセット中から特定のカラム（employee_ssn）を含むテーブルを探し出す要求があります。このように膨大な量のデータ資産から特定の情報を探す場合には、Data Catalogの全文検索機能を活用することで、手間をかけずに目的の情報を見つけ出すことができます。これにより、どのデータセットにemployee_ssnカラムが含まれているのかを効率よく発見することができます。<br>不正解の選択肢についての説明：<br>選択肢：bqコマンドラインツールを使用して、組織内のすべてのプロジェクトをループ処理するシェルスクリプトを記述します<br>この選択肢が正しくない理由は以下の通りです。<br>bqコマンドラインツールを使用して、組織内のすべてのプロジェクトをループ処理するシェルスクリプトを記述するのは、非効率的で時間がかかる方法であり、労力を最小限に抑えるという要件を満たしません。<br>一方、Data Catalogを使用することでより効率的にemployee_ssnカラムを検索でき、労力を最小限に抑えることができます。<br>選択肢：組織内のすべてのプロジェクトをループし、INFORMATION_SCHEMA.COLUMNSビューでクエリを実行してemployee_ssn列を検索するスクリプトを記述します<br>この選択肢が正しくない理由は以下の通りです。<br>たしかにINFORMATION_SCHEMA.COLUMNSビューを使用してemployee_ssn列を検索するスクリプトを記述する方法は可能ですが、選択肢に求められている"労力を最小限に抑える"要件を満たしていません。これは比較的時間がかかり、一定のスキルが必要な作業です。<br>一方、Data Catalogを使用すると、一回の検索で必要な情報を得ることができ、大幅に作業を簡素化できます。<br>選択肢：組織内のすべてのプロジェクトをループし、INFORMATION_SCHEMA.COLUMNSビューでクエリを実行してemployee_ssn列を見つけるCloud Dataflowジョブを記述します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、この選択肢が提案するCloud Dataflowジョブの記述は、タスクを実行する際の労力を最小限に抑えるという要求に反しています。<br>一方、正解の選択肢にあるData Catalogの利用は、必要な情報を直接検索できるため、より効率的で負担が少ない方法を提供します。'>
<div class='choice'> 組織内のすべてのプロジェクトをループし、INFORMATION_SCHEMA.COLUMNSビューでクエリを実行してemployee_ssn列を検索するスクリプトを記述します</div>
<div class='choice'> 組織内のすべてのプロジェクトをループし、INFORMATION_SCHEMA.COLUMNSビューでクエリを実行してemployee_ssn列を見つけるCloud Dataflowジョブを記述します</div>
<div class='choice'> Data Catalogにアクセスし、検索ボックスでemployee_ssnを検索します</div>
<div class='choice'> bqコマンドラインツールを使用して、組織内のすべてのプロジェクトをループ処理するシェルスクリプトを記述します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題29<br>あなたは、Google CloudプロジェクトでConfig Connectorが管理するPub/Subトピックを完全に削除したいと考えています。<br>この要件を満たすためには、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「kubectlを使用してトピックリソースを削除します」です。<br>この問題では、Google CloudプロジェクトでConfig Connectorが管理するPub/Subトピックの削除について問われています。Config ConnectorはKubernetesを用いてGoogle Cloudのリソースを管理するためのツールであり、そのため本質的にKubernetesの操作方法に関する問題です。したがって、問題解決のためには、Config Connectorに関係する操作がどのように行われるかを理解する必要があります。誤った選択肢を選ばないためには、Kubernetesやkubectlの使い方、そしてConfig Connectorがどう働くかについての基本的知識が必要でしょう。<br>基本的な概念や原則：<br>Config Connector：Google CloudプロジェクトのリソースをKubernetesスタイルのAPIやツールで管理するためのサービスです。Kubernetes標準のkubectlコマンドを使用して、Google Cloudリソースのライフサイクルを管理します。<br>Pub/Subトピック：Google Cloud Pub/Subにおけるメッセージングのエンドポイントです。メッセージの発信者はトピックにメッセージを送り、受信者はトピックからメッセージを受け取ります。<br>kubectl：KubernetesのCLIツールで、Kubernetesクラスターやリソースの管理に使用します。Create、Get、Update、Deleteなどの操作をサポートしています。<br>gcloud CLI：Google Cloudのコマンドラインインターフェースツールです。Google Cloudリソースの作成、操作、管理を行うことができます。しかし、Config Connectorの管理下にあるリソースに対する操作は推奨されません。<br>正解についての説明：<br>（選択肢）<br>・kubectlを使用してトピックリソースを削除します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Config ConnectorはKubernetes APIを通じてGoogle Cloudリソースを作成、管理するためのツールで、これを使ってCloud Pub/Subのトピックやその他のGoogle Cloudのサービスを簡単に管理できます。kubectlはKubernetesのコマンドラインツールで、Google Kubernetes Engine（GKE）クラスターやその他のKubernetesクラスター上にあるリソースを制御するために使われます。<br>なので、Config Connectorが管理するPub/Subトピックを完全に削除するためには、kubectlを使用して該当のトピックリソースを削除すれば良いです。kubectl deleteコマンドを使用すれば、Google Cloudプロジェクトが所有するトピックを削除するための設定を行うことができます。これにより、指定されたトピックリソースがすぐに削除されるため、要件を満たす最善の選択肢です。<br>不正解の選択肢についての説明：<br>選択肢：kubectlを使用して、deleted-by-cnrmラベルを作成し、その値をトピックリソースのtrueに変更します<br>この選択肢が正しくない理由は以下の通りです。<br>deleted-by-cnrmラベルを作成し値をtrueに設定するアクションは存在しません。その代わりに、kubectlを使用して直接トピックリソースを削除すれば、Config ConnectorによってPub/Subトピックも削除されます。<br>選択肢：gcloud CLIを使用してトピックを削除します<br>この選択肢が正しくない理由は以下の通りです。<br>Config ConnectorはGoogle CloudリソースをKubernetesオブジェクトとして管理し、そのライフサイクルを制御します。そのため、Config Connectorが管理するリソースを削除する場合はkubectlを使用します。gcloud CLIは直接的なGoogle Cloudリソース管理に使用されますが、Config Connectorが管理するリソースに対する操作は裏で同期されないため、これが使用できません。<br>選択肢：gcloud CLIを使用して、トピックラベルmanaged-by-cnrmをfalseに更新します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud CLIを使用してトピックラベルmanaged-by-cnrmをfalseに更新すると、Config Connectorの管理が解除されますが、トピック自体は削除されません。<br>それに対して、kubectlを使ってトピックリソースを削除すると、そのトピックが完全に削除されます。'>
<div class='choice'> kubectlを使用して、deleted-by-cnrmラベルを作成し、その値をトピックリソースのtrueに変更します</div>
<div class='choice'> gcloud CLIを使用して、トピックラベルmanaged-by-cnrmをfalseに更新します</div>
<div class='choice'> gcloud CLIを使用してトピックを削除します</div>
<div class='choice'> kubectlを使用してトピックリソースを削除します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題30<br>本番アプリケーションをホストしているCompute Engineインスタンスがあります。インスタンスがCPUリソースの90%以上を15分以上消費した場合、電子メールを受け取りたいと考えています。また、このためにGoogleのサービスを使用したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「1.Cloud Monitoring Workspaceを作成し、Google Cloudプロジェクトを関連付けます<br>2.閾値をトリガー条件として使用するCloud Monitoringアラートポリシーを作成します<br>3.通知チャネルにメールアドレスを設定します」です。<br>この問題では、Compute EngineインスタンスのCPU利用率が一定の閾値を超えた際に電子メール通知を受け取る方法を尋ねています。Googleのサービスが活用され、問題は具体的にどのGoogleサービスを組み合わせて使用することで要件を満たすかが焦点になります。ヒントとなるのはCompute EngineのCPU利用率の監視と電子メール通知の要件で、これらを満たす適切なサービスを選択することが求められています。それぞれの選択肢が提供する機能とその適用可能性を理解し、それらを問題の前提とマッチングさせることが重要です。<br>基本的な概念や原則：<br>Cloud Monitoring：Google Cloudの監視、診断、およびアラート作成サービスです。システム全体のパフォーマンスと稼働率を確認し、問題が発生したときに通知を受け取ることができます。<br>Workspace：Cloud Monitoringの概念で、モニタリングするリソースとアラートの設定をまとめて管理するためのスペースです。<br>アラートポリシー：特定の条件が満たされたときに通知を送るための設定です。例えば、CPUリソースの利用率が特定の閾値を超えた場合に通知を送るように設定することができます。<br>通知チャネル：アラートを受け取る場所や方法を指定する設定です。電子メール、SMS、チャットなど様々な種類の通知チャネルが存在します。<br>CPUリソース利用率：Compute EngineインスタンスのCPUが使用されている割合です。高い値はCPUが過負荷になっている可能性を示し、アラートのトリガーとして使用されます。<br>Cloud Logging：Google Cloudのログ管理サービスです。システムやアプリケーションのログを集中管理し、分析や監視に使用することができます。しかし、このケースではCPUリソース利用率の監視には不適切です。<br>SMTPサーバー：メールの送信を行うサーバーのことです。指定されたGmailのSMTPサーバーでメールを自動送信するスクリプトを書くという選択肢は手間がかかり、Googleの監視サービスを利用していないため不適切です。<br>正解についての説明：<br>（選択肢）<br>・1.Cloud Monitoring Workspaceを作成し、Google Cloudプロジェクトを関連付けます<br>2.閾値をトリガー条件として使用するCloud Monitoringアラートポリシーを作成します<br>3.通知チャネルにメールアドレスを設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud Monitoringは、Google Cloud上で実行されているアプリケーションについての洞察を得るための強力なツールです。Computing Engineインスタンスなどの各Google Cloudリソースのパフォーマンスの監視を可能にします。Cloud Monitoring Workspaceを作成することにより、あなたのプロジェクトのリソースを監視する基盤となるダッシュボードを提供します。<br>次に、閾値をトリガー条件として使用するCloud Monitoringアラートポリシーを作成することで、CPUリソースの消費が90%以上になったときにアラートをトリガーする条件を設定することが可能になります。このアクション結果として、CPU消費が予定値を超えた場合の通知を確立して受信することができます。<br>最後に、通知チャネルにメールアドレスを設定することにより、あなたが求めている通知方法、すなわち電子メールでの通知を受け取れます。これらすべての操作により、本番アプリケーションがCPUリソースの90%以上を長時間消費したことをすぐに認識し、必要な対策を講じることが可能になります。<br>不正解の選択肢についての説明：<br>選択肢：1.Gmailアカウントを作成します<br>2.CPU使用率を監視するスクリプトを書きます<br>3.CPU使用率が閾値を超えたら、そのスクリプトに、Gmailアカウントとポート25のsmtp.gmail.comをSMTPサーバーとして使用して電子メールを送信させます<br>この選択肢が正しくない理由は以下の通りです。<br>スクリプトを書くという方法は手動的であり、GmailアカウントやSMTPサーバーを利用して通知を送ることはGoogleサービスの効率的な利用ではありません。<br>また、この方法は一部の技術的な知識を必要とし、メンテナンスも必要です。<br>それに対して、Cloud MonitoringはGoogleのサービスであり、自動的に監視し通知を送ることができます。よってより簡単かつ効率的です。<br>選択肢：1.Cloud Monitoring Workspaceを作成し、Google Cloudプロジェクトを関連付けます<br>2.CPU使用率を監視し、Cloud Monitoringにカスタムメトリクスとして送信するスクリプトを記述します<br>3.Cloud Monitoringでインスタンスの稼働時間チェックを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>カスタムメトリクスを作成するスクリプトを記述する必要はありません。Compute EngineはすでにCPU使用率などのメトリクスを提供しており、それらを使ってアラートポリシーを作成することができます。<br>また、監視対象としてCPU使用率を選択すべきであり、インスタンスの稼働時間では達成が難しいです。<br>選択肢：1.Cloud Loggingで、次の正規表現を使用してCPU使用率を抽出するログベースのメトリクスを作成します：CPU使用率：([0-9] {1,3})% 2<br>2.Cloud Monitoringで、このメトリクスに基づいてアラートポリシーを作成します<br>3.通知チャネルでメールアドレスを設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Loggingはログデータを収集・分析するためのものであり、CPU使用率のようなシステムパフォーマンス指標を直接抽出するためのツールではありません。この機能はあくまでCloud Monitoringのロールであるため、正規表現を使用してCPU使用率をCloud Loggingで抽出しようとするこのアプローチは不適切です。'>
<div class='choice'><br>1.Cloud Monitoring Workspaceを作成し、Google Cloudプロジェクトを関連付けます<br>2.閾値をトリガー条件として使用するCloud Monitoringアラートポリシーを作成します<br>3.通知チャネルにメールアドレスを設定します</div>
<div class='choice'><br>1.Cloud Loggingで、次の正規表現を使用してCPU使用率を抽出するログベースのメトリクスを作成します：CPU使用率：([0-9] {1,3})% 2<br>2.Cloud Monitoringで、このメトリクスに基づいてアラートポリシーを作成します<br>3.通知チャネルでメールアドレスを設定します</div>
<div class='choice'><br>1.Cloud Monitoring Workspaceを作成し、Google Cloudプロジェクトを関連付けます<br>2.CPU使用率を監視し、Cloud Monitoringにカスタムメトリクスとして送信するスクリプトを記述します<br>3.Cloud Monitoringでインスタンスの稼働時間チェックを作成します</div>
<div class='choice'><br>1.Gmailアカウントを作成します<br>2.CPU使用率を監視するスクリプトを書きます<br>3.CPU使用率が閾値を超えたら、そのスクリプトに、Gmailアカウントとポート25のsmtp.gmail.comをSMTPサーバーとして使用して電子メールを送信させます</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題31<br>現在、2つのvCPUと4GBのメモリで構成されている仮想マシンがあります。メモリが不足しています。仮想マシンを8GBのメモリにアップグレードしたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「VMを停止し、メモリを8GBに増やし、VMを起動します」です。<br>この問題では、仮想マシンのメモリを増やすための正しい手順を理解することが重要です。既存の仮想マシンのメモリを増加させるためには、VMの稼働を停止し、必要なメモリにしたがってメモリ設定を変更し、再度起動する必要があります。それぞれの選択肢が、このプロセスを正確に満たすかどうかを評価し、最も適切な手順を選ぶことが求められています。<br>基本的な概念や原則：<br>仮想マシン（VM）のメモリアップグレード：Google Cloudでは、仮想マシンのメモリやvCPUをアップグレードするためには、まず仮想マシンを停止し、必要なサイズに変更した後、仮想マシンを再起動する必要があります。<br>ライブマイグレーション：実行中のVMを別のホストに移動させるプロセスです。しかし、これはホストのメンテナンスやアップグレードのためにGoogle Cloudが行うものであり、ユーザーが任意でメモリを増やすために使用するものではありません。<br>gcloud：Google Cloudのコマンドラインツールです。このツールを使用してVMの設定を変更することも可能ですが、メモリの増加にはVMの再起動が必要です。<br>マシンタイプ：Google Cloudは様々なマシンタイプを提供しており、それぞれが異なるvCPUとメモリ量の組み合わせを持っています。しかし、単にメモリを増やしたいだけの場合、マシンタイプの変更は適切ではありません。<br>正解についての説明：<br>（選択肢）<br>・VMを停止し、メモリを8GBに増やし、VMを起動します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloudの仮想マシン（VM）では、メモリやCPUなどのリソースの割り当て調整は、仮想マシン（VM）が停止している状態でのみ行うことができます。<br>したがって、まず仮想マシンを停止する必要があります。それから、設定を変更してメモリを8GBに増やします。この変更を行った後は、変更を適用するために仮想マシンを再度起動する必要があります。以上の手順を確実に行うことで、仮想マシンのメモリを8GBにアップグレードする要件を満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：より多くのメモリを搭載したマシンにワークロードを移動するために、ライブマイグレーションに頼ります<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloudでは、ライブマイグレーション機能を利用してメモリを増やすことはできません。メモリを増やすには、VMを停止し、設定を変更して再起動する必要があります。<br>したがって、この選択肢は該当の要件を満たすための適切な手段ではありません。<br>選択肢：gcloudを使ってVMにメタデータを追加します。キーをrequired-memory-sizeに、値を8GBに設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloudでは、仮想マシンのメモリを増やすためには、実際にVMを停止し、メモリを8GBに変更し、再起動する操作が必要です。メタデータを追加することでメモリサイズを変更することはできません。<br>選択肢：VMを停止し、マシンタイプをn1-standard-8に変更してVMを起動します<br>この選択肢が正しくない理由は以下の通りです。<br>n1-standard-8はメモリが30GBでvCPUも8つになるマシンタイプなので、メモリを8GBに増やすという要件には適合しますが、必要以上のリソースを与えてしまい、コストが掛かりすぎる結果を生む可能性があるためです。<br>一方、VMを停止してメモリを8GBに上げ、VMを起動する選択肢は、要件を的確に満たしています。'>
<div class='choice'> gcloudを使ってVMにメタデータを追加します。キーをrequired-memory-sizeに、値を8GBに設定します</div>
<div class='choice'> VMを停止し、マシンタイプをn1-standard-8に変更してVMを起動します</div>
<div class='choice'> VMを停止し、メモリを8GBに増やし、VMを起動します</div>
<div class='choice'> より多くのメモリを搭載したマシンにワークロードを移動するために、ライブマイグレーションに頼ります</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題32<br>以下の2つのYAMLファイルを使用して、Google Kubernetes Engineクラスター内に新しいアプリケーションをデプロイしました。<br>（YAML 1）<br>apiVersion: apps/v1<br>kind: Deployment<br>metadata:<br>name: myapp-deployment<br>spec:<br>selector:<br>matchLabels:<br>app: myapp<br>replicas: 2<br>template:<br>metadata:<br>labels:<br>app: myapp<br>spec:<br>containers:<br>- name: myapp<br>image: myapp:1.1<br>ports:<br>- containerPort: 80<br>（YAML 2）<br>apiVersion: v1<br>kind: Service<br>metadata:<br>name: myapp-service<br>spec:<br>ports:<br>- port: 8000<br>targetPort: 80<br>protocol: TCP<br>selector:<br>app: myapp<br>デプロイされたポッドのステータスを確認すると、そのうちの1つがまだPENDINGステータスであることに気づきました：<br>そのポッドがペンディングステータスに留まっている原因を突き止めたいと思います。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「myapp-deployment-11aabbb222-1a22bポッドの詳細を確認し、警告メッセージがないかチェックします」です。<br>この問題では、Google Kubernetes Engine（GKE）のクラスター内にデプロイしたポッドのうち1つがPendingステータスに留まっている原因を求めています。Pendingステータスは、リソースがまだスケジュールされていないことを意味します。そのため、そのポッドがPendingステータスに留まっている理由を探り出すためには、該当するポッドの詳細を調査することが第一歩です。必要なリソース、設定、または依存関係が不足していたり、問題がある可能性があります。それらは通常、ポッドの詳細情報や警告メッセージに表示されます。<br>基本的な概念や原則：<br>Google Kubernetes Engine: Google CloudのマネージドKubernetesサービスです。ワークロードを自動化、管理、スケーリングし、デプロイすることができます。<br>Deployment（Kubernetes）：Kubernetesのリソースの一つで、同じポッドの複製を管理し、更新とロールバックを自動化します。<br>Service（Kubernetes）：Kubernetesのリソースの一つで、一連のポッドへのネットワークトラフィックを抽象化し、アクセスを制御します。<br>Pod（Kubernetes）：Kubernetesの基本的なデプロイユニットで、一つ以上のコンテナが同じ環境下で動作します。<br>ポッドのステータス（Pending）：ポッドがまだクラスターノード上にスケジュールされていないことを示します。リソースの不足や他の制約条件が原因です。<br>正解についての説明：<br>（選択肢）<br>・myapp-deployment-11aabbb222-1a22bポッドの詳細を確認し、警告メッセージがないかチェックします<br>この選択肢が正解の理由は以下の通りです。<br>まず、KubernetesのポッドのステータスがPendingとなる場合、一般的にはポッドがまだノードにスケジュールされていない、つまり、ポッドが動作するべきノードが決まっていないことや、指定されているリソース要求が満たせないなどの理由が考えられます。<br>したがって、問題を特定するためには、ポッドの詳細情報の確認が必要です。ポッドの詳細情報には、ポッドの状態、再起動回数、ポッドがスケジュールされたノード、ポッドのイベントなどが含まれます。これらの情報を見ることで、たとえば、ポッドが何らかの理由でスケジュールできないなど、問題の原因を突き止めることができます。<br>正解の選択肢は、これらの情報を確認する行為を指しているため、この要件を満たす適切な解答です。<br>不正解の選択肢についての説明：<br>選択肢：myapp-serviceサービスオブジェクトの詳細を確認し、エラーメッセージをチェックします<br>この選択肢が正しくない理由は以下の通りです。<br>問題はポッドがPendingステータスにあることで、サービスオブジェクトではなく、ポッド状態やその警告メッセージを確認することで、Pending状態の原因を特定できます。サービスはポッドへのネットワーク接続を高めますが、ポッドのスケジューリングや起動とは直接関係ありません。<br>したがって、サービスオブジェクトのエラーメッセージを確認することは、本問題を解決するための適切な手段ではありません。<br>選択肢：myapp-deployment Deploymentオブジェクトの詳細を確認し、エラーメッセージをチェックします<br>この選択肢が正しくない理由は以下の通りです。<br>ポッドのステータスはDeploymentオブジェクトではなく、それぞれのポッド自体に関連しています。<br>したがって、問題解決のためには該当のポッドの詳細を直接確認することが必要です。<br>それに対して、Deploymentオブジェクトの詳細を確認しても、ポッドがPendingステータスになっている具体的な原因を知ることはできません。<br>選択肢：myapp-deployment-11aabbb222-1a22bポッドのコンテナのログを表示し、警告メッセージがないか確認します<br>この選択肢が正しくない理由は以下の通りです。<br>ポッドがまだPENDING状態ということは、そのポッド内のコンテナはまだ起動していないということです。<br>従って、コンテナのログを確認しても、まだ何も出力されていないため、問題の特定に役立ちません。そのため、ポッドの詳細を確認することが正しい対応です。'>
<div class='choice'> myapp-deployment-11aabbb222-1a22bポッドの詳細を確認し、警告メッセージがないかチェックします</div>
<div class='choice'> myapp-serviceサービスオブジェクトの詳細を確認し、エラーメッセージをチェックします</div>
<div class='choice'> myapp-deployment-11aabbb222-1a22bポッドのコンテナのログを表示し、警告メッセージがないか確認します</div>
<div class='choice'> myapp-deployment Deploymentオブジェクトの詳細を確認し、エラーメッセージをチェックします</div>
</div>
            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>