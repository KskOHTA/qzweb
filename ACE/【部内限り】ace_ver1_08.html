<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Cloud Leader問題集 08</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">
<div class='question' data-multiple='FALSE' data-question='問題1<br>平日の午前9時から午後6時の間に使用されるアプリケーションをホストするCompute Engineインスタンスがあります。ディザスタリカバリのために、このインスタンスを毎日バックアップしたいと考えています。バックアップは30日間保存したいと考えています。管理オーバーヘッドが最も少なく、サービス数が最も少ないGoogle推奨のソリューションを利用したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「1.Cloud Consoleで、Compute Engine Disksページに行き、インスタンスのディスクを選択します<br>2.Snapshot Scheduleセクションで、Create Scheduleを選択し、次のパラメータを設定します：開始時間： 1:00 AM" 2:00 AM、スナップショットの自動削除：30日後」です。<br>この問題では、平日の指定された時間に使用されるCompute Engineインスタンスを毎日バックアップし、バックアップは30日間保持するという要件があります。この要件を満たす最も管理オーバーヘッドが少なく、Googleが推奨するソリューションを選択することが求められています。必要な情報は主に仕様とGoogle Cloudのバックアップ関連機能の理解に依存します。その要件を満たすための最適なソリューションを見つける際には、管理の簡易さとGoogleの推奨を重視する必要があります。この観点から解答選択肢を検討し適切なものを選びます。<br>基本的な概念や原則：<br>Compute Engine：Google Cloudの仮想マシン（VM）サービスで、開発者はVMインスタンスを起動して、任意の仮想化されたハードウェア上でアプリケーションを動かすことができます。<br>Compute Engine Disks：Compute Engineの永続ディスクで、VMインスタンスのブートディスクとして、または追加のストレージとして利用できます。<br>Snapshot：Compute Engine Disksの内容を完全に保存する方法で、ディスクのバックアップや新しいディスクの作成に使われます。<br>Snapshot Schedule：Compute Engineでは、定期的にディスクスナップショットを作成するようスケジュールを設定できます。これには、スナップショットの取得時間と保持期間を指定できます。<br>Cloud Console：Google Cloudの管理と操作のためのウェブベースのインターフェースです。すべてのGoogle Cloudサービスを視覚的に管理できます。<br>Cloud Scheduler：Google Cloudのフルマネージド型cronジョブスケジューラーで、任意の時間間隔でジョブを実行するスケジュールを設定できます。しかし、Compute EngineのSnapshot Schedule機能を使う方が管理オーバーヘッドが少なくなります。<br>Cloud Function：Google Cloudのサーバレス実行環境で、特定のイベントに対する応答としてコードを実行することができます。しかし、Compute EngineのSnapshot Schedule機能を使う方が管理オーバーヘッドが少なくなります。<br>正解についての説明：<br>（選択肢）<br>・1.Cloud Consoleで、Compute Engine Disksページに行き、インスタンスのディスクを選択します<br>2.Snapshot Scheduleセクションで、Create Scheduleを選択し、次のパラメータを設定します：開始時間： 1:00 AM" 2:00 AM、スナップショットの自動削除：30日後<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud ConsoleからCompute Engineのディスク設定にアクセスし、スナップショットスケジュールを作成する方法を選択したのは適切です。この機能を使うと、簡単な設定だけでディスクの定期的なスナップショットを作成し、自動的に旧スナップショットを削除することができます。これにより、必要なバックアップを作成しつつ管理の手間を最小限に抑えられます。<br>また、設定の詳細である"開始時間：1:00 AM - 2:00 AM"スナップショットの自動削除：30日後"という設定も適切です。開始時間が早朝の1時から2時とすることで、アプリケーションが稼働している平日の午前9時から午後6時とは充分に時間をずらすことができ、バックアップ作業によるアプリケーション性能の影響を最小化します。スナップショットの自動削除を30日後に設定することで、バックアップの保存期間を適切に管理することができます。これらの設定により、Google推奨のソリューションを最小限の手間で活用し、求められていた要件を満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：1.インスタンスのメタデータを更新し、以下の値を追加します：0 1 * * * 2.インスタンスのメタデータを更新し、以下の値を追加します：30<br>この選択肢が正しくない理由は以下の通りです。<br>まず、Compute Engineインスタンスのメタデータを更新しても、定期的なバックアップスケジュールを作成することはできません。<br>また、インスタンスのメタデータを更新しても、スナップショットの自動削除期間を設定することもできません。これらの機能はSnapshot Scheduleを使用することで直接的に設定できます。<br>選択肢：1.インスタンスのディスクのスナップショットを作成するCloud Functionを作成します<br>2.30日以上前のスナップショットを削除するCloud Functionを作成します<br>3.Cloud Schedulerを使用して、両方のCloud Functionを毎日午前1時にトリガーします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud FunctionとCloud Schedulerを使う方法は、管理オーバーヘッドが大きいです。<br>また、これらのサービス数が正解の選択肢よりも多くなるため、Googleの推奨ソリューション、つまり、シンプルで効率的なソリューションとは一致しません。正解の選択肢はSnapshot Scheduleを使用することで、管理オーバーヘッドを減らし、サービスの数も少なくなります。<br>選択肢：1.ディスクの内容をCloud Storageにコピーするbashスクリプトをインスタンスに作成します<br>2.バックアップCloud Storageバケット内の30日以上前のデータを削除するbashスクリプトをインスタンスに作成します<br>3.これらのスクリプトを毎日午前1時に実行するようにインスタンスのcrontabを設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Compute Engineのスナップショットスケジュール機能を使用しないと、スクリプトの管理とトラブルシューティングに過剰な手間がかかります。<br>また、スクリプト方式ではCompute Engineのスナップショットが提供するデータ一貫性などの恩恵を受けられません。管理やサービスの数を最小化する観点から見て、不適切です。'>
<div class='choice'><br>1.ディスクの内容をCloud Storageにコピーするbashスクリプトをインスタンスに作成します<br>2.バックアップCloud Storageバケット内の30日以上前のデータを削除するbashスクリプトをインスタンスに作成します<br>3.これらのスクリプトを毎日午前1時に実行するようにインスタンスのcrontabを設定します</div>
<div class='choice'><br>1.インスタンスのメタデータを更新し、以下の値を追加します：0 1 * * *<br>2.インスタンスのメタデータを更新し、以下の値を追加します：30</div>
<div class='choice'><br>1.Cloud Consoleで、Compute Engine Disksページに行き、インスタンスのディスクを選択します<br>2.Snapshot Scheduleセクションで、Create Scheduleを選択し、次のパラメータを設定します：開始時間： 1:00 AM" 2:00 AM、スナップショットの自動削除：30日後</div>
<div class='choice'><br>1.インスタンスのディスクのスナップショットを作成するCloud Functionを作成します<br>2.30日以上前のスナップショットを削除するCloud Functionを作成します<br>3.Cloud Schedulerを使用して、両方のCloud Functionを毎日午前1時にトリガーします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題2<br>Deployment Managerで、配置のリソースをダウンタイムさせずに配置を更新する必要があります。<br>どのコマンドを使用する必要がありますか？' data-answer='3' data-explanation='解説<br>正解は「gcloud deployment-manager deployments update --config」です。<br>この問題では、Deployment Managerを使用したリソースのダウンタイム無しでの配置更新の方法について問われています。選択肢からは、gcloudコマンドを使用した操作が求められています。ここで、具体的なコマンドの違いを理解し、どのコマンドが配置の更新に適しているかを見極めることが求められます。配置の更新なので、新規作成ではなく既存リソースの更新に着目することが重要です。<br>基本的な概念や原則：<br>Deployment Manager： Google Cloudのインフラストラクチャの作成と管理を自動化するためのサービスです。設定ファイルを使って、リソースのデプロイメントを定義、作成、変更することができます。<br>gcloud deployment-manager deployments update --config：Deployment Managerでのデプロイメントの更新に使用します。既存のリソースを修正または置き換えることができます。ダウンタイム無しでデプロイメントを更新するためのコマンドです。<br>gcloud deployment-manager deployments create --config：Deployment Managerでの新規デプロイメントの作成に使用します。新たにリソースを作成します。<br>gcloud deployment-manager resources create --config、gcloud deployment-manager resources update --config：これらのコマンドは存在しません。Deployment Managerの操作は基本的にデプロイメントレベルで行います。<br>正解についての説明：<br>（選択肢）<br>・gcloud deployment-manager deployments update --config<br>この選択肢が正解の理由は以下の通りです。<br>まず、Deployment Managerは、Google Cloudリソースの作成、更新、削除を自動化し、再利用可能なテンプレートを提供するインフラストラクチャアズコード（IaC）ツールです。Deployment Manager利用者は、YAML構成ファイルを用意し、その構成ファイルを使用してテンプレートを作成及び変更します。正解の選択肢である"gcloud deployment-manager deployments update --config" コマンドは、Deployment Managerで配置を更新するためのものであり、--configオプションは更新設定のYAMLファイルを指定するためのものです。これにより、現在のデプロイメントのリソース設定を新しい設定で上書きすることができます。<br>また重要な点として、Deployment Managerは既存のリソースが更新時に影響を受けない状態で新しい設定を適用します。すなわち、このコマンドを使用することでダウンタイムを発生させずに配置のリソースを更新することが可能となり、この選択肢が正解です。<br>不正解の選択肢についての説明：<br>選択肢：gcloud deployment-manager deployments create --config<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud deployment-manager deployments create --config コマンドは新たに配置を作成するためのもので、既存の配置を更新するためには使用できません。<br>逆に、"gcloud deployment-manager deployments update --config"コマンドは既存の配置をダウンタイム無しで更新できます。<br>選択肢：gcloud deployment-manager resources create --config<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud deployment-manager resources create --configは新しいリソースを作成するためのコマンドです。既存の配置を更新するためには、正解の選択肢であるgcloud deployment-manager deployments update --configを使用する必要があります。ダウンタイムなしで既存のリソースを更新するためには新しくリソースを作成することではなく、既存のデプロイメントを更新する操作が求められています。<br>選択肢：gcloud deployment-manager resources update --config<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud deployment-manager resources update --configは有効なコマンドではありません。Deployment Managerで配置更新を行う正しいコマンドは"gcloud deployment-manager deployments update --config"です。このコマンドにより、配置名と設定ファイルが指定され、ダウンタイムなしでリソースの更新が行えます。'>
<div class='choice'> gcloud deployment-manager resources update --config</div>
<div class='choice'> gcloud deployment-manager deployments create --config</div>
<div class='choice'> gcloud deployment-manager resources create --config</div>
<div class='choice'> gcloud deployment-manager deployments update --config</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題3<br>あなたは、複雑なDeployment Managerテンプレートを大幅に変更し、プロジェクトにコミットする前に、定義されたすべてのリソースの依存関係が適切に満たされていることを確認したいと考えています。自分の変更について最も迅速なフィードバックが必要です。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「同じプロジェクトで"--previewオプションを使用してDeployment Managerテンプレートを実行し、相互依存するリソースの状態を観察します」です。<br>この問題では、Deployment Managerテンプレートの変更を行った後、リソースの依存関係が適切に満たされているかどうかを確認する方法を求められています。提示された選択肢を見て、リソースの状態を効率的に観察・確認できて、かつ問題文で要求されている"最も迅速なフィードバック"を提供できる手法を選ぶ必要があります。選択する方法は、導入前のデバッグやトラブルシューティングに最も適したものであるべきです。<br>基本的な概念や原則：<br>Deployment Manager：Google Cloud上でインフラストラクチャを自動化し、管理するためのサービスです。リソースの作成、更新、削除を自動化するテンプレートを使用します。<br>--previewオプション：Deployment Managerでテンプレートを実行する際、実際に各リソースを作成する前に、プロビジョニングプロセスをシミュレートするオプションです。依存関係などテンプレートのエラーチェックを行うときに使用されます。<br>リソースの依存関係：多数のクラウドリソース間で存在する、一つのリソースが他のリソースに依存して動作する関係です。適切な依存関係が構築されていないと、リソースの作成や更新が失敗する可能性があります。<br>Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムからのログ情報を一元管理し、分析することができます。ただし、テンプレートの依存関係を確認する場合には、必ずしも適切なフィードバックを提供できないことがあります。<br>正解についての説明：<br>（選択肢）<br>・同じプロジェクトで"--previewオプションを使用してDeployment Managerテンプレートを実行し、相互依存するリソースの状態を観察します<br>この選択肢が正解の理由は以下の通りです。<br>Deployment Managerの--previewオプションは、実際に変更を適用する前にプロジェクト全体の状態を視覚化し、テンプレートの実行をシミュレートする機能を提供します。これにより、予期せぬエラーや依存関係の問題を早期に検出できます。具体的には、--previewオプションを利用すると、Deployment Managerは指定したテンプレートの実行計画を作成し、その結果を表示しますが、実際のリソースは作成または修正しません。つまり、テンプレートの変更が意図したとおりに機能するかどうかを確認するための安全な方法です。これにより複雑なDeployment Managerテンプレートの変更を行っても、事前に確認できるためリスクを低減することができます。このため、最も迅速なフィードバックが必要な状況では、--previewオプションの使用が最適です。<br>不正解の選択肢についての説明：<br>選択肢：Pythonで作成されたDeployment Managerテンプレート内で、きめ細かいロギングステートメントを使用します<br>この選択肢が正しくない理由は以下の通りです。<br>きめ細かいロギングステートメントを使用すると、Deployment Managerテンプレートの動作についての情報を得ることができますが、それはリソースの依存関係が適切に満たされているかを確認することには直接寄与しません。<br>一方、"--preview"オプションを使用すれば、テンプレートが作成または更新しようとするリソースの状態を具体的に確認できます。<br>選択肢：Google Cloud ConsoleのCloud Loggingページで、Deployment Managerの実行アクティビティを監視します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud LoggingでDeployment Managerの実行アクティビティを監視することでは、依存関係が適切に満たされているかを事前に確認することができません。これは、すでにテンプレートが実行された後のログ情報を確認するものです。<br>一方、"--preview"オプションはテンプレートの実行前に依存関係を確認することが可能で、迅速なフィードバックを得ることができます。<br>選択肢：同じ構成を持つ別のプロジェクトに対してDeployment Managerテンプレートを実行し、失敗を監視します<br>この選択肢が正しくない理由は以下の通りです。<br>同じ構成を持つ別のプロジェクトでテンプレートを実行すると、新しいプロジェクトを立ち上げ、リソースを実際にデプロイする手間がかかります。<br>また、エラーが発生した場合、元のプロジェクトと同じ条件でエラーが発生したか確認するのが難しい可能性があります。<br>それに対して、"--preview"オプションを使うと、デプロイを実行する前に、予想される影響を確認できます。'>
<div class='choice'> 同じプロジェクトで"--previewオプションを使用してDeployment Managerテンプレートを実行し、相互依存するリソースの状態を観察します</div>
<div class='choice'> Pythonで作成されたDeployment Managerテンプレート内で、きめ細かいロギングステートメントを使用します</div>
<div class='choice'> 同じ構成を持つ別のプロジェクトに対してDeployment Managerテンプレートを実行し、失敗を監視します</div>
<div class='choice'> Google Cloud ConsoleのCloud Loggingページで、Deployment Managerの実行アクティビティを監視します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題4<br>特定のCloud Storageのリージョンストレージバケットに保存された動画は、90日後にColdlineに移動され、作成から1年後に削除されるようにポリシーを設定する必要があります。<br>どのようにポリシーを設定すればよいですか？' data-answer='1' data-explanation='解説<br>正解は「SetStorageClassアクションとDeleteアクションでAge条件を使用して、Cloud Storageオブジェクトのライフサイクル管理を使用します。SetStorageClassアクションを90日に設定し、Deleteアクションを365日に設定します」です。<br>この問題では、Google Cloud Storageの特定のバケットのオブジェクトに対してライフサイクル管理を適切に設定する方法が問われています。ここでは、オブジェクトが作成されてから一定期間経過したのちに、StorageClassをColdlineに変更し、さらに一定期間経過したら削除するという特定のポリシーを適用するための適切な手段を選択する必要があります。効率的なデータ管理のために、Cloud Storageのライフサイクル管理の仕様を理解し、それが問題の要件とどのように一致または不一致であるかを確認することがカギとなります。ここで重要なのは、Age条件の日数が作成日からの経過日数であることを理解することです。<br>基本的な概念や原則：<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスです。ファイルの保存や取得が可能で、大量のデータを安全かつスケーラブルに保存できます。<br>SetStorageClassアクション：Cloud Storageのライフサイクル管理の一部で、特定の条件が満たされたときにオブジェクトのストレージクラスを変更するアクションです。例えば、オブジェクトが一定の日数経過したときにColdlineに移動するなどの処理が可能です。<br>Deleteアクション：Cloud Storageのライフサイクル管理の一部で、特定の条件が満たされたときにオブジェクトを削除するアクションです。例えば、オブジェクトが一定の日数経過したときに削除するなどの処理が可能です。<br>ライフサイクル管理：Cloud Storageの機能で、オブジェクトのライフサイクルを自動的に管理します。オブジェクトの年齢、名前、ストレージクラスなどに基づいて特定のアクションをトリガーます。<br>Coldline：Cloud Storageのストレージクラスの一つで、長期保管やディザスタ復旧に最適なコスト効率の高いストレージクラスです。<br>Age条件：Cloud Storageのライフサイクル管理の条件の一つで、オブジェクトが作成されてからの経過日数に基づいてアクションをトリガーます。<br>gsutil：Google Cloud Storageをコマンドラインから操作するためのツールです。このツールを使って、オブジェクトやバケットの作成、編集、削除などを行うことができます。<br>正解についての説明：<br>（選択肢）<br>・SetStorageClassアクションとDeleteアクションでAge条件を使用して、Cloud Storageオブジェクトのライフサイクル管理を使用します。SetStorageClassアクションを90日に設定し、Deleteアクションを365日に設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud Storageではオブジェクトのライフサイクル管理を行うことができます。これは、特定の条件に基づいてアクションを実行するルールを設定することで動作します。本問題では、動画ファイルが特定の日数経過後にストレージクラスを変更し、さらに特定の日数後に削除するというアクションが求められています。<br>Cloud Storageのライフサイクル管理では、条件に"Age"という項目とアクションに"SetStorageClass"および"Delete"という項目を指定できます。"Age"条件はオブジェクトが作成されてからの経過日数を指定します。"SetStorageClass"アクションは、条件に一致した場合にオブジェクトのストレージクラスを変更します。"Delete"アクションは、条件に一致した場合にオブジェクトを削除します。<br>したがって、この問題は90日後に動画をColdlineに移動するには"SetStorageClass"アクションを90日に設定し、365日後（つまり作成から1年後）に削除するには"Delete"アクションを365日に設定すれば解決します。このような設定を行うことで、求められているポリシーを適切に実現できます。<br>不正解の選択肢についての説明：<br>選択肢：SetStorageClassアクションとDeleteアクションでAge条件を使用して、Cloud Storageオブジェクトのライフサイクル管理を使用します。SetStorageClassアクションを90日に設定し、Deleteアクションを275日（365 - 90）に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Deleteアクションの設定値を365日から90日差し引いた275日に設定すると、オブジェクトは作成から275日後に削除されます。<br>しかし、問題の要件では作成から1年後、つまり365日後に削除することが求められています。<br>したがって、Deleteアクションは275日ではなく365日に設定するべきです。<br>選択肢：gsutil rewriteを使い、Deleteアクションを275日（365-90）に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>gsutil rewriteはバケットのデータを他のストレージクラスに変換するために使用されますが、データの移動や削除などのライフサイクル管理には使えません。そのため、Cloud Storageオブジェクトのライフサイクルを制御するためのSetStorageClassアクションとDeleteアクションを90日と365日に設定し、それにより特定の条件を満たすオブジェクトに対するアクションを定義する正解の選択肢が適切です。<br>選択肢：gsutil rewriteを使って、Deleteアクションを365日に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>gsutil rewriteはデータの再エンコードに使用されますが、ライフサイクル管理には使用できません。<br>一方、正解の選択肢ではSetStorageClassアクションとDeleteアクションを使用して、必要なライフサイクルの設定ができます。'>
<div class='choice'> SetStorageClassアクションとDeleteアクションでAge条件を使用して、Cloud Storageオブジェクトのライフサイクル管理を使用します。SetStorageClassアクションを90日に設定し、Deleteアクションを275日（365 - 90）に設定します</div>
<div class='choice'> SetStorageClassアクションとDeleteアクションでAge条件を使用して、Cloud Storageオブジェクトのライフサイクル管理を使用します。SetStorageClassアクションを90日に設定し、Deleteアクションを365日に設定します</div>
<div class='choice'> gsutil rewriteを使い、Deleteアクションを275日（365-90）に設定します</div>
<div class='choice'> gsutil rewriteを使って、Deleteアクションを365日に設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題5<br>あなたはData Studioを使用して、BigQuery上に構築されたデータウェアハウスのテーブルを視覚化しています。データは日中にデータウェアハウスに追加されます。夜間には、テーブルを上書きして日次サマリーが再計算されます。ある日、あなたはData Studioのチャートが壊れていることに気づきました。<br>この問題を解決するためにはどうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「BigQueryインターフェイスを使用して、毎晩のジョブを確認し、エラーがないか調べます」です。<br>この問題では、あなたがData StudioとBigQueryでデータの視覚化作業をしている状況と、その中で発生した問題を理解し解決策を導き出すことが求められています。視覚化のチャートが壊れている原因として、夜間に日次サマリーが再計算される際のテーブル上書きプロセスに問題がある可能性が示唆されています。そのため、選択肢を検討する際には、このプロセスのエラーを診断できる適切なツールや手段を選ぶことが重要です。<br>基本的な概念や原則：<br>BigQuery：Google Cloudの大規模データ分析ツールです。リアルタイム分析を実行して大規模なデータセットを対話的に分析することができます。<br>Data Studio：Google Cloudのデータ視覚化ツールです。BigQueryなどからデータを取り込み、インタラクティブなダッシュボードやレポートを生成します。<br>日次サマリー：定期的に集計される、特定の期間（通常は1日）のデータの概要です。<br>エラー確認：予期しない問題や不具合が発生した場合、エラーや失敗の原因を特定するための重要なステップです。エラーメッセージを確認したり、ログを調査したりします。<br>Cloud Console：Google Cloudの全てのリソースとアプリケーションを管理するためのウェブベースのインターフェースです。<br>Cloud Debugger：アプリケーションの問題を診断するためのGoogle Cloudツールです。本番環境のアプリケーションのデバッグをサポートします。<br>Cloud Logging：Google Cloudのログ管理サービスです。アプリケーション、サービス、システムから生成されるログを一元的に管理し、分析することができます。<br>正解についての説明：<br>（選択肢）<br>・BigQueryインターフェイスを使用して、毎晩のジョブを確認し、エラーがないか調べます<br>この選択肢が正解の理由は以下の通りです。<br>まず、Data Studioのチャートが壊れているとき最初に確認すべきは、そのチャートが引用しているデータ自体が正常であるかどうかです。問題が起きているデータが夜間の再計算プロセスによって作成される日次サマリーである場合、この再計算ジョブでエラーが生じている可能性があります。<br>BigQueryインターフェイスを使用してジョブの履歴を確認することで、再計算ジョブが正常に完了しているか、または何か問題があったかどうかを確認することができます。エラーがあった場合、そのエラーメッセージや情報をもとに問題解決に取り組むことが可能になります。結果として、壊れたチャートの問題を解決するためには、データソースである再計算ジョブの状態をまず確認するのが妥当な手段であると言えます。<br>不正解の選択肢についての説明：<br>選択肢：Cloud ConsoleのError Reportingページを確認して、エラーを見つけます<br>この選択肢が正しくない理由は以下の通りです。<br>Error ReportingページはGoogle Cloudプロジェクトの実行中のサービスのエラーを集約して表示するものであり、BigQueryのジョブに関連するエラーの記録は含まれていません。対して正解の選択肢では、BigQueryのインターフェースを使用してジョブエラーを確認することで、データ更新の問題点を特定できるため、妥当です。<br>選択肢：Cloud Debuggerを使用して、データが正しくリフレッシュされなかった原因を突き止めます<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Debuggerは主にアプリケーションのデバッグに使用され、BigQueryのジョブやデータリフレッシュの問題のトラブルシューティングには適していません。<br>一方、BigQueryインターフェイスを使用してエラーをチェックすることは、問題がData Studio側ではなく、BigQueryのジョブにある可能性を確認する効果的な手段です。<br>選択肢：Cloud Loggingで、Data Studioレポートのフィルタを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud LoggingでData Studioレポートのフィルタを作成すると、Data Studio自体のログ情報しか確認できません。<br>しかし、問題の原因はBigQuery上での日次サマリー再計算のエラーの可能性が高いため、BigQueryインターフェイスを使用して、毎晩のジョブを確認しエラーを調査する必要があります。'>
<div class='choice'> Cloud Loggingで、Data Studioレポートのフィルタを作成します</div>
<div class='choice'> Cloud ConsoleのError Reportingページを確認して、エラーを見つけます</div>
<div class='choice'> BigQueryインターフェイスを使用して、毎晩のジョブを確認し、エラーがないか調べます</div>
<div class='choice'> Cloud Debuggerを使用して、データが正しくリフレッシュされなかった原因を突き止めます</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題6<br>あなたの会社は、ディザスタリカバリ目的でアプリケーションのバックアップファイルを保存するためにCloud Storageを使用しています。Googleの推奨プラクティスに従う必要があります。どのストレージオプションを使用すべきですか？' data-answer='2' data-explanation='解説<br>正解は「Coldlineストレージ」です。<br>この問題では、Google Cloud Storageの各ストレージオプションの特性や用途を理解し、それらをディザスタリカバリ目的に適用する課題に直面しています。それぞれのストレージクラスは、特定の使用シナリオに最適化されており、その中からディザスタリカバリの目的に最適なものを選択することが求められます。そのためには、各オプションの特性、利用料金、データへのアクセス頻度やアクセス時の速度などを考慮する必要があります。<br>基本的な概念や原則：<br>Coldlineストレージ：データのアクセス頻度が低く、アーカイブやディザスタリカバリなどのシナリオに対応するGoogle Cloud Storageのストレージクラスです。低コストで長期保存が可能です。<br>マルチリージョンストレージ：データの可用性や堅牢性を重視するシナリオに対応するGoogle Cloud Storageのストレージクラスです。データは複数のジオグラフィカルリージョンに分散して保存されます。<br>リージョンストレージ：特定のリージョン内でのデータの高速アクセスに対応するGoogle Cloud Storageのストレージクラスです。一部の高パフォーマンスシナリオで使用されます。<br>Nearlineストレージ：データのアクセス頻度が中程度であるシナリオに対応するGoogle Cloud Storageのストレージクラスです。バックアップや障害復旧などに使用することができます。<br>ディザスタリカバリ：災害発生時に、システムとネットワークの運用を迅速に回復するための戦略や手順です。システムのバックアップとリストア、及びそのポリシーが中心です。<br>正解についての説明：<br>（選択肢）<br>・Coldlineストレージ<br>この選択肢が正解の理由は以下の通りです。<br>まず、Coldlineストレージは、頻繁にアクセスされないデータを保存するためのGoogle Cloud Storageのオプションで、コスト効率の観点から優れています。具体的には、ディザスタリカバリ目的でアプリケーションのバックアップを保存する場合、このデータは通常、日々の業務オペレーションで頻繁にアクセスされることはありません。<br>したがって、そのような低頻度のアクセスデータに対してはColdlineストレージの利用が推奨されます。<br>さらに、Coldlineストレージはデータの耐久性を保持しつつも低コストを実現します。そのため、頻繁なアクセスが不要なアプリケーションのバックアップデータを保存する場合には、Coldlineストレージを使用すべきです。<br>このように、Googleの推奨プラクティスに従いつつコスト効率の良いストレージを使用するためには、Coldlineストレージが適しています。<br>不正解の選択肢についての説明：<br>選択肢：マルチリージョンストレージ<br>この選択肢が正しくない理由は以下の通りです。<br>マルチリージョンストレージはファイルの可用性を最優先するストレージクラスで、バックアップファイルのような頻繁にアクセスしないデータにはコストが割高になる可能性があります。ディザスタリカバリの目的で利用する場合、Coldlineストレージの方が長期保存に適しており、コスト効率も良いです。<br>選択肢：リージョンストレージ<br>この選択肢が正しくない理由は以下の通りです。<br>リージョンストレージはデータの場所を指定するオプションで、バックアップファイルの保存に使用するストレージクラスのことではありません。<br>一方、Coldlineストレージは保存コストを抑えるために間欠的なアクセスを必要とするデータに対するストレージクラスの一つで、ディザスタリカバリに適しています。<br>選択肢：Nearlineストレージ<br>この選択肢が正しくない理由は以下の通りです。<br>Nearlineストレージは頻繁なアクセスが必要なデータには適していますが、ディザスタリカバリ目的のバックアップファイルは頻繁にアクセスしないため、Coldlineストレージの方がコスト効率が良いとされています。'>
<div class='choice'> Nearlineストレージ</div>
<div class='choice'> マルチリージョンストレージ</div>
<div class='choice'> Coldlineストレージ</div>
<div class='choice'> リージョンストレージ</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題7<br>あなたは、Google Cloudプロジェクトで、Cloud Spanner Identity Access Management（IAM）ロールにいつユーザーが追加されたかを確認したいと考えています。Google Cloudコンソールで何をすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「Cloud Loggingコンソールに行き、管理者のアクティビティログを確認し、Cloud Spanner IAMロールのためにフィルタリングします」です。<br>この問題では、Google Cloud環境でユーザーのアクセス管理情報を調査する適切な方法を選ぶ必要があります。特にCloud Spanner IAMロールへのユーザーの追加された時期を探す場合はどのツールやコンソールを用いるべきかを判断しなければなりません。各選択肢に登場するサービスや機能の基本的な機能を理解し、それぞれが提供する詳細情報の範囲を把握することが重要です。<br>基本的な概念や原則：<br>Cloud Logging：Google Cloudのログ管理と分析サービスです。アクティビティ、操作、エラーなどのログデータを収集してリアルタイム分析を行います。<br>Cloud Spanner IAMロール：Google Cloud上のCloud Spanner資源に対するユーザーのアクセス権限を定義するロールです。<br>管理者のアクティビティログ：Google Cloud上の管理タスクに関するログです。ユーザーやシステムの操作を追跡し、監査を可能にします。<br>IAM & admin：Google CloudのIAM（Identity and Access Management）サービスの一部です。リソースへのアクセスを管理し、18種類以上の異なるロールが用意されています。<br>Google Cloud Operations SuiteMonitoring：Google Cloudの監視とトラブルシューティングのツールセットです。アラートやカスタムダッシュボードを通してシステムのパフォーマンスを監視します。<br>正解についての説明：<br>（選択肢）<br>・Cloud Loggingコンソールに行き、管理者のアクティビティログを確認し、Cloud Spanner IAMロールのためにフィルタリングします<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloud Loggingは、Google Cloudプロジェクトでの管理者やユーザーのアクティビティを追跡し、ログに記録するという強力な監視機能を提供しています。これにより、プロジェクトに変更が加えられたときに詳細な情報を得ることができます。具体的には、Cloud SpannerのIAMロールに対する変更（ユーザが追加または削除された時点など）は、Cloud Logging上の"管理者のアクティビティログ"に記録されます。そのため、Cloud Loggingコンソールにアクセスして、Cloud Spanner IAMロールのために管理者のアクティビティログをフィルタリングすることで、特定のユーザがIAMロールに追加された時点を調査することができます。<br>したがって、これが課題を解決するための適切な方法であり、選択肢は正解です。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Spannerコンソールを開いて設定を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Spannerコンソールを開いて設定を確認するだけでは、IAMロールにユーザーが追加された時間を知ることはできません。<br>一方で、Cloud Loggingは管理者のアクティビティログを追跡し、タイムスタンプ付きの情報を提供するため、IAMロールの変更履歴を知るために適しています。<br>選択肢：IAM & adminコンソールを開き、Cloud SpannerロールのIAMポリシーを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>IAM & adminコンソールは誰が何の権限を持っているかを確認するのに使いますが、ユーザーがいつ追加されたかという情報を提供してはいません。それに対してCloud Loggingは管理者のアクティビティログを提供し、特定のIAMロールへのアクセスがいつ付与されたかを確認できます。<br>選択肢：Google Cloud Operations SuiteMonitoringコンソールに行き、Cloud Spannerの情報を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloud Operations SuiteMonitoringコンソールはシステムのパフォーマンスメトリクスを追跡するためのものであり、IAMロールの変更履歴などの管理者のアクティビティ情報を確認するためのものではありません。<br>それに対して、Cloud Loggingはユーザーアクティビティやシステムイベントを追跡するためのツールであるため、IAMロールの変更履歴を確認する適切な方法です。'>
<div class='choice'> Google Cloud Operations SuiteMonitoringコンソールに行き、Cloud Spannerの情報を確認します</div>
<div class='choice'> IAM & adminコンソールを開き、Cloud SpannerロールのIAMポリシーを確認します</div>
<div class='choice'> Cloud Spannerコンソールを開いて設定を確認します</div>
<div class='choice'> Cloud Loggingコンソールに行き、管理者のアクティビティログを確認し、Cloud Spanner IAMロールのためにフィルタリングします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題8<br>あなたの所属する金融会社は、監査ログファイルを3年間保存する必要があります。組織には何百ものGoogle Cloudプロジェクトがあります。ログファイルの保存に費用対効果の高いアプローチを導入する必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「Cloud AuditからColdlineストレージバケットにログを保存するシンクへのエクスポートを作成します」です。<br>この問題では、監査ログを費用効果的に3年間保存する方法について問われています。金融会社に所属し、何百ものGoogle Cloudプロジェクトがあることから大量のログが発生し、その管理が課題です。重点的に考えるべきは"費用対効果の高さ"です。選択肢としてあげられている各種サービスや手法を用いて、どの方法が用途に最適か評価することが求められます。<br>基本的な概念や原則：<br>Cloud Audit：Google CloudのAPI操作に対するログを集めるサービスです。誰が何を何時に行ったかを把握することができます。<br>Coldlineストレージ：Google Cloud Storageのストレージクラスの一つで、非常に低頻度でアクセスされるデータを保管するのに最適です。コスト効率が高いですが、データが必要になるまでの時間（復元時間）が長いです。<br>エクスポート：Google Cloudのログを他のGoogle Cloudサービスに送る機能です。エクスポートにより、ログデータを長期保存したり、外部システムで分析したりすることが可能になります。<br>BigQuery：大規模なデータセットに対して高速なSQLクエリを実行できるフルマネージドな大規模データウェアハウスです。しかし、大量のログデータの長期保存にはコストがかかる可能性があります。<br>Cloud Pub/Sub：リアルタイムで高度にスケーラブルなメッセージングとイベントサービスです。アプリケーション間でメッセージを送信したり、データをストリーミングしたりするためのサービスですが、長期保存用には適していません。<br>Cloud Dataflow：バッチおよびリアルタイムのデータ処理を行うフルマネージドサービスです。しかし、ログデータの長期保存には適していません。<br>正解についての説明：<br>（選択肢）<br>・Cloud AuditからColdlineストレージバケットにログを保存するシンクへのエクスポートを作成します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud AuditはGoogle Cloud内で行われた活動を追跡し記録する重要なサービスであり、ログデータの生成元として機能します。これらのログは監査目的のために保存する必要がありますが、大量に生成されるため保存コストを抑えるための賢い戦略が必要です。<br>これを考慮に入れると、Cloud StorageのColdlineストレージクラスは、長期保存が必要なデータを格納するのに適しています。Coldlineストレージは、アクセス頻度が低いデータ向けの低コストのストレージオプションであり、3年間もの長期間データを取っておく場合に最適です。<br>さらに、Cloud Storageは高い耐久性と可用性を提供し、データの損失を防ぎます。<br>そこで、Cloud AuditからColdlineストレージに対してログをエクスポートすることは、金融会社がコスト効率を向上させつつも年数を経たログデータにアクセスできるようにするための良い手段です。<br>不正解の選択肢についての説明：<br>選択肢：Cloud AuditからBigQueryにログを保存するシンクへのエクスポートを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>BigQueryにログを保存することも可能ですが、BigQueryは頻繁にアクセスまたは分析が必要なデータに対して効率的である一方、Coldlineストレージは長期保存と低コストを重視したストレージクラスであるため、3年間の保存を要求する監査ログに対しては、Coldlineストレージの方が費用対効果が高いと言えます。<br>選択肢：Logging APIを使用して、Google Cloud Operations SuiteログからBigQueryにログをコピーするカスタムスクリプトを記述します<br>この選択肢が正しくない理由は以下の通りです。<br>Logging APIを使用しBigQueryにコピーするスクリプトを記述する方法は、高い技術的な実装が必要で、複数のプロジェクトに対応するためにはスケーラビリティにも問題があります。<br>一方、Cloud AuditからColdlineストレージバケットへの自動エクスポートでは、一箇所でログをまとめて保存し、保存コストも抑えられます。<br>選択肢：これらのログをCloud Pub/Subにエクスポートし、ログをCloud SQLに格納するCloud Dataflowパイプラインを書きます<br>この選択肢が正しくない理由は以下の通りです。<br>まず、Cloud Pub/SubやCloud Dataflow、Cloud SQLを使用してログを取り扱うことは可能ですが、費用対効果の観点から見ると最適な方法ではありません。これらのサービスはコストがかかり構成も複雑であり、3年間もの長期間のログ保存には不適切です。<br>それに対して、正解のCloud AuditからColdlineストレージへのエクスポートは、保存コストが低く長期間の保存に適した方法であるため、費用対効果の観点からも適切です。'>
<div class='choice'> これらのログをCloud Pub/Subにエクスポートし、ログをCloud SQLに格納するCloud Dataflowパイプラインを書きます</div>
<div class='choice'> Cloud AuditからColdlineストレージバケットにログを保存するシンクへのエクスポートを作成します</div>
<div class='choice'> Logging APIを使用して、Google Cloud Operations SuiteログからBigQueryにログをコピーするカスタムスクリプトを記述します</div>
<div class='choice'> Cloud AuditからBigQueryにログを保存するシンクへのエクスポートを作成します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題9<br>単一のCompute Engineインスタンスにアプリケーションをデプロイしました。アプリケーションはディスクにログを書き込みます。ある日、ユーザーがアプリケーションでエラーを報告し始めたため、あなたは問題を診断したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「Ops Agentをインストールして設定し、Cloud Loggingからログを表示します」です。<br>この問題では、エラーを報告するユーザーからのフィードバックを元にアプリケーションの問題診断を進めるためのアプローチを選ぶことが求められています。そのため、まずアプリケーションのログがどのように取得可能で、それをどのように解析するかが重要なポイントになります。選択肢を見る際には、ログを抽出して効率的に問題診断に活用できる手段を探すことに注目し、単純にシステムの状態確認や接続方法のみを示す選択肢は適切でない可能性が高いことに注意してください。<br>基本的な概念や原則：<br>Ops Agent：Google Cloudのロギングとモニタリングエージェントです。Compute Engineインスタンス上のアプリケーションログやシステムメトリクスの収集、転送を行います。<br>Cloud Logging：Google Cloudのロギングサービスで、アプリケーションとシステムログを収集、分析、保存します。Ops Agentを使ってCompute Engineからログを収集できます。<br>Compute Engineインスタンス：Google Cloudの仮想マシン（VM）インスタンスを指します。このインスタンス上でアプリケーションをデプロイ・実行します。<br>ヘルスチェック：Compute Engineネットワークにより行われる、インスタンスのレスポンス確認処理です。ただし、特定のアプリケーションのエラー追跡には不適切です。<br>シリアルコンソール：仮想マシンのデバッグに使用されるツールです。しかし、アプリケーションログの表示に使うよりは、Ops AgentとCloud Loggingの組み合わせが推奨されます。<br>正解についての説明：<br>（選択肢）<br>・Ops Agentをインストールして設定し、Cloud Loggingからログを表示します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Ops AgentはGoogle Cloudのサービスで、Compute Engineインスタンスのデータの収集、解析、転送を行います。このため、Ops Agentをインストールするとアプリケーションのログ情報を効果的に収集できます。それから、収集されたログ情報はCloud Loggingを利用することで表示、監視、分析することができます。<br>したがって、ユーザーから報告されたエラーに基づいて問題を診断するために、Ops Agentをインストールし設定し、Cloud Loggingからログ情報を確認するのが最適な解決策です。これにより、エラーの原因を突き止め、迅速な解決を図ることができます。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Loggingに移動し、アプリケーションログを表示します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Loggingに移動しても、Ops Agentをインストールして設定しない限り、アプリケーションログは自動的にCloud Loggingに送られません。<br>正解の選択肢のように、Ops Agentをインストールし設定することで初めてCompute EngineインスタンスのアプリケーションログをCloud Loggingで確認できます。<br>選択肢：インスタンスのヘルスチェックを設定し、"連続成功"のヘルシー閾値を1に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンスのヘルスチェックを設定し、“連続成功”のヘルシー閾値を1に設定しても、アプリケーションのエラー診断には直接役立たず、あくまでインスタンスの稼働状態の確認が可能になります。<br>それに対して、Ops Agentをインストールして設定し、Cloud Loggingからログを表示することで、アプリケーションの問題を特定・診断するための情報を得られます。<br>選択肢：インスタンスのシリアルコンソールに接続し、アプリケーションログを読みます<br>この選択肢が正しくない理由は以下の通りです。<br>シリアルコンソールからアプリケーションログを読むことは可能ですが、これを使用すると重要な情報が失われる可能性があります。対してOps Agentをインストールし、Cloud Loggingでログを表示すると、ログ情報が一元管理され、時間をさかのぼってエラー解析が可能となり効率が良いです。'>
<div class='choice'> Ops Agentをインストールして設定し、Cloud Loggingからログを表示します</div>
<div class='choice'> Cloud Loggingに移動し、アプリケーションログを表示します</div>
<div class='choice'> インスタンスのヘルスチェックを設定し、"連続成功"のヘルシー閾値を1に設定します</div>
<div class='choice'> インスタンスのシリアルコンソールに接続し、アプリケーションログを読みます</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題10<br>あなたは、さまざまなチームが非本番環境のワークロードを実行できるGoogle Kubernetes Engine（GKE）クラスターを会社で運用しています。機械学習（ML）チームは、モデルをトレーニングするためにNvidia Tesla P100 GPUにアクセスする必要があります。設定にあたっては、労力とコストを最小限に抑えたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「新しいGPU対応ノードプールをGKEクラスターに追加します。MLチームに、cloud.google.com/gke --accelerator: nvidia-tesla-p100 nodeSelectorをポッド仕様に追加するよう依頼します」です。<br>この問題では、非本番環境のGoogle Kubernetes Engine（GKE）クラスターで運用される機械学習（ML）モデルのトレーニングを効率的に行う方法が求められています。MLチームがGPUにアクセスする必要があり、同時に労力とコストの削減も求められています。そのため、Google Cloudの各サービスを利用して、GPUの利用を最適に管理する方法を考える必要があります。効率性とコスト削減を実現するために、ノードプールの追加や再作成、特殊なアノテーションの追加、独自のKubernetesクラスターの構築などを選択肢として検討します。これらの選択肢から適切な手法を選ぶことが求められています。<br>基本的な概念や原則：<br>Google Kubernetes Engine（GKE）：Google Cloudで提供されるマネージドKubernetesサービスで、コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を自動化します。<br>ノードプール：GKEクラスター内のノード（ワーカーマシン）のグループのことです。特定の設定や目的で作成でき、異なる仮想マシンタイプやGPUを持つノードを含めることができます。<br>nodeSelector：Kubernetesの機能で、ポッドが特定のノードで実行されるように制御するためのフィールドです。これによりMLチームのポッドがGPU対応のノードプールにスケジュールされます。<br>GPU対応ノードプール：P100 GPUといった特定のGPUを持つGKEノードプールのことです。トレーニングなどの高性能コンピューティングワークロードの実行に最適です。<br>Kubernetesのアノテーション：Kubernetesオブジェクトに添付するためのキーバリューのペアです。設定やフィールドの説明に使用しますが、ノード選択やスケジューリングには使用できません。<br>正解についての説明：<br>（選択肢）<br>・新しいGPU対応ノードプールをGKEクラスターに追加します。MLチームに、cloud.google.com/gke --accelerator: nvidia-tesla-p100 nodeSelectorをポッド仕様に追加するよう依頼します<br>この選択肢が正解の理由は以下の通りです。<br>まず、GKEクラスターに新しいGPU対応ノードプールを追加することで、その他のワークロードの実行に影響を与えることなく、MLチームが必要なNvidia Tesla P100 GPUにアクセスできるようになります。既存のノードプールにGPUを追加するのではなく、新しいノードプールを作成することで、リソースの管理が容易になり、労力とコストの最小化につながります。<br>また、MLチームにnodeSelectorを追加するよう依頼することで、MLチームはGPUを必要とするポッドを適切なノードにスケジューリングできます。nodeSelectorにより、ポッドがGPUを持つノードに自動的にスケジュールされるようになるため、MLチームが各ポッドを手動で特定のノードに割り当てる必要がなくなり、労力を減らすことができます。以上が、この選択肢が正解となる理由です。<br>不正解の選択肢についての説明：<br>選択肢：MLチームに、accelerator: gpuのアノテーションをポッド仕様に追加するよう依頼します<br>この選択肢が正しくない理由は以下の通りです。<br>ただアノテーション &#39;accelerator: gpu&#39; を追加しても、特定のGPU種類への要求は明示されません。これではMLチームがNvidia Tesla P100 GPUを要求することはできず、要件を満たすことができません。<br>一方、正解の選択肢では具体的なGPU種類をnodeSelectorに指定しているため、要件をちゃんと満たしています。<br>選択肢：GKEクラスターのすべてのノードを再作成し、すべてのノードでGPUを有効にします<br>この選択肢が正しくない理由は以下の通りです。<br>全てのノードでGPUを有効にすると、必要ないワークロードまでGPUが使われ、コストが無駄になります。<br>また、ノードの再作成は労力が大きいです。<br>それに対して、正解の選択肢は、必要なチームのみがGPUを使用し、しかも新たなノードプールを追加するだけなので、コストも労力も最小限に抑えられます。<br>選択肢：GPUを搭載したノードで、Compute Engineの上に独自のKubernetesクラスターを作成します。このクラスターをMLチームに割り当てます<br>この選択肢が正しくない理由は以下の通りです。<br>独自のKubernetesクラスターを作成すると、既存のGKEクラスターのリソースを十分に活用できず、また管理コストも増えます。<br>一方、既存のGKEクラスターにGPU対応ノードプールを追加する方が、管理が簡単でコストも抑えられます。'>
<div class='choice'> MLチームに、accelerator: gpuのアノテーションをポッド仕様に追加するよう依頼します</div>
<div class='choice'> GPUを搭載したノードで、Compute Engineの上に独自のKubernetesクラスターを作成します。このクラスターをMLチームに割り当てます</div>
<div class='choice'> 新しいGPU対応ノードプールをGKEクラスターに追加します。MLチームに、cloud.google.com/gke --accelerator: nvidia-tesla-p100 nodeSelectorをポッド仕様に追加するよう依頼します</div>
<div class='choice'> GKEクラスターのすべてのノードを再作成し、すべてのノードでGPUを有効にします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題11<br>gcloud app deployを使用してApp Engineアプリケーションをデプロイしましたが、意図したプロジェクトにデプロイされませんでした。この原因とアプリケーションのデプロイ先を確認したいと考えています。<br>あなたはこのために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「Cloud Shellにアクセスしてgcloud config listを実行し、デプロイに使用するGoogle Cloudの設定を確認します」です。<br>この問題では、App Engineアプリケーションのデプロイ先が想定と違うというシナリオが提示されています。この問題を解くためには、デプロイ先がどのように決まるのかと、どの手段でこれを確認できるのかについて理解が必要です。また選択肢にはいくつかの設定ファイルやサービスが提示されていますが、その中から適切なものを選ぶ必要があります。そのため、各設定ファイルやサービスが何を制御するのかを理解しておくことも重要です。<br>基本的な概念や原則：<br>gcloud app deploy：Google Cloud SDKの一部で、App Engineアプリケーションをデプロイするコマンドです。実行すると、現在のディレクトリにあるapp.yaml設定ファイルを使用してアプリケーションをデプロイします。<br>Cloud Shell：Google Cloudのインタラクティブなシェル環境です。ブラウザから直接Google Cloudのリソースとプロジェクトを管理できます。<br>gcloud config list：gcloud CLIの一部で、現在設定されているGoogle Cloudの設定情報を表示するコマンドです。プロジェクトID、デフォルトのリージョンやゾーン、認証情報などを確認できます。<br>app.yaml：App Engineアプリケーションの設定を定義するファイルです。アプリケーションのバージョン、URLルーティング、スケーリング設定などを定義します。<br>Deployment Manager：インフラストラクチャの作成、管理、削除を自動化するGoogle Cloudのサービスです。テンプレートを使用してリソースのデプロイメントを定義でき、そのデプロイメント設定を管理できます。<br>正解についての説明：<br>（選択肢）<br>・Cloud Shellにアクセスしてgcloud config listを実行し、デプロイに使用するGoogle Cloudの設定を確認します<br>この選択肢が正解の理由は以下の通りです。<br>gcloud config listコマンドは、Google Cloud SDKの現在の設定を表示するために使用されます。このコマンドのアウトプットは、使用するプロジェクト、認証の詳細、現在のリージョンとゾーンなどの部分を含んでいます。App Engineアプリケーションが意図したプロジェクト以外にデプロイされてしまった場合、その原因は設定にある可能性が高いです。<br>したがって、gcloud config listを実行することで、デフォルトのプロジェクト設定や現在の設定などを確認することができ、予期しないデプロイが行われた理由を特定しやすくなります。そのためこの選択肢が最も適切とされています。<br>不正解の選択肢についての説明：<br>選択肢：アプリケーションのapp.yamlファイルをチェックし、プロジェクトの設定を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>app.yamlファイルはアプリケーションの設定を指定するためのものであり、デプロイ先のプロジェクトを決定するための情報は含まれていません。代わりにgcloud config listを用いれば、アクティブなプロジェクト設定等が確認できます。<br>選択肢：アプリケーションのweb-application.xmlファイルをチェックし、プロジェクトの設定を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>web-application.xmlファイルはApp Engineで使用されるものですが、Google Cloudでアプリケーションをデプロイする目的地についての情報は含まれていません。<br>それに対して、gcloud config listコマンドを使用すると、gcloudツールの現在の設定やプロジェクトを確認することができます。<br>選択肢：Deployment Managerに移動し、アプリケーションのデプロイメントの設定を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>Deployment Managerはリソースやサービスの一括デプロイを行うツールであり、gcloud app deployによるApp Engineアプリケーションのデプロイ先に関連しません。<br>一方、gcloud config listを実行すると、現在のGoogle Cloud設定が表示され、どのプロジェクトにデプロイされているか確認可能です。'>
<div class='choice'> Deployment Managerに移動し、アプリケーションのデプロイメントの設定を確認します</div>
<div class='choice'> アプリケーションのweb-application.xmlファイルをチェックし、プロジェクトの設定を確認します</div>
<div class='choice'> アプリケーションのapp.yamlファイルをチェックし、プロジェクトの設定を確認します</div>
<div class='choice'> Cloud Shellにアクセスしてgcloud config listを実行し、デプロイに使用するGoogle Cloudの設定を確認します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題12<br>あなたがアプリケーションを監視していると、特定のエラーが急増しているというユーザーからのフィードバックを受け取りました。そのエラーの原因が、サービスアカウントに十分な権限がないことであることに気づきました。あなたは問題を解決できましたが、問題が再発した場合に通知を受けたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「アラートポリシーで使用される特定のエラーについて、カスタムログベースのメトリクスを作成します」です。<br>この問題では、あなたが特定のエラーが再発した際に通知を受ける方法について問われています。ここで重要なのは、あなたが対象のエラーを特定し、そのエラーが再発したときに即座に通知を受ける方法を探しているということ実です。そのため、選択肢について考える際には、不足しているサービスアカウントの権限の問題を解決するだけでなく、同様の問題が再発するとすぐにそれを察知できるソリューションを選ぶことが重要です。<br>基本的な概念や原則：<br>アラートポリシー：Google Cloudの監視サービスで、特定の条件が満たされたときに通知を送るルールを定義します。異常状態の検出や問題の早期発見に寄与します。<br>カスタムログベースのメトリクス：Cloud Monitoringにより提供され、ログイベント数やログイベントの特定の属性を測定するカスタムメトリクスを作成します。ユーザ自身で設定し、特定の状況や問題に対する洞察を得ることができます。<br>ログビューア：Google Cloudの使いやすいログ管理インターフェースで、Cloud Loggingからのログデータの閲覧や分析を行う機能を提供しています。<br>BigQuery：Google Cloudの大規模なログデータやイベントデータを高速に分析するためのフルマネージド型のデータウェアハウスサービスです。<br>Data Studio：Google Cloudのレポート作成およびダッシュボード作成ツールです。分析結果やデータの視覚化に利用します。<br>サービスアカウント：Google Cloudリソースにアクセスするアプリケーションのための特別なタイプのアカウントです。アプリケーションはサービスアカウントを通じて認証と権限を得て、特定の操作を行います。<br>正解についての説明：<br>（選択肢）<br>・アラートポリシーで使用される特定のエラーについて、カスタムログベースのメトリクスを作成します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloudでは、Cloud Loggingを使用して特定のエラーメッセージをトラッキングし、それらのメッセージに基づいてカスタムログベースのメトリクスを作成することができます。これにより、特定のエラーの発生を数値として追跡し、視覚的に確認することが可能になります。<br>さらに、これらのカスタムメトリクスに基づいてアラートポリシーを作成することができます。そのアラートポリシーが条件を満たすと、通知が送信され、その結果、問題の再発時に通知を受け取ることができるようになります。<br>したがって、カスタムログベースのメトリクスによって問題の特定と、その再発時に通知を受け取るための閾値を設定することが可能となり、これが最適な解決策である理由です。<br>不正解の選択肢についての説明：<br>選択肢：ログビューアで、重大度"エラー"とサービスアカウント名でログをフィルタリングします<br>この選択肢が正しくない理由は以下の通りです。<br>ログビューアでログをフィルタリングすると、目的のログを見つけることはできますが、これはアクティブな監視ではなく、再発したときに自動的な通知を受ける機能は提供していません。<br>一方で、カスタムログベースのメトリクスを作成し、アラートポリシーを設定すると、特定のエラーが発生したときに自動的に通知を受けることができます。<br>選択肢：BigQueryへのシンクを作成し、すべてのログをエクスポートします。エクスポートされたログでData Studioダッシュボードを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>BigQueryへのシンクを作成し、Data Studioダッシュボードを作成する方法はエラーの可視化に役立ちますが、問題の再発通知の要件には対応できません。反対に、カスタムログベースのメトリクスにより特定のエラーを検出し、アラートポリシーを用いて問題が再発した場合に通知を受けることができます。<br>選択肢：プロジェクトオーナーにサービスアカウントへのアクセス権を付与します<br>この選択肢が正しくない理由は以下の通りです。<br>プロジェクトオーナーにサービスアカウントへのアクセス権を付与しても、特定のエラーの急増に対する通知の要件は満たされません。<br>それに対して、正解の選択肢にあるように、カスタムログベースのメトリクスを作成することで、特定のエラーの急増を検知し通知を受けることができます。'>
<div class='choice'> プロジェクトオーナーにサービスアカウントへのアクセス権を付与します</div>
<div class='choice'> ログビューアで、重大度"エラー"とサービスアカウント名でログをフィルタリングします</div>
<div class='choice'> BigQueryへのシンクを作成し、すべてのログをエクスポートします。エクスポートされたログでData Studioダッシュボードを作成します</div>
<div class='choice'> アラートポリシーで使用される特定のエラーについて、カスタムログベースのメトリクスを作成します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題13<br>Cloud Shellのgcloudコマンドラインを使用して、Google Cloudプロジェクトで有効になっているGoogle Cloud APIのリストを作成する必要があります。プロジェクト名はmy-projectです。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「gcloud projects listを実行してプロジェクトIDを取得し、gcloud services list --projectを実行します」です。<br>この問題では、特定のGoogle Cloudプロジェクトで有効になっているGoogle Cloud APIのリストを取得する方法について問われています。ここで必要なのは、"my-project"という名前のプロジェクト内で有効になっているAPIのみを特定することです。したがって、提供された選択肢を評価する際には、"my-project"を対象としたコマンドであることと、有効なAPIのみをリスト化するコマンドであることに注意する必要があります。選択肢の中には、利用可能な全てのAPIをリスト化するコマンドや、プロジェクトの設定については触れずにアカウント情報に焦点を当てるコマンドも含まれていますが、この問題の要件を満たすためにはそれらは適切ではありません。<br>基本的な概念や原則：<br>Cloud Shell：Google Cloudのブラウザベースのコマンドラインインターフェースです。開発、管理、モニタリングの各タスクを行うためのツールが含まれています。<br>gcloud：Google Cloudのプロジェクトやリソースを管理するためのコマンドラインツールです。<br>gcloud projects list：Google Cloudの現在のユーザーが所有しているプロジェクトの一覧を提供します。<br>gcloud services list：指定したプロジェクトで有効になっているすべてのAPIとサービスをリストアップします。--projectオプションを使用してプロジェクトを指定します。<br>gcloud init：gcloudのデフォルトの設定やプロジェクトの設定、認証を行います。<br>gcloud info：gcloudの現在の設定やプロジェクト情報、認証情報などを表示します。<br>gcloud projects describe：指定したプロジェクトの詳細情報を表示します。プロジェクトIDが必要です。<br>正解についての説明：<br>（選択肢）<br>・gcloud projects listを実行してプロジェクトIDを取得し、gcloud services list --projectを実行します<br>この選択肢が正解の理由は以下の通りです。<br>gcloudはGoogle Cloud SDKの一部であり、Google Cloudリソースの作成、管理、操作をコマンドラインから行うためのツールです。まず、"gcloud projects list"コマンドを使用すれば、全てのGoogle Cloudプロジェクトの一覧が表示され、特定のプロジェクト（my-project）のプロジェクトIDを確認することができます。プロジェクトIDはその後のコマンドで使用されます。<br>次に、"gcloud services list --project=my-project-id"（ここでmy-project-idは先ほど取得したプロジェクトID）というコマンドは、指定したプロジェクトで有効になっているGoogle Cloud APIのリストを表示するためのコマンドです。"--project"オプションを使用してプロジェクトを指定すれば、そのプロジェクトに関連するAPIのリストが取得できます。<br>したがって、これら2つのコマンドを組み合わせて使用することで、特定のプロジェクトにおける有効なAPIのリストを作成することが可能になります。<br>不正解の選択肢についての説明：<br>選択肢：gcloud initを実行して現在のプロジェクトをmy-projectに設定し、gcloud services list --availableを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud initによりプロジェクトをmy-projectに設定しても、gcloud services list --availableは全ての可能なサービスのリストを表示するため、特定のプロジェクトで有効になっているAPIのリストは取得できません。<br>それに対して、正解の選択肢は特定のプロジェクトで有効なサービスをリスト化します。<br>選択肢：gcloud infoを実行してアカウント値を表示し、gcloud services list --accountを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、Google Cloud APIのリストを取得するためには対象プロジェクトの指定が必要であり、アカウント値だけでは不十分です。<br>また、gcloud services listには--accountオプションは存在せず、これが指定できないため、この選択肢は誤りです。むしろプロジェクトIDを取得し、それを用いてAPIのリストを取得するのが正しい方法です。<br>選択肢：gcloud projects describeを実行してプロジェクトの値を確認し、gcloud services list --availableを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud projects describeはプロジェクトのメタデータを表示しますが、有効なAPIのリストを提供しません。<br>さらに、gcloud services list --availableは利用可能な全てのAPIを表示しますが、有効化されているAPIだけをフィルターすることはできません。正解の選択肢は特定のプロジェクトで有効化されているAPIのみを列挙します。'>
<div class='choice'> gcloud projects listを実行してプロジェクトIDを取得し、gcloud services list --projectを実行します</div>
<div class='choice'> gcloud initを実行して現在のプロジェクトをmy-projectに設定し、gcloud services list --availableを実行します</div>
<div class='choice'> gcloud infoを実行してアカウント値を表示し、gcloud services list --accountを実行します</div>
<div class='choice'> gcloud projects describeを実行してプロジェクトの値を確認し、gcloud services list --availableを実行します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題14<br>先月、あなたのプロジェクトで予想以上のコストが発生しました。調査の結果、開発用のGKEコンテナが膨大な数のログを出力していることが判明しました。あなたは、最小限のステップ数でログを迅速に無効にしたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「1.Cloud Loggingの [Logs ingestion] ウィンドウに移動し、GKEコンテナリソースのログソースを無効にします」です。<br>この問題では、Google Kubernetes Engine（GKE）コンテナが生成するログのコストが予想以上に高くなった状況で、最小限の手順で迅速にログを無効化する方法を問います。具体的には、Cloud Loggingの設定を変更することによって、ログを無効化してコストを節減する方法を選択することが求められます。重要なポイントは、できるだけ少ないステップで、再度クラスターの再構築や設定の変更などをせずにコストを削減できる方法を選択することです。<br>基本的な概念や原則：<br>Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムからのログを収集、分析、ストレージに保管することができます。<br>Logs ingestion：Cloud Loggingで提供される機能で、ログの収集範囲を設定できます。特定のリソースのログ収集を有効化または無効化することができます。<br>GKE（Google Kubernetes Engine）：Google Cloud上でKubernetesを実行するためのマネージドサービスです。アプリケーションをコンテナとしてデプロイ、スケーリング、管理できます。<br>GKEコンテナリソースのログソース：GKEで実行されるコンテナのログデータを指す用語です。無駄な出力がある場合、これを無効化することでコストを削減できます。<br>GKE Cluster Operationsリソースのログソース：GKEクラスターの操作に関するログデータを指す用語です。具体的にはクラスターの作成、更新、削除などの操作情報が含まれます。<br>新規クラスター再作成：既存のクラスターを削除し、新しくクラスターを作成する行為です。しかし、この方法はログ出力を抑制するためには非効率的であり、また無駄なコストを発生させます。<br>レガシーCloud LoggingとレガシーGoogle Cloud Operations SuiteMonitoring：Google Cloud旧バージョンのログ管理とモニタリングツールを指します。これらを無効化すると、必要な監視や分析機能が利用できなくなる可能性があります。<br>正解についての説明：<br>（選択肢）<br>・1.Cloud Loggingの [Logs ingestion] ウィンドウに移動し、GKEコンテナリソースのログソースを無効にします<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloud Loggingには、特定のリソースタイプのログの取り込みを無効にする機能があります。"Logs ingestion"ウィンドウでは、特定のログソース（この場合、GKEコンテナ）のログ取り込みを制御できます。ログソースを無効にすると、そのリソースタイプのログは収集や保存が停止します。これにより、開発用のGKEコンテナが生成する大量のログで発生するコストを迅速かつ効率的に削減することができます。しかも、これは非常にシンプルな操作で実現可能で、最小限のステップ数で対応できるため、問題文の要件を満たす最適な解決策と言えます。<br>不正解の選択肢についての説明：<br>選択肢：1.Cloud LoggingのLogs ingestionウィンドウに移動し、GKE Cluster Operationsリソースのログソースを無効にします<br>この選択肢が正しくない理由は以下の通りです。<br>問題文においてログが大量に出力されているのは、"GKEコンテナ"であり"GKE Cluster Operations"ではありません。<br>したがって、これを無効化しても本来問題に対する効果的な解決策になりません。正解の選択肢である"GKEコンテナリソースのログソース"を無効にすることで、適切に不要なログ出力を抑制することができます。<br>選択肢：1.GKEコンソールに移動し、既存のクラスターを削除します<br>2.新しいクラスターを再作成します<br>3.レガシーCloud Loggingを有効にするオプションをオフにします<br>この選択肢が正しくない理由は以下の通りです。<br>まず、クラスターを削除し再作成する手順は必要以上に手間と時間がかかります。<br>さらに、既存の作業を中断させ、コンテナの状態やデータを失う可能性があります。正解の選択肢はCloud Loggingの設定を変更するだけなので、迅速かつ簡単にログ出力を無効にすることができます。<br>選択肢：1.GKEコンソールに移動し、既存のクラスターを削除します<br>2.新しいクラスターを再作成します<br>3.レガシーGoogle Cloud Operations SuiteMonitoringを有効にするオプションをオフにします<br>この選択肢が正しくない理由は以下の通りです。<br>既存のクラスターを削除し、新しいクラスターを再作成することは非常に時間がかかり、効率的ではありません。<br>また、この方法だと開発が一時停止することになります。<br>対照的に、ログソースを直接無効にする方法はステップ数が少なく、迅速に行えます。'>
<div class='choice'><br>1.GKEコンソールに移動し、既存のクラスターを削除します<br>2.新しいクラスターを再作成します<br>3.レガシーCloud Loggingを有効にするオプションをオフにします</div>
<div class='choice'><br>1.Cloud LoggingのLogs ingestionウィンドウに移動し、GKE Cluster Operationsリソースのログソースを無効にします</div>
<div class='choice'><br>1.GKEコンソールに移動し、既存のクラスターを削除します<br>2.新しいクラスターを再作成します<br>3.レガシーGoogle Cloud Operations SuiteMonitoringを有効にするオプションをオフにします</div>
<div class='choice'><br>1.Cloud Loggingの [Logs ingestion] ウィンドウに移動し、GKEコンテナリソースのログソースを無効にします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題15<br>あなたは、新バージョンの機能をテストするために、Compute Engine上にSQL Server 2017のインスタンスを作成しました。最も少ないステップ数でこのインスタンスに接続したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「Google CloudコンソールでWindowsのユーザ名とパスワードを設定します。ポート3389用のファイアウォールのルールが存在することを確認します。Google CloudコンソールでRDPボタンをクリックし、認証情報を入力してログインします」です。<br>この問題では、Compute Engine上で動作するSQL Server 2017に対する最も少ないステップ数での接続方法について問われています。Windows上のSQL Serverへ接続するため、RDP（リモートデスクトッププロトコル）を用いた接続の手順となり、一般的にポート番号3389が使用されます。しかし、不適切な手順を選択できる選択肢として混入されているので、Google Cloud Consoleを通じてどのような手順を踏めば接続できるのかを理解することが鍵です。そして、RDP接続に必要なパスワード設定とファイアウォール設定を適切に行った上での接続プロセスを選びます。<br>基本的な概念や原則：<br>Compute Engine：Google CloudのIaaS型サービスです。仮想マシンやディスクボリュームを作成・管理できます。<br>SQL Server 2017：Microsoftが提供するリレーショナルデータベース管理システムです。Compute Engine上で実行することができます。<br>Windowsユーザ名とパスワード：Windowsの認証情報です。Compute EngineにWindowsパスワードを設定し、Windowsユーザー名とともに使用します。<br>ファイアウォールのルール：ネットワークに対する許可や拒否のルールを管理します。Compute Engineの接続先ポートを適切に設定するために重要です。<br>RDP（Remote Desktop Protocol）：Windowsのリモートデスクトップ機能を利用するためのプロトコルです。ポート3389を使用します。<br>Google Cloudコンソール：Google Cloudの管理インターフェースです。Compute Engineのインスタンスの作成や管理が可能です。<br>RDPクライアント：リモートデスクトップ接続を実現するソフトウェアです。RDP接続を利用してCompute EngineのWindowsインスタンスに接続します。<br>正解についての説明：<br>（選択肢）<br>・Google CloudコンソールでWindowsのユーザ名とパスワードを設定します。ポート3389用のファイアウォールのルールが存在することを確認します。Google CloudコンソールでRDPボタンをクリックし、認証情報を入力してログインします<br>この選択肢が正解の理由は以下の通りです。<br>まず、SQL Server 2017はWindowsベースのデータベースシステムであり、通常、Windowsシステムへのアクセスにはリモートデスクトッププロトコル（RDP）が使用されます。よって、Google CloudコンソールでRDPボタンをクリックして、クラウドのWindowsインスタンスへ攻撃を受けることが一番簡単な接続方法です。<br>次に、Compute Engine上にWindowsインスタンスを作成した場合、ユーザーはそれぞれ独自のユーザー名とパスワードを設定します。これにより、ユーザーは自身のアカウントでシステムに安全に接続することが可能になります。ユーザー名とパスワードの設定は、Google Cloud Consoleから簡単に行うことができます。<br>最後に、ポート3389はWindowsのRDP接続用のデフォルトのポートであり、ここにファイアウォールのルールが存在することは、RDP接続を可能にします。ファイアウォールのルールは、特定のポートに対するインバウンド接続を許可し、その結果、リモートユーザーがインスタンスにアクセスできるようにします。<br>これらの3つのステップは最小限の操作でCompute Engine上のSQL Server 2017に迅速な接続を提供することを可能にします。<br>不正解の選択肢についての説明：<br>選択肢：デスクトップにRDPクライアントをインストールします。ポート3389用のファイアウォールのルールが存在することを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>不正解選択肢のアプローチでは、Google CloudコンソールでWindowsのユーザ名とパスワードを設定していないため、接続の認証が行えません。<br>これに対し、正解はユーザ名とパスワードを設定して認証情報を提供するため、効率的にサーバーに接続できます。<br>選択肢：デスクトップにRDPクライアントをインストールします。Google CloudコンソールでWindowsのユーザー名とパスワードを設定します。この認証情報を使用してインスタンスにログインします<br>この選択肢が正しくない理由は以下の通りです。<br>RDPクライアントのインストールは余分なステップを必要とします。正しい選択肢では、Google Cloudコンソール内から直接RDP接続を行うことで、最小限のステップで目的を達成することが可能となっています。<br>選択肢：Google CloudコンソールでWindowsパスワードを設定します。ポート22用のファイアウォールのルールが存在することを確認します。Google CloudコンソールでRDPボタンをクリックし、認証情報を入力してログインします<br>この選択肢が正しくない理由は以下の通りです。<br>ポート22はSSHで使用されるポートであり、WindowsとRDP（リモートデスクトッププロトコル）接続にはポート3389が使用されます。<br>したがって、ポート22用のファイアウォールのルールを確認することは、WindowsのRDP接続には必要ありません。'>
<div class='choice'> Google CloudコンソールでWindowsのユーザ名とパスワードを設定します。ポート3389用のファイアウォールのルールが存在することを確認します。Google CloudコンソールでRDPボタンをクリックし、認証情報を入力してログインします</div>
<div class='choice'> デスクトップにRDPクライアントをインストールします。Google CloudコンソールでWindowsのユーザー名とパスワードを設定します。この認証情報を使用してインスタンスにログインします</div>
<div class='choice'> デスクトップにRDPクライアントをインストールします。ポート3389用のファイアウォールのルールが存在することを確認します</div>
<div class='choice'> Google CloudコンソールでWindowsパスワードを設定します。ポート22用のファイアウォールのルールが存在することを確認します。Google CloudコンソールでRDPボタンをクリックし、認証情報を入力してログインします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題16<br>機密データを3つのCloud Storageバケットに保存し、データアクセスロギングを有効にしています。可能な限り少ない手順で、これらのバケットに対する特定のユーザーのアクティビティを検証したいと考えています。メタデータラベルの追加と、これらのバケットからどのファイルが閲覧されたかを検証する必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「Google Cloudコンソールを使用して、アクティビティログをフィルタリングし、情報を表示します」です。<br>この問題では、Cloud Storageバケットに対するユーザーのアクティビティログを検証する最も効率的な方法を選ぶことが求められています。バケットへのアクセス情報の取得と、メタデータラベルの追加の二つの要装を満たす手順を選択する必要があります。必要な操作を最小限に抑えるために、最もシンプルで直接的な手法を選択することが重要です。<br>基本的な概念や原則：<br>Google Cloudコンソール：Google Cloudの全サービスを管理するためのWebベースの控えめなインターフェイスです。リソースの監視、管理、デバッグが可能です。<br>データアクセスロギング：Google Cloudのサービスがユーザーやサービスアカウントによってアクセスされたときに生成されるログのことです。これにより誰が何を行ったかを確認することができます。<br>Cloud Storageバケット：Cloud Storageにデータを保存するためのコンテナのことです。バケットには一意の名前が付けられ、設定により特定のユーザーやサービスアカウントのアクセスを制御します。<br>Google Cloud Operations Suite：Google CloudとAWSのアプリケーションの監視、トラブルシューティング、アラートの設定を可能にする一連のツールのことです。しかし、特定のバケットアクティビティの追跡には最適ではありません。<br>メタデータラベル：Google Cloudのリソースを整理し、管理するためのツールです。ラベルはキーと値のペアで構成され、リソースに追加情報を提供します。<br>正解についての説明：<br>（選択肢）<br>・Google Cloudコンソールを使用して、アクティビティログをフィルタリングし、情報を表示します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloudコンソールは非常に使いやすいユーザーインターフェースを持っています。そのため、特定のユーザーのアクティビティを検証することが容易になります。Cloudコンソールでは、"アクティビティ"タブを開くと、特定の期間、ユーザーやリソースタイプに基づくアクティビティのフィルタリングが可能です。<br>また、データアクセスロギングを有効にしているという前提の下であれば、これらのバケットからどのファイルが閲覧されたかを含む詳細な情報はすでにログに記録されています。そのため、Cloudコンソールを通じてこのログを表示することで、手間なく要件の確認が可能になります。<br>したがって、Google Cloudコンソールを使用してアクティビティログをフィルタリングし、情報を表示することは有効な対応策と言えます。<br>不正解の選択肢についての説明：<br>選択肢：Google Cloudコンソールを使用して、Google Cloud Operations Suiteログをフィルタリングし、情報を表示します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloud Operations Suiteは監視、ログ、トレースなどの情報を一括管理するためのツールであり、指定のCloud Storageバケットから閲覧されたファイルを直接検証することはできません。そのため、Google Cloudコンソールを使用して直接アクティビティログをフィルタリングし情報を表示する方が要件を満たすのに適しています。<br>選択肢：Google Cloud ConsoleのStorageセクションでバケットを表示します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloud ConsoleのStorageセクションでは、単にバケットのリストや各バケットの基本情報を表示するだけで、特定ユーザーのアクティビティや閲覧したファイルの詳細情報を検証することはできません。<br>一方、アクティビティログをフィルタリングすることで具体的なユーザーのアクティビティやアクセスしたファイル情報を詳細に確認できます。<br>選択肢：Google Cloud Operations Suiteでトレースを作成し、情報を表示します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloud Operations Suiteのトレースは、アプリケーションのパフォーマンスレポートを作成するためのものであり、特定のユーザーのアクティビティやデータへのアクセスログを検証するための機能はありません。<br>これに対し、Google Cloudコンソールからは、具体的なアクセスログをフィルタリングし、特定のユーザーのアクティビティを直接検証することができます。'>
<div class='choice'> Google Cloudコンソールを使用して、アクティビティログをフィルタリングし、情報を表示します</div>
<div class='choice'> Google Cloudコンソールを使用して、Google Cloud Operations Suiteログをフィルタリングし、情報を表示します</div>
<div class='choice'> Google Cloud ConsoleのStorageセクションでバケットを表示します</div>
<div class='choice'> Google Cloud Operations Suiteでトレースを作成し、情報を表示します</div>
</div>
            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>