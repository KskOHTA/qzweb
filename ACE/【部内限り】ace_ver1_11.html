<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Cloud Leader問題集 11</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">
<div class='question' data-multiple='FALSE' data-question='問題48<br>汎用のCompute Engineインスタンス上にアプリケーションがあり、そのゾーンSSD Persistent Disk上で過剰なディスク読み取りスロットルが発生しています。このアプリケーションは、主にディスクから大きなファイルを読み取ります。ディスクサイズは現在350GBです。コストを最小限に抑えながら、最大限のスループットを提供したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「インスタンスでローカルSSDを使用するように移行します」です。<br>この問題では、Compute Engineインスタンスでディスク読み取りスロットルが発生している状況を改善する方法を求められています。また、問題の文脈から読み取れるように、主に大きなファイルのディスクからの読み取りに負荷がかかっているため、ディスクIOのパフォーマンス改善に焦点を当てるべきです。最後に、コストを最小限に抑えながら、最大限のスループットを提供する方法を考察する必要があります。これらの要素を必ず考慮に入れて選択肢を評価してください。<br>基本的な概念や原則：<br>ローカルSSD：インスタンスに直接接続された高パフォーマンスなディスクです。読み取り書き込み速度が非常に高いですが、インスタンスが停止した場合にデータは保持されません。<br>Persistent Disk：Google Cloudのブロックストレージで、インスタンスが停止した場合でもデータを保持することができます。しかし、ローカルSSDに比べて読み書き速度は低いです。<br>ディスクサイズ：Google CloudのPersistent Diskでは、ディスクサイズが大きいほどIOPSとスループットが向上します。しかし、不必要にディスクサイズを大きくするとコストが高くなるため、バランスを取る必要があります。<br>リージョナルSSD：二つのゾーン間でデータを自動的にレプリケートするためのPersistent Diskの一種です。リージョナル冗長性が必要な場合に使用しますが、単一ゾーンのディスクと比較してコストが高くなります。<br>正解についての説明：<br>（選択肢）<br>・インスタンスでローカルSSDを使用するように移行します<br>この選択肢が正解の理由は以下の通りです。<br>まず、問題の前提として、大きなファイルを頻繁にディスクから読み取るようなアプリケーションで、ディスク読み取りスロットル（読み取り速度の制限）が発生している場合は、ハードウェアのI/O（入出力）性能が問題となる可能性があります。Google CloudのローカルSSDは、高いI/O性能と低い遅延を持つ一時的なブロックストレージであり、大量のデータ読み取りに対して高いスループット（データ転送速度）を提供します。言い換えると、大きなファイルを頻繁に読み取るような読み込み集約型のワークロードに適しているということです。<br>また、コストを最小限に抑える要件にも対応しています。ローカルSSDはCompute Engineインスタンスに直接接続され、インスタンスのライフサイクルに従います。<br>したがって、不必要なストレージコストを発生させることなく、インスタンスと一緒に作成および削除することができます。<br>したがって、このケースではローカルSSDへの移行が有効な解決策です。<br>不正解の選択肢についての説明：<br>選択肢：ディスクのサイズを1TBに増やします<br>この選択肢が正しくない理由は以下の通りです。<br>単純にディスクサイズを増やすだけでは、読み込みスループットが一定になるため、大きなファイルの読み取りが過剰なディスク読み取りスロットルを引き起こす可能性があります。<br>一方、ローカルSSDを使うと、高いIOPSとスループットを実現でき、大量のデータ処理に適しているため、選択肢が正解です。<br>選択肢：インスタンスに割り当てられたCPUを増やします<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンスに割り当てられたCPUを増やすことは、ディスク読み取りスロットルの問題を直接解決しません。読み取り速度を向上させるには、ディスクのI/O性能を向上させる必要があります。ローカルSSDを使用すると、高速な読み取り性能を得られ、読み取りスロットルを軽減できます。<br>選択肢：インスタンスでリージョナルSSDを使用するように移行します<br>この選択肢が正しくない理由は以下の通りです。<br>リージョナルSSDはデータ耐久性と可用性に優れていますが、それには高いコストが伴います。大きなファイルを読み取る使途で最大のスループットを得るには、ローカルSSDが最もコスト効率が良く、パフォーマンスに優れています。'>
<div class='choice'> インスタンスでローカルSSDを使用するように移行します</div>
<div class='choice'> ディスクのサイズを1TBに増やします</div>
<div class='choice'> インスタンスに割り当てられたCPUを増やします</div>
<div class='choice'> インスタンスでリージョナルSSDを使用するように移行します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題49<br>あなたは数百人のユーザー向けにCloud Run上でウェブアプリケーションを実行しています。一部のユーザーから、アプリケーションの最初のウェブページの読み込みに、次のページよりもはるかに時間がかかるという苦情が寄せられています。この問題を軽減するためにGoogleの推奨に従う必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「Cloud Runサービスの最小インスタンス数を3に設定します」です。<br>この問題では、Cloud Run上のウェブアプリケーションで初回ページの読み込み遅延の問題が発生しており、この問題を軽減するための対策を求められています。各選択肢に対する理解とそれぞれがどのようにウェブアプリケーションの問題に影響を与えるかを検討することが重要です。また、"Googleの推奨に従う"という言及を重視しつつ、Cloud Runの仕様や設定に対する理解を念頭に置くことが大切です。<br>基本的な概念や原則：<br>Cloud Run：Google Cloud内のフルマネージド環境でコンテナベースのアプリケーションを実行するためのサービスです。サーバレス運用や自動スケーリングが可能です。<br>最小インスタンス数：Cloud Runサービスの設定で、必ず立ち上がっているべきインスタンス数を指定します。初期の読み込み遅延（コールドスタート）を軽減するために利用されます。<br>同時実行数：Cloud Runサービスの1つのインスタンスが同時に処理できるリクエストの数を指定します。この数値を1に設定すると、各リクエストのレイテンシが増える可能性があります。<br>最大インスタンス数：Cloud Runサービスが自動的にスケールできるインスタンスの上限数を指定します。この上限値を増やすだけでは、初回の読み込み遅延には対処できません。<br>HTTP/2：HTTP/1.1の後継となるプロトコルで、1つのTCP接続上で複数のリクエストとレスポンスを同時にやりとりができます。ただし、初回の読み込み遅延には直接対処しないため、このシナリオの解決策とはなりません。<br>正解についての説明：<br>（選択肢）<br>・Cloud Runサービスの最小インスタンス数を3に設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Cloud Runはフルマネージド型のコンテナ実行環境で、トラフィックがないときには自動的にスケールダウンし、必要なときにはスケールアップします。<br>しかし、スケールアップが必要な時にはコンテナの初期化に時間がかかることがあり、これがユーザーの感じる最初のページの読み込み遅延（コールドスタート）を生んでいます。<br>そのため、この遅延を減らすために最小インスタンス数を設定することで、常に一定数のコンテナインスタンスを動作させておくことができます。これにより、突然のトラフィック増加にも迅速に対応でき、ユーザー体験の改善が期待できます。<br>したがって、Cloud Runサービスの最小インスタンス数を3に設定することは、この問題を軽減するために適切な解答です。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Runサービスの同時実行数を1に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Runサービスの同時実行数を1に設定すると、1つのインスタンスに1つのリクエストのみ処理させる設定となり、書き込みのレイテンシが高くなります。<br>一方、最小インスタンス数を3に設定すると、常に起動して待機中のインスタンスが確保され、初回のウェブページの読み込み時間が短縮されます。<br>選択肢：Cloud Runサービスの最大インスタンス数を100に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Runサービスの最大インスタンス数を100に設定すると、必要に応じて多くのインスタンスを生成しますが、最初のページの読み込みが遅い問題に対する対策とはなりません。<br>一方、最小インスタンス数を3に設定すると、常に3つのインスタンスが待機しており、要求に即座に応答できるため読み込み時間を短縮できます。<br>選択肢：HTTP/1.1の代わりにHTTP/2を使用するように、ウェブアプリケーションを更新します<br>この選択肢が正しくない理由は以下の通りです。<br>HTTP/2を使用すると通信効率は改善するかもしれませんが、Cloud Runの初回読み込み遅延問題を根本的に解決するものではありません。<br>逆に、最小インスタンス数を3に設定することで、常に利用可能なインスタンスが存在し、初回読み込みの遅延を軽減することができます。'>
<div class='choice'> Cloud Runサービスの同時実行数を1に設定します</div>
<div class='choice'> Cloud Runサービスの最小インスタンス数を3に設定します</div>
<div class='choice'> HTTP/1.1の代わりにHTTP/2を使用するように、ウェブアプリケーションを更新します</div>
<div class='choice'> Cloud Runサービスの最大インスタンス数を100に設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題50<br>あなたが管理しているインスタンスグループが、新しいインスタンスの作成に失敗したというアラートを発しました。インスタンス作成の問題を解決する必要があります。<br>この要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「インスタンスグループが使用しているインスタンステンプレートに有効な構文が含まれていることを確認します。インスタンス名と同じ名前の永続ディスクを削除します。インスタンステンプレートでdisks.autoDeleteプロパティをtrueに設定します」です。<br>この問題では、あなたがインスタンスグループの管理者で、新しいインスタンスの作成が失敗し、その問題を解消する必要があります。重要な要素として、インスタンステンプレートの構文、永続ディスクの存在および名前、disks.autoDelete属性の値が挙げられます。この情報を基にオプションを解釈し、各選択肢が問題の解決にどの程度寄与するかを評価していく必要があります。従って、選択肢を正確に理解し、その効果が具体的にどのように問題の解決につながるかを検証することが必要です。<br>基本的な概念や原則：<br>インスタンスグループ：同じ設定で運用したいインスタンスをまとめて管理する機能です。ヘルスチェックやオートスケーリングなどの設定も一括で行うことができます。<br>インスタンステンプレート：Compute Engine上のインスタンスグループを作成するための設定の雛形です。起動時ディスク、ネットワーク設定、アクセス権限などを定義できます。<br>構文の有効性：インスタンステンプレートに記述された設定が正しい構文となっていることが重要です。誤った構文の場合、インスタンスの作成が失敗する可能性があります。<br>永続ディスク：Google Cloudで提供されるスケーラブルなブロックストレージです。永続ディスクの名前が既に存在する場合は、新規作成できないため注意が必要です。<br>disks.autoDeleteプロパティ：インスタンスが削除される際にそのインスタンスのディスクも一緒に削除するかを指定するプロパティです。trueに設定すると、インスタンスの削除と共にディスクも削除されます。これによりインスタンスの作成が失敗するケースを防ぐことができます。<br>正解についての説明：<br>（選択肢）<br>・インスタンスグループが使用しているインスタンステンプレートに有効な構文が含まれていることを確認します。インスタンス名と同じ名前の永続ディスクを削除します。インスタンステンプレートでdisks.autoDeleteプロパティをtrueに設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず始めに、インスタンス作成エラーが起きる主要な原因としては、インスタンステンプレートに不正な構文が記述されている可能性があるため、インスタンステンプレートの内容を確認し、問題がないことを最初に検証することが重要です。<br>さらに、既存のインスタンスと同名の永続ディスクが存在する場合、新しいインスタンスの作成も失敗します。そのため、新しいインスタンスを作成する前に確認し、必要ならば削除することが求められます。<br>最後に、disks.autoDeleteをtrueに設定することで、インスタンス削除時にディスクの自動削除も同時に行うことができます。これにより、名前の競合によるインスタンス作成の失敗を防ぐことができます。<br>以上のアクションをとることで、インスタンスグループによる新しいインスタンスの作成失敗問題を対処できるため、この選択肢が選ばれました。<br>不正解の選択肢についての説明：<br>選択肢：インスタンスグループで使用される有効な構文を含むインスタンステンプレートを作成します。インスタンス名と同じ名前の永続ディスクを削除します<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンステンプレートを作成するだけでは、インスタンスグループが新しいインスタンスを作成できない問題を修正できません。<br>正解の選択肢は、既存のインスタンステンプレートに有効な構文が含まれていることを確認し、disks.autoDeleteプロパティもtrueに設定しています。これにより、インスタンスが削除される時に同時にディスクも削除され、新しいインスタンスの作成を可能にします。<br>選択肢：インスタンスグループで使用される有効な構文を含むインスタンステンプレートを作成します。インスタンス名と永続ディスク名の値がテンプレート内で同じでないことを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>無効なインスタンス名によって作成が失敗した場合、新しいテンプレートを作成するだけでは解決せず、対象のディスクも削除する必要があります。<br>また、ディスク削除についての設定が欠けています。これらが正解選択に含まれているためです。<br>選択肢：現在のインスタンステンプレートを削除し、新しいインスタンステンプレートに置き換えます。インスタンス名と永続ディスク名の値がテンプレート内で同じでないことを確認します。インスタンステンプレートのdisk.autoDeleteプロパティをtrueに設定します<br>この選択肢が正しくない理由は以下の通りです。<br>現在のインスタンステンプレートを削除して新しいものに置き換えると、問題の原因を特定できません。問題が解決されていない可能性があります。<br>また、正解の選択肢では、新しいインスタンスの作成に問題がないことを確認するために既存のテンプレートを確認しています。'>
<div class='choice'> インスタンスグループで使用される有効な構文を含むインスタンステンプレートを作成します。インスタンス名と同じ名前の永続ディスクを削除します</div>
<div class='choice'> インスタンスグループが使用しているインスタンステンプレートに有効な構文が含まれていることを確認します。インスタンス名と同じ名前の永続ディスクを削除します。インスタンステンプレートでdisks.autoDeleteプロパティをtrueに設定します</div>
<div class='choice'> インスタンスグループで使用される有効な構文を含むインスタンステンプレートを作成します。インスタンス名と永続ディスク名の値がテンプレート内で同じでないことを確認します</div>
<div class='choice'> 現在のインスタンステンプレートを削除し、新しいインスタンステンプレートに置き換えます。インスタンス名と永続ディスク名の値がテンプレート内で同じでないことを確認します。インスタンステンプレートのdisk.autoDeleteプロパティをtrueに設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題51<br>あなたは、Google Cloud上にデプロイされた&#39;dev&#39;という名前のGoogle Kubernetes Engine（GKE）クラスターの保守を任されています。あなたは、コマンドラインインターフェイス（CLI）を使用してGKEの設定を管理したいと考えています。また、Cloud SDKをダウンロードしてインストールしたばかりです。将来のCLIコマンドがデフォルトでこの特定のクラスターに対応するようにしたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「gcloud config set container/cluster devコマンドを使用します」です。<br>この問題では、Google Cloud上の特定のKubernetes Engine（GKE）クラスターに対して、コマンドラインインターフェイス（CLI）を使いたいというシナリオに対する適切な行動方法を選択することが求められています。"dev"という名のGKEクラスターに対してCLIコマンドを実行するのが要求されているので、選択肢を比較する際にはその要件に基づくものを選ばなければなりません。Google Cloud SDKのうちのどの機能を使用することが最も効率的か、または問題の要件を最善に満たすのかを理解することが重要です。<br>基本的な概念や原則：<br>gcloud config set：Google Cloud CLIの設定を変更するためのコマンドです。特定のプロジェクトやクラスターをデフォルトで使用するよう設定することができます。<br>Google Cloud SDK：Google Cloudのプロダクトやサービスをコマンドラインから操作するためのツール群です。主にgcloud、gsutil、bqの命令を提供しています。<br>Google Kubernetes Engine（GKE）：Google Cloud上で提供されている、Kubernetesのマネージドサービスです。Kubernetesクラスターのセットアップ、アップグレード、スケールングを自動化します。<br>コマンドラインインターフェイス（CLI）：ユーザーがテキストコマンドを入力してコンピューターと対話するためのインターフェイスです。クラウドのリソース管理によく用いられます。<br>Google Cloudコマンド：Cloud SDKに含まれる、Google Cloudのリソースを操作するためのコマンドです。たとえば、&#39;gcloud config set&#39;や&#39;gcloud container clusters update&#39;などがあります。<br>正解についての説明：<br>（選択肢）<br>・gcloud config set container/cluster devコマンドを使用します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloudではgcloudコマンドラインインターフェイス（CLI）を使用してGoogle Kubernetes Engine（GKE）クラスターの管理を行うことができます。&#39;gcloud config set container/cluster dev&#39;というコマンドを使用すると、CLIコマンドを入力する際にデフォルトで&#39;dev&#39;クラスターに対しての操作を行うように設定することができます。この場合、個々のコマンドごとに特定のクラスターを指定する必要がなくなるため、作業の効率化が期待できます。<br>また、この選択肢はCloud SDKのインストール直後に進められる手順であり、gcloud CLIの基本的な設定方法について示しています。<br>したがって、CLIを用いてGKEの設定を管理する目的に適しています。<br>ただし、別のGKEクラスターを操作する際には、そのクラスター名を指定した同様のコマンドを使用して、デフォルトのクラスターを変更することも覚えておいてください。<br>不正解の選択肢についての説明：<br>選択肢：gcloud container clusters update devコマンドを使用します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud container clusters update devコマンドは、既存のクラスターの設定を更新するためのものであり、CLIコマンドがデフォルトで特定のクラスターに対応するように設定するためのコマンドではありません。そのため要件と一致しません。<br>一方、gcloud config set container/cluster devコマンドはデフォルトのクラスターを&#39;sev&#39;に設定するため、要件を満たします。<br>選択肢：~/.gcloudフォルダにクラスター名を含むgke.defaultというファイルを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud cliは~/.gcloudフォルダにgke.defaultというファイルを作成してデフォルトクラスターを設定するそういった機能を持っていません。正しくは、&#39;gcloud config set container/cluster dev&#39;コマンドを使用することでデフォルトのクラスター設定が可能です。<br>選択肢：クラスター名を含むgke.defaultというファイルを~/.gcloudフォルダに作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Google Cloudでは、CLIのデフォルト設定は"gcloud config set"コマンドを通じて変更されます。<br>一方、"~/.gcloud"フォルダに特定のファイルを作成するという方法はGoogle CloudのCLI操作には存在しません。正解の選択肢の"gcloud config set container/cluster dev"はCLIでのデフォルトクラスターを定義する正しい方法です。'>
<div class='choice'> gcloud config set container/cluster devコマンドを使用します</div>
<div class='choice'> クラスター名を含むgke.defaultというファイルを~/.gcloudフォルダに作成します</div>
<div class='choice'> ~/.gcloudフォルダにクラスター名を含むgke.defaultというファイルを作成します</div>
<div class='choice'> gcloud container clusters update devコマンドを使用します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題52<br>複数のゾーンで動作するCompute Engineインスタンスのグループに対して、可能な限り少ない手順で、ネットワークのロードバランシングのためのオートヒーリングを設定したいと考えています。<br>10秒ずつ3回試行した後、VMが応答しない場合、VMの再作成を構成する必要があります。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「マネージドインスタンスグループを作成します。オートヒーリングのヘルスチェックをヘルシー（HTTP）に設定にします」です。<br>この問題では、Compute Engineインスタンスのグループにオートヒーリングを設定する手順を最小限に抑えたいという要望を理解することが求められています。また、具体的には、10秒間隔で3回の試行後にVMが応答しない場合にVMを再作成する設定を適用する必要があります。ここで重要な点は、オートヒーリングの設定とロードバランシングの設定は別々のものであり、それぞれを正しく理解し、正しい選択肢へと導くことです。選択肢を推敲する際には、問題が求めている要素を満たす選択肢を選ぶために、各選択肢が提供する機能と設定方法をよく理解することが求められます。<br>基本的な概念や原則：<br>マネージドインスタンスグループ：Google CloudのCompute Engineのインスタンスを管理するサービスです。高可用性とロードバランシングを容易に実現します。<br>オートヒーリング：システムの自動復旧機能です。障害が発生したインスタンスを自動的に修復または再起動します。<br>ヘルスチェック：Compute Engineインスタンスのヘルスステータスを定期的に検証する進行中の確認シリーズです。異常が検出されると、不健全なインスタンスを再作成するオートヒーリング機能が引き金になります。<br>ロードバランシング：ネットワークトラフィックを複数のサーバーに均等に分散することです。これにより、単一のサーバーに過度の負荷がかかるのを防ぎ、高可用性と応答性を提供します。<br>オートスケーリング: 需要に応じて、マシンリソースの数を自動的に増減する機能です。これによりパフォーマンスを維持しながらコストを最小限に抑えることができます。<br>正解についての説明：<br>（選択肢）<br>・マネージドインスタンスグループを作成します。オートヒーリングのヘルスチェックをヘルシー（HTTP）に設定にします<br>この選択肢が正解の理由は以下の通りです。<br>まず、マネージドインスタンスグループ（MIGs）には、オートスケーリング、ロードバランシング、オートヒーリングの機能があり、これを用いることで、VMインスタンスに対する迅速なメンテナンスやゾーンへの耐性を達成することができます。オートヒーリングは、ヘルスチェックに基づいて稼働しているインスタンスのヘルスを検証し、問題があるインスタンスを自動的に修復または交換します。<br>そして、ヘルスチェックは設定によって、応答しないVMに対して何度も試行を行い、それでも応答しないVMに対しては再作成を行います。このヘルスチェックはプロトコルや応答タイムアウト、チェック間隔、非ヘルスステータスの試行回数など、細かい設定を選択することができ、問題の詳細に応じた対応が可能です。<br>したがって、MIGsとヘルスチェック設定を使えば、指定した回数VMが応答しない場合の再作成を達成することができます。<br>不正解の選択肢についての説明：<br>選択肢：既存のインスタンスグループを参照するバックエンド設定でHTTPロードバランサを作成します。ヘルスチェックをヘルシー（HTTP）にします<br>この選択肢が正しくない理由は以下の通りです。<br>HTTPロードバランサを作成しても、オートヒーリングの機能も設定も提供していません。<br>一方、マネージドインスタンスグループではオートヒーリングを設定することができます。<br>したがって、VMが応答しない場合の再作成を構成するためにはマネージドインスタンスグループの作成が必要です。<br>選択肢：既存のインスタンスグループを参照するバックエンド設定でHTTPロードバランサを作成します。バランシングモードを定義し、最大RPSを10に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>HTTPロードバランサのバランシングモードの定義や最大RPSの設定は、ロードの分散に関連していますが、特定のVMのヘルスチェックなど、オートヒーリングの設定とは無関係です。対してマネージドインスタンスグループはオートヒーリングの設定が可能です。<br>選択肢：マネージドインスタンスグループを作成します。オートスケーリング設定がオンになっていることを確認します<br>この選択肢が正しくない理由は以下の通りです。<br>オートスケーリング設定をオンにしても、それによってオートヒーリングが設定されるわけではありません。オートスケーリングは需要に応じてインスタンスの数を増減させる機能であり、一方、オートヒーリングは特定のヘルスチェックの基準を満たさないインスタンスを自動的に再作成する機能です。<br>したがって、VMが応答しない場合に再作成するという要件を満たすには、ヘルスチェックの設定が必要なため、正解はヘルスチェックを設定する選択肢です。'>
<div class='choice'> マネージドインスタンスグループを作成します。オートヒーリングのヘルスチェックをヘルシー（HTTP）に設定にします</div>
<div class='choice'> 既存のインスタンスグループを参照するバックエンド設定でHTTPロードバランサを作成します。バランシングモードを定義し、最大RPSを10に設定します</div>
<div class='choice'> 既存のインスタンスグループを参照するバックエンド設定でHTTPロードバランサを作成します。ヘルスチェックをヘルシー（HTTP）にします</div>
<div class='choice'> マネージドインスタンスグループを作成します。オートスケーリング設定がオンになっていることを確認します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題53<br>分析のためには、すべてのCompute Engineインスタンスからplatform-logsというBigQueryデータセットにすべてのログを送信する必要があります。すべてのインスタンスにCloud Loggingエージェントをインストール済みです。あなたは、コストを最小限に抑えたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「1.Cloud Loggingで、Compute Engineのログだけを表示するフィルタを作成します<br>2.Create Exportをクリックします<br>3.Sink ServiceとしてBigQueryを選択し、Sink Destinationとしてplatform-logsデータセットを選択します」です。<br>この問題では、Compute Engineインスタンスからの全ログをBigQueryデータセットに送信する方法と、そのプロセスでコストの最小化を達成する方法を求めています。Cloud Loggingエージェントが既にインストールされていることを考慮に入れつつ、BigQueryとCloud Logging間で適切なデータエクスポートと転送の戦略を選択することが求められています。選択肢の中から最も効率的でコスト効果の高い解決策を探すためには、それぞれのサービスの機能とそれらの連携について理解していることが必要です。<br>基本的な概念や原則：<br>Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションとシステムからのログを収集、分析、表示し、トラブルシューティングと診断情報を提供します。<br>Cloud Loggingエージェント：Compute EngineインスタンスのアプリケーションログをCloud Loggingに送信するためのソフトウェアです。<br>BigQuery：Google Cloudの大規模データ分析サービスです。巨大なデータセットに対するSQLクエリを高速に実行することができます。<br>フィルタリングとエクスポート：Cloud Loggingの機能で、特定の種類のログを選択し、異なるGoogle Cloudサービスにエクスポートすることができます。<br>サービスアカウント：Google Cloudリソースを認証するための特殊な種類のアカウントです。<br>Cloud Functions：イベント駆動型の計算を提供するサーバレス実行環境です。特定のイベントに応じて、事前に設定された関数を自動的に実行します。<br>Cloud Scheduler：Google Cloudのジョブスケジューラサービスです。定期的なタスク実行や一定間隔でのAPI呼び出しなどを自動化することができます。<br>正解についての説明：<br>（選択肢）<br>・1.Cloud Loggingで、Compute Engineのログだけを表示するフィルタを作成します<br>2.Create Exportをクリックします<br>3.Sink ServiceとしてBigQueryを選択し、Sink Destinationとしてplatform-logsデータセットを選択します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Compute EngineのすべてのログをBigQueryデータセットに送信するためにCloud Loggingを使用することは、ログの集中管理を可能にするとともに、必要なデータのフィルタリングを行いながら効率的に取り扱いを可能にします。特にフィルタを作成することで不必要なデータの送信を防ぎ、その結果コストを抑えることができます。<br>次に、エクスポート機能を使用することで、作成したフィルタに基づいて選択したログデータを特定のサービスに送信することができます。これにより、BigQueryという分析ツールに直接データを送ることができ、予めインストール済みのCloud Loggingエージェントから取得したログの処理を効率的に行うことができます。<br>以上の理由により、この選択肢がコストを最小限に抑えつつ要件を満たす最適な答えとなります。<br>不正解の選択肢についての説明：<br>選択肢：1.インスタンスで使用するサービスアカウントに、platform-logsデータセットのBigQuery Data Editorロールを与えます<br>2.インスタンスのメタデータを更新して、次の値を追加します<br>この選択肢が正しくない理由は以下の通りです。<br>BigQueryに直接ログを送信するためのCloud Loggingエージェントの設定やメタデータの更新オプションは存在しません。正しい選択は、ログを収集しエクスポートするためのCloud Loggingのexport機能を利用する方法です。<br>選択肢：1. Cloud Loggingで、ログというCloud Pub/Subトピックをシンクとして使用してログエクスポートを作成します<br>2. ログトピック内のメッセージによってトリガーされるCloud Functionsを実装します<br>3. Compute Engineからのものではないログを削除し、Compute Engineのログをプラットフォームログデータセットに挿入するようにCloud Functionsを構成します<br>この選択肢が正しくない理由は以下の通りです。<br>この選択肢は、Cloud Pub/Sub, Cloud Functionsなどの余分なリソースを使用するためコストがかさむことと、過度に複雑で管理が難しいためです。比べて、正解の選択肢はCloud LoggingとBigQueryの直接の統合を使用することでシンプルかつコスト効率的にログのエクスポートを行うことができます。<br>選択肢：1. プラットフォームログデータセットに対してBigQueryユーザー役割を持つCloud Functionsを実装します<br>2. 次のクエリを実行するBigQueryジョブを作成するようにこのCloud Functionsを構成します：INSERT INTO dataset.platform-logs (timestamp, log) SELECT timestamp, log FROM compute.logs WHERE timestamp &gt; DATE_SUB（CURRENT_DATE(), INTERVAL 1 DAY)<br>3. Cloud Schedulerを使用して、このCloud Functionsを1日に1回トリガーします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Functionsを使用してBigQueryへのインサートを行う手法は、ログのリアルタイム転送ではなく定期的な転送になります。<br>また、Cloud FunctionsとCloud Schedulerの管理コストが発生します。<br>一方、正解の選択肢ではCloud Loggingのエクスポート機能を使用することで、リアルタイムにかつ追加のコスト無しでログを転送できます。'>
<div class='choice'><br>1. プラットフォームログデータセットに対してBigQueryユーザー役割を持つCloud Functionsを実装します<br>2. 次のクエリを実行するBigQueryジョブを作成するようにこのCloud Functionsを構成します：INSERT INTO dataset.platform-logs (timestamp, log) SELECT timestamp, log FROM compute.logs WHERE timestamp &gt; DATE_SUB（CURRENT_DATE(), INTERVAL 1 DAY)<br>3. Cloud Schedulerを使用して、このCloud Functionsを1日に1回トリガーします</div>
<div class='choice'><br>1. Cloud Loggingで、ログというCloud Pub/Subトピックをシンクとして使用してログエクスポートを作成します<br>2. ログトピック内のメッセージによってトリガーされるCloud Functionsを実装します<br>3. Compute Engineからのものではないログを削除し、Compute Engineのログをプラットフォームログデータセットに挿入するようにCloud Functionsを構成します</div>
<div class='choice'><br>1.Cloud Loggingで、Compute Engineのログだけを表示するフィルタを作成します<br>2.Create Exportをクリックします<br>3.Sink ServiceとしてBigQueryを選択し、Sink Destinationとしてplatform-logsデータセットを選択します</div>
<div class='choice'><br>1.インスタンスで使用するサービスアカウントに、platform-logsデータセットのBigQuery Data Editorロールを与えます<br>2.インスタンスのメタデータを更新して、次の値を追加します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題54<br>あなたはゲーム統計をデータベースに保存するマルチプレイヤーゲームアプリケーションを構築しています。アプリケーションの人気が高まるにつれて、一貫したパフォーマンスを提供することに懸念を抱いています。管理の複雑さを増すことなく、世界中のユーザーに対して最適なゲームパフォーマンスを保証する必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「Cloud Spannerを使用して、ゲーム統計にマッピングされたユーザーデータを保存します」です。<br>この問題では、マルチプレイヤーゲームアプリケーションのゲーム統計をデータベースに格納し、そのパフォーマンスを一貫して提供するという要件を満たすための最適な解決策を考える必要があります。特に、世界中のユーザーに対して最適なゲームパフォーマンスを維持しつつ、管理の複雑さを増やさない方法を検討することが重要です。選択肢を考慮する際には、これらの需要を全て満たす解決策を見つけ出すことが重要です。<br>基本的な概念や原則：<br>Cloud Spanner：Google Cloudのスケーラブルで強力なリレーショナルデータベースサービスです。トランザクショナル整合性と地理的なスケールを同時に提供し、大規模な読み取りと書き込み、世界中のユーザーに対する一貫性を保証します。<br>Cloud SQL：Google Cloudのフルマネージドリレーショナルデータベースサービスです。マネージメント作業を減らし、性能の良いデータベース資源の管理を容易にします。ただし、クロスリージョンレプリケーションが可能ですが、Cloud Spannerのような地理的なスケールは提供しません。<br>BigQuery：Google Cloudのスケーラブルなデータウェアハウジングサービスです。大量のデータの保存と分析に最適であり、リアルタイム分析をサポートします。ただし、一貫性あるトランザクションやゲーム統計のようなデータの即時処理には、最適ではありません。<br>Bigtable：Google CloudのNoSQLデータベースサービスです。ローミングイベントデータ、時系列データ、マーケティングデータなど大量のデータの保存とリアルタイム分析に最適です。ユーザー名でパーティショニングされたデータベースの作成が可能ですが、各ユーザーに一貫した体験を提供するために、データベースを適切に管理する必要があります。<br>正解についての説明：<br>（選択肢）<br>・Cloud Spannerを使用して、ゲーム統計にマッピングされたユーザーデータを保存します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Cloud SpannerはGoogle Cloudのフルマネージド型、分散RDBMSであり、高可用性と一貫したパフォーマンスの提供が特徴です。この強力なパフォーマンスとスケーラビリティは、人気の高まるマルチプレイヤーゲームアプリケーションが求める要件を満たします。海外または国内のどこにいるユーザーでも、一貫したゲームパフォーマンスが保証されます。<br>また、Cloud Spannerは、SQLクエリの処理とトランザクションの管理を自動的に行うため、スケールが大きくなっても手間がかかりません。<br>次に、Cloud Spannerはフルマネージド型のサービスなので、データベースの管理が容易であり、複雑さを増すことなく、アプリケーションの構築に集中することができます。そのため、この問題の要件に最適な解決策と言えます。<br>不正解の選択肢についての説明：<br>選択肢：EU、米国、およびAPAC地域のゲーム統計を保存するために、クロスリージョンレプリケーションを備えたCloud SQLデータベースを使用します<br>この選択肢が正しくない理由は以下の通りです。<br>クロスリージョンレプリケーションを備えたCloud SQLデータベースでは一貫性を犠牲にすることになり、また管理の複雑さも増します。<br>一方、Cloud Spannerはグローバルトランザクションと強い一貫性を提供し、同時に管理の複雑さを増すことなく、世界中のユーザーに対して最適なパフォーマンスを維持します。<br>選択肢：BigQueryを使用してゲーム統計を保存し、Redis on Memorystoreインスタンスを前面に置いてグローバルな一貫性を提供します<br>この選択肢が正しくない理由は以下の通りです。<br>BigQueryは分析ワークロード向けであり、リアルタイムの一貫性向けではありません。<br>また、Redisと組み合わせても複数リージョン間のでデータの完全な一貫性を提供することは難しいです。<br>それに対して、Cloud Spannerは一貫性とスケーラビリティを両立した、多地域での使用に適したデータベースです。<br>選択肢：ユーザー名でパーティショニングされたBigtableデータベースにゲーム統計を格納します<br>この選択肢が正しくない理由は以下の通りです。<br>Bigtableは一貫したパフォーマンスを提供しますが、孤立したリージョン内でしか動作しないため、世界中のユーザーに最適なゲームパフォーマンスを保証することが難しくなります。<br>しかし、Cloud Spannerはグローバルなスケーラビリティと一貫性を提供し、管理の複雑さを増やすことなく、各地域のユーザーに最適なパフォーマンスを提供することができます。'>
<div class='choice'> EU、米国、およびAPAC地域のゲーム統計を保存するために、クロスリージョンレプリケーションを備えたCloud SQLデータベースを使用します</div>
<div class='choice'> ユーザー名でパーティショニングされたBigtableデータベースにゲーム統計を格納します</div>
<div class='choice'> BigQueryを使用してゲーム統計を保存し、Redis on Memorystoreインスタンスを前面に置いてグローバルな一貫性を提供します</div>
<div class='choice'> Cloud Spannerを使用して、ゲーム統計にマッピングされたユーザーデータを保存します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題55<br>ビジネスクリティカルなアプリケーションをローカルデータセンターからGoogle Cloudに移行しようとしています。高可用性戦略の一環として、ゾーン障害が発生した場合でも、アプリケーションで使用されるすべてのデータがすぐに利用できるようにしたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「アプリケーションデータをリージョン永続ディスクに保存します。障害が発生した場合は、このディスクをアタッチしたインスタンスを別のゾーンに作成します」です。<br>この問題では、ローカルデータセンターからGoogle Cloudへのアプリケーションの移行とその対障害性に焦点を当てています。ゾーン障害が発生した場合でもデータがすぐに利用可能でなければならないという重要な要件が示されています。選択肢を見ると、データは"リージョン永続ディスク"と"ゾーン永続ディスク"のどちらかに保存されるという二項対立が見受けられます。これらの違いを理解し、ゾーンの障害へのリジリエンスと高可用性という目標を満たすためにはどのストレージタイプが適しているかを判断することが求められています。<br>基本的な概念や原則：<br>リージョン永続ディスク：Google Cloud上でのデータストレージの一種で、リージョン全体でデータを保存することができます。ゾーンの障害が発生してもデータは自動的に別のゾーンに存在し続けます。<br>ゾーン障害：Google Cloudの地理的エリア（ゾーン）における一時的な死滅または障害のことを指します。これは自然災害またはシステム障害などによるものです。<br>ゾーン永続ディスク：Google Cloud上でのデータストレージの一種で、特定のゾーンにデータを保存します。ゾーン障害が発生すると、同一ゾーン内のデータに対してリスクが存在します。<br>高可用性：システムが長期間にわたり継続的に利用可能であることです。システム障害が発生しても短時間で復旧し、ダウンタイムを最小限に抑えます。<br>データ移行：あるストレージシステムから別のストレージシステムにデータを移動するプロセスです。これには、データの互換性、セキュリティ、完全性の問題が含まれます。<br>ディスクのスナップショット：ディスクの特定の時点での完全なコピーです。スナップショットを利用することで障害が発生した場合でも状態を復元することが可能ですが、一定のタイムディレイが発生します。<br>正解についての説明：<br>（選択肢）<br>・アプリケーションデータをリージョン永続ディスクに保存します。障害が発生した場合は、このディスクをアタッチしたインスタンスを別のゾーンに作成します<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloudのリージョン永続ディスクは、データを複数のゾーンに自動的にレプリケートします。これは、他のゾーンでの障害が発生した場合でも、データが利用可能であることを保証します。そのため、ゾーン障害が発生した場合に、このディスクをアタッチしたインスタンスを別のゾーンに作成すれば、アプリケーションデータはすぐに利用可能になります。つまり、この方法は、ゾーン内で障害が発生しても高い可用性を保つことができ、ビジネスクリティカルなアプリケーションのデータを保護するのに適しています。<br>また、リージョン永続ディスクはゾーン間でデータ移動のオーバーヘッドがないため、要件を手際よく満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：アプリケーションデータをゾーン永続ディスクに保存します。ディスクのスナップショットスケジュールを作成します。障害が発生したら、最新のスナップショットから新しいディスクを作成し、別のゾーンの新しいVMにアタッチします<br>この選択肢が正しくない理由は以下の通りです。<br>ゾーン永続ディスクを選択した場合、高可用性を確保するためには手動でスナップショットを取得し、新しいディスクを作成、アタッチする工程が必要になります。これに対してリージョン永続ディスクならば、データがすぐに利用可能です。これはゾーン障害発生時でも別ゾーンに即座にインスタンスを作成可能であるためです。<br>選択肢：アプリケーションデータをゾーン永続ディスクに保存します。障害が発生した場合は、このディスクをアタッチしたインスタンスを別のゾーンに作成します<br>この選択肢が正しくない理由は以下の通りです。<br>ゾーン永続ディスクは特定のゾーンに存在し、そのゾーンで障害が発生すればデータが利用不可になる可能性があります。<br>一方、リージョン永続ディスクに保存すると、複数のゾーンに跨ってデータが保持され、ゾーン障害が発生した場合でもすぐに利用できるので、高可用性戦略を実現するにはこちらが適しています。<br>選択肢：アプリケーションデータをリージョン永続ディスクに保存します。ディスクのスナップショットスケジュールを作成します。障害が発生したら、最新のスナップショットから新しいディスクを作成し、別のゾーンの新しいVMにアタッチします<br>この選択肢が正しくない理由は以下の通りです。<br>スナップショットから新しいディスクを作成して新しいVMにアタッチする過程は時間がかかり、データがすぐに利用可能だという要件を満たすことができません。<br>それに対して、正解の選択肢では障害時にすぐに別のゾーンにインスタンスを作りディスクをアタッチすることで、要件を即座に満たすことができます。'>
<div class='choice'> アプリケーションデータをゾーン永続ディスクに保存します。ディスクのスナップショットスケジュールを作成します。障害が発生したら、最新のスナップショットから新しいディスクを作成し、別のゾーンの新しいVMにアタッチします</div>
<div class='choice'> アプリケーションデータをリージョン永続ディスクに保存します。ディスクのスナップショットスケジュールを作成します。障害が発生したら、最新のスナップショットから新しいディスクを作成し、別のゾーンの新しいVMにアタッチします</div>
<div class='choice'> アプリケーションデータをリージョン永続ディスクに保存します。障害が発生した場合は、このディスクをアタッチしたインスタンスを別のゾーンに作成します</div>
<div class='choice'> アプリケーションデータをゾーン永続ディスクに保存します。障害が発生した場合は、このディスクをアタッチしたインスタンスを別のゾーンに作成します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題56<br>バックエンドデータベースとしてCloud Spannerを使用するアプリケーションがあります。アプリケーションのトラフィックパターンは非常に予測可能です。そのため、トラフィックに応じてSpannerノードの数を自動的に増減したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「Cloud SpannerのCPUが閾値を上回ったり下回ったりしたときに、Webhookにアラートを送信するCloud Monitoringアラートポリシーを作成します。HTTPをリッスンし、それに応じてSpannerリソースのサイズを変更するCloud Functionを作成します」です。<br>この問題では、アプリケーションのトラフィックパターンが予測可能であるという前提のもと、クラウド環境でスケールアップやダウンの自動化をどのように実現するかが問われています。アプリケーションのトラフィックが一定のルールに従って変化する場合、それらの変化をモニタリングしつつ、必要に応じてリソースを増減することで、パフォーマンスを維持しつつコストを抑えることができます。クラウドSpannerのノード数を自動的に増減するためには、Cloud MonitoringとCloud Functionを使った設定が求められています。これらのGoogle Cloudサービスを適切に設定して、リソースの自動調整ができる環境を作ることが求められています。<br>基本的な概念や原則：<br>Cloud Spanner：Google Cloudの分散リレーショナルデータベースサービスです。グローバル規模でのトランザクション処理と、SQLクエリとACIDトランザクションをサポートしています。<br>Cloud Monitoring：Google Cloudのサービスで、アプリケーションとインフラストラクチャのパフォーマンスをモニタリングします。アラート機能も提供しており、閾値を超えると通知を行います。<br>Cloud Function：Google Cloudのサーバレス実行環境です。HTTPトリガーを使ってCloud Spannerのスケーリングを動的に制御するために使用されます。<br>アラートポリシー：Cloud Monitoringにおける設定で、特定のメトリクスが設定した閾値を超えたり下回ったりした時にアラートを送信する仕組みです。<br>Cloud SpannerのCPU使用率：Cloud Spannerのパフォーマンスを評価するための重要な指標です。CPU使用率が一定の閾値を超えるとパフォーマンスが低下する恐れがあります。<br>Webhook：特定のイベントが発生したときにHTTPリクエストを送信するシステムです。このケースでは、Cloud MonitoringのアラートをトリガーとしてWebhookが発火します。<br>SRE（Site Reliability Engineering）：システムの信頼性を確保するためのソフトウェアエンジニアリングの手法です。このケースでは、SREがアラートを受けて手動でリソースを調整する選択肢が提示されていますが、自動スケーリングのニーズには対応していません。<br>正解についての説明：<br>（選択肢）<br>・Cloud SpannerのCPUが閾値を上回ったり下回ったりしたときに、Webhookにアラートを送信するCloud Monitoringアラートポリシーを作成します。HTTPをリッスンし、それに応じてSpannerリソースのサイズを変更するCloud Functionを作成します<br>この選択肢が正解の理由は以下の通りです。<br>Cloud Spannerは現在、自動的なスケーリングをサポートしていませんが、Cloud MonitoringアラートポリシーとCloud Functionを組み合わせることで、自動スケーリングのような動作を実現することができます。まず、Cloud Monitoringアラートポリシーを設定することで、Cloud SpannerのCPU使用率が一定の閾値を超えたり下回ったりしたときに、Webhookに警告メッセージを自動的に送信するようにします。<br>そして、そのWebhookをリッスンするCloud Functionを作成することで、警告メッセージに対応して、Cloud Spannerのノード数をプログラムで増減させることができます。これにより、トラフィックパターンに応じてSpannerノードの数を自動的に増減するニーズを満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Monitoringのメトリクスを確認するためにスケジュールされたベースで実行されるcronジョブを作成し、それに応じてSpannerインスタンスのサイズを変更します<br>この選択肢が正しくない理由は以下の通りです。<br>cronジョブは定時実行が前提であり、SpannerのCPU使用率が高まった瞬間的な変化に対応するには遅すぎます。CPUの利用状況に応じて自動的に調整するためには、Cloud MonitoringとCloud Functionを組み合わせてリアルタイムに反応する仕組みが必要です。<br>選択肢：Cloud SpannerのCPUが閾値を超えると、常駐運用のSREのメールにアラートを送信するように、Cloud Monitoringのアラートポリシーを作成します。SREはそれに応じてリソースを増減します<br>この選択肢が正しくない理由は以下の通りです。<br>要求されたのは、Spannerノードの数を自動的に増減することですが、この選択肢ではSREが手動でリソースを増減すると答えています。これは自動化の要件を満たさないため、不適切です。正しい選択肢ではCloud Functionを使用して、完全に自動化されたリソースの増減を提供します。<br>選択肢：Cloud Monitoringアラートポリシーを作成し、Cloud SpannerのCPUが閾値を超えるとGoogle Cloud Supportのメールにアラートを送信します。Googleサポートはそれに応じてリソースを増減します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、Google Cloud Supportがリソースを手動で増減するという考え方が誤っています。Google Cloud Supportはこれらのことを手動で管理するサービスではなく、このような処理は自動化のツールを使用するべきです。正解の選択肢では、これがCloud FunctionとCloud Monitoringアラートポリシーを組み合わせることで実現されています。'>
<div class='choice'> Cloud SpannerのCPUが閾値を上回ったり下回ったりしたときに、Webhookにアラートを送信するCloud Monitoringアラートポリシーを作成します。HTTPをリッスンし、それに応じてSpannerリソースのサイズを変更するCloud Functionを作成します</div>
<div class='choice'> Cloud SpannerのCPUが閾値を超えると、常駐運用のSREのメールにアラートを送信するように、Cloud Monitoringのアラートポリシーを作成します。SREはそれに応じてリソースを増減します</div>
<div class='choice'> Cloud Monitoringのメトリクスを確認するためにスケジュールされたベースで実行されるcronジョブを作成し、それに応じてSpannerインスタンスのサイズを変更します</div>
<div class='choice'> Cloud Monitoringアラートポリシーを作成し、Cloud SpannerのCPUが閾値を超えるとGoogle Cloud Supportのメールにアラートを送信します。Googleサポートはそれに応じてリソースを増減します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題57<br>ビジネスにとって重要なワークロードがCompute Engine上で実行されています。このワークロードの起動ディスク上のデータが定期的にバックアップされるようにしたいと考えています。災害時には、バックアップをできるだけ早くリストアできるようにする必要があります。また、コスト削減のため、古いバックアップは自動的にクリーニングされるようにしたいと考えています。あなたは、Googleが推奨するプラクティスに従いたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「希望の間隔を使用して、ディスクのスナップショットスケジュールを作成します」です。<br>この問題では、Compute Engineのワークロードのデータバックアップとそのリストアの迅速性、コスト削減についての要件を理解することが求められています。さらに、Googleが推奨する方法に従う点も重要です。上記の要件を満たす解決策を選ぶ際には、定期的なバックアップ、迅速なリストア、自動的なバックアップのクリーニング、そしてGoogle推奨のプラクティスに沿っているかどうか、以上の4点を意識して解答を選んでください。<br>基本的な概念や原則：<br>ディスクのスナップショットスケジュール：定期的にCompute Engineディスクのスナップショットを取得するための設定です。災害回復などのためのバックアップを提供します。<br>スナップショット：ディスクの特定の時点の状態をキャプチャしたもので、復元のために使用されます。<br>Compute Engine：Google Cloudの仮想マシンを提供するサービスで、好きなときにスケーリングと操作ができます。<br>クリーニングポリシー：古いデータや不要なデータを自動的に削除するための方針です。コスト削減とデータの整理に役立ちます。<br>Cloud Functions：Google Cloudのサーバレス実行環境で、任意の処理をスケーラブルに実行できます。一般的にはデータ処理やイベント駆動のワークロード向けです。<br>cronジョブ：定期的にタスクを実行するシステムの機能です。指定した時間や間隔でスクリプトやコマンドを自動実行します。<br>Cloud Tasks：Google Cloudのタスクキューサービスで、非同期ワークロードの処理を管理します。<br>正解についての説明：<br>（選択肢）<br>・希望の間隔を使用して、ディスクのスナップショットスケジュールを作成します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Compute Engineのスナップショットスケジュールは、定期的なディスクバックアップを自動的に作成・管理するための機能です。そのため、リソースの自動的な定期バックアップを行いたいと考えている場合には非常に便利な機能と言えます。<br>また、スナップショットスケジュールを使用することで、バックアップ時にシステムがダウンしないため、ワークロードの中断を防ぐことができます。これはビジネスにとって重要なワークロードを扱う際に特に重要となるメリットです。<br>さらに、スナップショットスケジュールにはリテンションポリシーという機能があり、これを設定することで古いバックアップは自動的に削除・クリーニングされるため、コスト削減を実現することができます。これは、コスト削減の要件を満たすために必要な機能です。<br>最後に、スナップショットのリストアは、災害時に迅速なデータリカバリを可能にします。<br>したがって、正解の選択肢は、便利な自動化、ダウンタイム防止、コスト削減、迅速なリカバリとともに、Googleの推奨するプラクティスを適切に満たします。<br>不正解の選択肢についての説明：<br>選択肢：インスタンステンプレートを作成するためにCloud Functionsを実装します<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンステンプレートを作成するためのCloud Functionsは、Compute Engineのデータを定期的にバックアップし、早くリストアできるようにする機能を提供しません。<br>それに対して、ディスクのスナップショットスケジュールはこの要件に適しています。スナップショットスケジュールでは、定期的にディスクの状態をスナップショットとして保存し、災害時にこれをディスクにリストアできます。<br>また、古いスナップショットは自動的にクリーニングされます。<br>選択肢：gcloudを使用してディスクから新しいディスクを作成するcronジョブを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloudを使用して新しいディスクを作成するcronジョブはコストがかかり、データ復旧の速度も遅く、古いバックアップの自動クリーニングも行えません。<br>それに対して、スナップショットスケジュールは定期的なバックアップが可能で、即時のリストアや古いスナップショットの自動削除が可能です。<br>選択肢：Cloud Tasksを作成して画像を作成し、Cloud Storageにエクスポートします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud TasksとCloud Storageを使った画像作成とエクスポートでは、起動ディスクのデータをバックアップする目的には合致しますが、災害時の早いリストアやクリーニングに対応するための仕組みが不足しています。<br>対し、ディスクのスナップショットスケジュールは、定期的なバックアップ、高速なリストア、古いスナップショットの自動クリーニングが可能で、要求を全て満たします。'>
<div class='choice'> 希望の間隔を使用して、ディスクのスナップショットスケジュールを作成します</div>
<div class='choice'> gcloudを使用してディスクから新しいディスクを作成するcronジョブを作成します</div>
<div class='choice'> Cloud Tasksを作成して画像を作成し、Cloud Storageにエクスポートします</div>
<div class='choice'> インスタンステンプレートを作成するためにCloud Functionsを実装します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題58<br>Cloud Storageで静的ウェブサイトをホストしています。最近、このサイトにPDFファイルへのリンクを掲載し始めました。現在、ユーザーがこれらのPDFファイルへのリンクをクリックすると、ブラウザがファイルをローカルシステムに保存するよう促します。代わりに、ユーザーにローカルにファイルを保存するように求めず、クリックしたPDFファイルをブラウザウィンドウ内に直接表示したいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「PDFファイルオブジェクトのContent-Typeメタデータをapplication/pdfに設定します」です。<br>この問題では、Cloud Storageの設定とユーザーの体験との関連性について理解することが重要です。指摘されている問題は、ユーザーがPDFリンクをクリックした際の動作で、特定の設定変更によって直接ブラウザ上で表示することが望まれています。選択肢を評価する際には、Cloud Storageで設定できるメタデータや他の設定のロールを意識し、それらがどのようにユーザーの体験に影響を与えるかを考えなければなりません。<br>基本的な概念や原則：<br>Content-Typeメタデータ：HTTP応答ヘッダーの一つで、返されるコンテンツのメディアタイプを指定します。この情報は、ブラウザがどのようにコンテンツを表示するかを決定します。<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスです。非常に大規模なデータを保存、取得、共有することができます。<br>Cloud CDN：Google Cloud提供のコンテンツ配信ネットワーク（CDN）サービスです。ユーザーに高速で安全なウェブとビデオコンテンツを提供します。<br>公開共有：Google Cloud Storageで特定のオブジェクトをインターネットに公開する設定です。これにより、アクセス権限を持たないユーザーでも該当のオブジェクトを取得することができます。<br>ラベル：Google Cloudのリソースに追加できるキーと値のペアです。リソースの構造化と管理を容易にします。<br>正解についての説明：<br>（選択肢）<br>・PDFファイルオブジェクトのContent-Typeメタデータをapplication/pdfに設定します<br>この選択肢が正解の理由は以下の通りです。<br>正解の選択肢は、PDFファイルオブジェクトのContent-Typeメタデータをapplication/pdfに設定することを提案しています。これは、ブラウザにどのようにファイルを解釈し、どのように表示するかを告げる重要な情報を提供します。Content-Typeとは、HTTPヘッダーの一部であり、サーバーがクライアントに送信するコンテンツのメディアタイプを定義します。application/pdfと設定することで、ブラウザはPDFファイルをダウンロードするのではなく、ブラウザウィンドウ内で直接表示すべきであると解釈します。<br>したがって、問題文の要件を満たすためには、Cloud Storage上のPDFファイルオブジェクトのContent-Typeメタデータをapplication/pdfに設定するのが適切です。<br>不正解の選択肢についての説明：<br>選択肢：ウェブサイトのフロントエンドでCloud CDNを有効にします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud CDNはコンテンツを高速に配送するためのサービスであり、PDFファイルをブラウザ内で表示するための要件を直接満たしません。正解はContent-Typeメタデータを設定することで、ブラウザがPDFとして認識し直接開くことが可能になります。<br>選択肢：PDFファイルオブジェクトの"公開共有"を有効にします<br>この選択肢が正しくない理由は以下の通りです。<br>PDFファイルオブジェクトの"公開共有"を有効にすることは、そのファイルを誰でもアクセスできるように設定することであり、PDFをブラウザで直接表示する問題とは関係ありません。正解の選択肢であるContent-Typeメタデータを設定することで、ブラウザはファイル形式を認識し、その通りに表示することができます。<br>選択肢：Content-Typeのキーとapplication/pdfの値を持つラベルをストレージバケットに追加します<br>この選択肢が正しくない理由は以下の通りです。<br>ラベルはGoogle Cloud Storageバケットの管理目的で使用され、オブジェクトごとの操作に影響を与えません。そのため、この方法ではPDFをブラウザ内で表示する要件を達成できません。<br>それに対して、正解の選択肢ではContent-TypeメタデータをPDFファイルオブジェクトごとに設定するため、ブラウザはその情報を用いてPDFを直接表示することができます。'>
<div class='choice'> ウェブサイトのフロントエンドでCloud CDNを有効にします</div>
<div class='choice'> PDFファイルオブジェクトの"公開共有"を有効にします</div>
<div class='choice'> Content-Typeのキーとapplication/pdfの値を持つラベルをストレージバケットに追加します</div>
<div class='choice'> PDFファイルオブジェクトのContent-Typeメタデータをapplication/pdfに設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題59<br>gcloudに複数の構成を使用しています。可能な限り少ない手順で、非アクティブな構成の構成済みKubernetes Engineクラスターをレビューしたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「kubectl config get-contextsを使って出力を確認します」です。<br>この問題では、gcloudに複数の構成があり、非アクティブな構成のKubernetes Engineクラスターを可能な限り少ない手順でレビューする方法を問われています。そのため、出力を確認するためのコマンドの選択に関心を持つことが必要です。この問題はgcloudとKubernetesの知識を組み合わせて解く必要があり、選択肢を見るときは、非アクティブな構成を効果的にレビューする手段を探すことを念頭に置くべきです。<br>基本的な概念や原則：<br>gcloud：Google Cloud SDKの主要なコマンドラインツールで、Google Cloudのリソースやアプリケーションを管理するためのインターフェースを提供します。<br>gcloudの構成：gcloudツールで利用する設定のことで、プロジェクト設定や認証情報などを管理します。複数の構成を持つことで、異なる設定で作業を行うことができます。<br>kubectl：Kubernetesクラスターを制御するためのコマンドラインツールです。<br>kubectl config get-contexts：現在のkubectlコンテキストの一覧表示コマンドです。非アクティブなKubernetes Engineクラスターの情報も確認することができます。<br>kubectl config use-context：kubectlコマンドの実行コンテキストを変更するコマンドです。コマンドの実行に必要なクラスターと認証ユーザー情報を切り替えられます。<br>正解についての説明：<br>（選択肢）<br>・kubectl config get-contextsを使って出力を確認します<br>この選択肢が正解の理由は以下の通りです。<br>まず、kubectl config get-contextsコマンドを使うと、あなたが定義したすべてのKubernetes Engineクラスターのコンテキストを一覧表示することができます。各コンテキストはKubernetesクラスターへの接続情報を含むため、これによって非アクティブな構成のKubernetes Engineクラスターをすぐに見つけることが可能になります。<br>また、このコマンドの出力からは各コンテキストの名前、クラスター、ネームスペース、そしてそのコンテキストが現在アクティブかどうかといった情報を得ることができます。たとえば、表示されたクラスターのリストから特定のクラスターのコンテキストを選択し、そのコンテキストをアクティブに設定することで、そのクラスターの詳細情報へアクセスすることができます。<br>したがって、非アクティブな構成の構成済みKubernetes Engineクラスターをレビューするためには、kubectl config get-contextsコマンドを使って一覧を確認し、その中から目的のクラスターを特定するのが最も効率的であり、手順を最小限に抑えることができます。<br>不正解の選択肢についての説明：<br>選択肢：gcloud config configurations describeを使って出力を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud config configurations describeコマンドはgcloudの設定情報を表示しますが、Kubernetes Engineクラスターの情報を直接取得することはできません。<br>それに対して、kubectl config get-contextsコマンドは、構成されたすべてのKubernetesクラスターの情報を表示します。<br>選択肢：gcloud config configurations activateとgcloud config listを使って出力を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>gcloud config configurations activateとgcloud config listを使用すると、Google Cloudプロジェクト全体の設定情報が表示されますが、Kubernetes Engineクラスターの情報は直接得られません。<br>一方、kubectl config get-contextsを使うと、Kubernetesのコンテキストが一覧表示され、特定のクラスター情報を確認できます。<br>選択肢：kubectl config use-contextとkubectl config viewを使って出力を確認します<br>この選択肢が正しくない理由は以下の通りです。<br>kubectl config use-contextは特定のクラスターに切り替えるコマンドで、非アクティブな構成をレビューする動作自体には不要です。<br>それに対して、kubectl config get-contextsは一度ですべての構成を表示するため、手順が少なく済みます。'>
<div class='choice'> kubectl config use-contextとkubectl config viewを使って出力を確認します</div>
<div class='choice'> gcloud config configurations describeを使って出力を確認します</div>
<div class='choice'> gcloud config configurations activateとgcloud config listを使って出力を確認します</div>
<div class='choice'> kubectl config get-contextsを使って出力を確認します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題60<br>あなたは最高のクエリパフォーマンスを得るためにCloud Spannerインスタンスを管理する必要があります。本番のインスタンスは単一のGoogle Cloudリージョンで実行されます。最短時間でパフォーマンスを改善する必要があります。Googleのベストプラクティスに従ってサービスを構成する必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率の割合が65%に達したときにアラートを出します。この閾値を超えた場合は、インスタンスにノードを追加します」です。<br>この問題では、Cloud Spannerインスタンスのパフォーマンス改善について問われています。ここで主に考慮すべきは、最短時間でパフォーマンス改善を実現するための方法と、Googleのベストプラクティスに従ってサービスを構成する方法です。特にキーとなる要素として、CPU使用率の閾値を設定して該当するアラートを作成する、そしてCPU使用率が一定の割合を超えた場合にノードを追加することが挙げられます。また、Cloud Monitoringを使用してパフォーマンスを効率的に管理する方法に注視する必要があります。<br>基本的な概念や原則：<br>Cloud Spanner：Google Cloudのフルマネージドでグローバル規模のリレーショナルデータベースサービスです。優れたスケーラビリティと整合性を持ち、クエリパフォーマンスも高いです。<br>ローディングパターン：Cloud Spannerのパフォーマンスは、データのローディングパターンによって異なります。最適なパフォーマンスを得るためには、特定のローディングパターンを持つテーブルの設計やローディングが重要です。<br>CPU使用率：Cloud Spannerでのリソース使用の一部として、CPU使用率があります。この値が高いとパフォーマンスに影響する可能性があるため、監視と適切な対応が必要です。<br>Cloud Monitoring：Google Cloudの監視ツールです。アプリケーションやサービスのパフォーマンスを確認し、異常な動作やリソース使用のトラッキングが可能です。<br>アラート：Cloud Monitoringで設定可能な通知です。特定の指標が設定した閾値を超えた場合に送られます。CPU使用率が高い場合の対応など、異常の早期発見に役立ちます。<br>CPU使用率の閾値：CPU使用率が一定の閾値を超えた場合に対応が必要になります。Googleのベストプラクティスでは、優先度の高いCPU使用率が65%に到達したときに対応を行うことを推奨しています。<br>Spannerノードの追加：Cloud Spannerのパフォーマンスを向上させる方法の一つです。ワークロードの増加に対応して、必要な場合にノードを追加します。<br>正解についての説明：<br>（選択肢）<br>・Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率の割合が65%に達したときにアラートを出します。この閾値を超えた場合は、インスタンスにノードを追加します<br>この選択肢が正解の理由は以下の通りです。<br>Cloud Spannerのパフォーマンスは、使用しているノードの数やCPUの使用率に大きく影響を受けます。<br>したがって、クエリのパフォーマンスを最適化するためには、これらの要素を適切に管理する必要があります。本問題では、まずCloud Monitoringを用いてCPU使用率にアラートを設定しています。これは、Cloud Spannerのパフォーマンス監視において重要なステップとなります。Cloud MonitoringによってCPU使用率がある閾値を超えた場合にアラートが発生し、それをトリガーにしてノードを追加することで、読み取りと書き込みのスループットが向上し、結果的にクエリパフォーマンスが改善します。<br>また、Googleのベストプラクティスでは、Cloud SpannerのCPU使用率を65％未満に保つことが推奨されています。したがってこの選択肢は、ベストプラクティスにも従った最適な改善策です。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率の割合が45%に達したときにアラートを出します。この閾値を超えた場合は、インスタンスにノードを追加します<br>この選択肢が正しくない理由は以下の通りです。<br>CPU使用率が45%に達した時点でノードを追加すると、リソースの使いすぎとなり、費用効率が悪くなります。GoogleのベストプラクティスはCPUの高負荷状態が65%に達した時にアラートを出すことです。そのためこの選択肢は効率的ではありません。<br>選択肢：Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率が45%に達したときにアラートを出します。データベースのクエリ統計を使用して、CPU使用率が高いクエリを特定し、それらのクエリを書き換えてリソース使用率を最適化します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud SpannerはCPU使用率が65%を超えるとパフォーマンスが低下するため、45%でアラートを設定すると過度に敏感に反応し、早急に手を打つ必要はない場合でも無駄にリソースを増やす可能性があります。<br>また、クエリの書き換えは時間をかけるため、"最短時間でパフォーマンスを改善する"要求に合いません。<br>選択肢：Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率が65%に達したときにアラートを出します。データベースのクエリ統計を使用して、CPU使用率が高いクエリを特定し、それらのクエリを書き換えてリソース使用率を最適化します<br>この選択肢が正しくない理由は以下の通りです。<br>問題文では即時のパフォーマンス改善が必要とされていますが、クエリを特定し書き換えるというアプローチはすぐにパフォーマンスを改善するものではありません。これには開発とテストの時間が必要で効率的ではありません。<br>対照的に、ノードを追加するアプローチは即座にパフォーマンスを改善します。'>
<div class='choice'> Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率の割合が45%に達したときにアラートを出します。この閾値を超えた場合は、インスタンスにノードを追加します</div>
<div class='choice'> Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率の割合が65%に達したときにアラートを出します。この閾値を超えた場合は、インスタンスにノードを追加します</div>
<div class='choice'> Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率が65%に達したときにアラートを出します。データベースのクエリ統計を使用して、CPU使用率が高いクエリを特定し、それらのクエリを書き換えてリソース使用率を最適化します</div>
<div class='choice'> Cloud Monitoringでアラートを作成し、優先度の高いCPU使用率が45%に達したときにアラートを出します。データベースのクエリ統計を使用して、CPU使用率が高いクエリを特定し、それらのクエリを書き換えてリソース使用率を最適化します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題61<br>本番プロジェクトと開発プロジェクトの両方にアクセスできるGoogle Cloudアカウントを持っています。開発プロジェクトと本番プロジェクトのすべてのコンピュートインスタンスを毎日リストする自動化プロセスを作成する必要があります。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「gcloud configを使用して、2つのコンフィギュレーションを作成します。コンフィギュレーションを個別にアクティブに設定するスクリプトを書きます。各構成について、gcloud compute instances listを使用してコンピュートリソースのリストを取得します」です。<br>この問題では、Google Cloudアカウントを使用して本番環境と開発環境の両方のコンピュートインスタンスを毎日自動的にリスト化するための方法を設定することを求めています。解決策はGoogle Cloudの管理ツールとスクリプティングを適切に組み合わせることで実現します。この問題を解く際には、Google Cloudの各種ツールの機能とロールを理解し、それらを使用して具体的な需要に適したスクリプトを構想することが求められます。この問題では、明確な要求とは異なる解答選択肢が提示されている可能性もあるので、そのような選択肢を識別し、適切な手法の選択に集中することが重要です。<br>基本的な概念や原則：<br>gcloud：Google Cloudのコマンドラインツールです。開発者はこのツールを使用してGoogle Cloudのリソースやアプリケーションを管理します。<br>gcloud config：gcloudツールの設定を管理するコマンドです。ユーザーはこれを使用して複数のプロジェクトやアカウントを切り替えるための環境設定を行うことができます。<br>gcloud compute instances list：gcloudコマンドの一部で、現在稼働中のCompute Engineインスタンスの一覧を出力します。<br>gsutil：Google Cloud Storageと対話するためのコマンドラインツールです。gsutil configにはCompute Engineインスタンスの情報を出力する能力はありません。<br>Cloud Shell：クラウド上のシェル環境です。クラウドの監査可能なログを作成したり、Google Cloudコマンドラインツールを使用したりすることができますが、自動化プロセスの作成には向いていません。<br>Google Cloud Console：Google Cloudのサービスを管理するためのWebベースのユーザーインターフェースです。適切なAPI呼び出しを行うことで、リソース情報をエクスポートすることは可能ですが、毎日の自動化プロセスの作成には向いていません。<br>正解についての説明：<br>（選択肢）<br>・gcloud configを使用して、2つのコンフィギュレーションを作成します。コンフィギュレーションを個別にアクティブに設定するスクリプトを書きます。各構成について、gcloud compute instances listを使用してコンピュートリソースのリストを取得します<br>この選択肢が正解の理由は以下の通りです。<br>まず、gcloud configを使用することで、複数のGoogle Cloudプロジェクトを一つのアカウントで管理することができます。各プロジェクトに対する設定の一組を作成し、それらを切り替えながら作業を行うための強力な手段です。<br>したがって、開発プロジェクトと本番プロジェクトという二つの異なるプロジェクトに対して一つのアカウントからアクセスするためには、この機能が必要です。<br>また、各構成を個別にアクティブに設定するスクリプトを作成することで、各プロジェクトに所属するコンピュートインスタンスのリストを取得するプロセスを、自動的かつスムーズに行うことができます。<br>そして、gcloud compute instances listを使用することで、特定のプロジェクトのコンピュートリソースの一覧を取得することができます。よって、これらの作業を実装することで、問題の要件を満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：gsutil configを使用して、2つのコンフィギュレーションを作成します。それぞれのコンフィギュレーションをアクティブに設定するスクリプトを書きます。各構成について、gsutil compute instances listを使用して、計算リソースのリストを取得します<br>この選択肢が正しくない理由は以下の通りです。<br>gsutilはCloud Storageとのやりとりに使用するツールであり、Compute Engineのインスタンスに関する操作を行うにはgcloudコマンドが適切です。<br>したがって、gsutil configとgsutil compute instances listは存在しないので、この選択肢は不正確です。<br>選択肢：Cloud Shellにアクセスし、この情報を毎日Cloud Storageにエクスポートします<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Shellを使って情報をエクスポートする手順だけでは、本番プロジェクトと開発プロジェクトから毎日自動的にコンピュートインスタンスのリストを取得する自動化プロセスの要件を満たしません。<br>また、正解選択肢と比べて、Cloud Shellを使う選択肢は2つのプロジェクト間でスイッチングできない点も問題です。<br>選択肢：Google Cloud Consoleにアクセスし、この情報を毎日Cloud SQLにエクスポートします<br>この選択肢が正しくない理由は以下の通りです。<br>まず、Google Cloud Consoleを通じたエクスポートは自動化することが困難です。<br>また、Cloud SQLは用途に合わず、インスタンスのリストを取得するには &#39;gcloud&#39; コマンドを利用したスクリプトの使用が適切です。そのため、この選択肢は要件を満たしません。'>
<div class='choice'> Cloud Shellにアクセスし、この情報を毎日Cloud Storageにエクスポートします</div>
<div class='choice'> Google Cloud Consoleにアクセスし、この情報を毎日Cloud SQLにエクスポートします</div>
<div class='choice'> gcloud configを使用して、2つのコンフィギュレーションを作成します。コンフィギュレーションを個別にアクティブに設定するスクリプトを書きます。各構成について、gcloud compute instances listを使用してコンピュートリソースのリストを取得します</div>
<div class='choice'> gsutil configを使用して、2つのコンフィギュレーションを作成します。それぞれのコンフィギュレーションをアクティブに設定するスクリプトを書きます。各構成について、gsutil compute instances listを使用して、計算リソースのリストを取得します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題62<br>あなたは10人の開発者グループのチームリーダーです。あなたは、Google Cloudのさまざまなソリューションを試すための個人的なサンドボックスとして使用できる個別のGoogle Cloudプロジェクトを各開発者に提供しました。開発者の誰かがサンドボックス環境に毎月500ドル以上費やしている場合、あなたは通知を受けたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「プロジェクトごとに予算を作成し、これらの予算すべてに予算アラートを設定します」です。<br>この問題では、複数の開発者がGoogle Cloudプロジェクトを個々に使用して実験を行い、その実験に発生するコストを監視し、一定の額を超えた際に通知を受け取るというシナリオを想定しています。解答を選ぶ際に重要な要素は、予算の設定方法とそれに伴うアラートの設定です。各開発者が個別にプロジェクトを運用しているため、各プロジェクトごとに予算設定を行うことが必要になります。また、特定の金額を超えた際に通知を受け取るためのアラート設定も重要です。この要件から考えると、予算とアラートをプロジェクトごとに設定する解答が正しいと考えられます。<br>基本的な概念や原則：<br>Google Cloudプロジェクト：Google Cloudリソースを組織化、管理するためのフレームワークです。各プロジェクトは設定、権限、課金の情報を共有します。<br>予算機能：Google Cloudのコスト管理ツールです。特定のサービスやプロジェクトの支出について予算を設定し、その予算を超えた場合にアラートを送信します。<br>予算アラート：Google Cloud Billingで設定できる機能です。予算の閾値に達したときに電子メールで通知が送信されます。<br>課金アカウント：Google Cloudの課金に関する情報と設定を管理するアカウントです。1つの課金アカウントは複数のプロジェクトと関連付けることができます。<br>BigQuery課金エクスポート：Google Cloudの課金データをBigQueryにエクスポートする機能です。詳細なコスト分析やレポート作成に使用できます。<br>Data Studio：Googleのビジュアル解析ツールです。データを視覚的に探索し、インサイトを共有することができます。<br>正解についての説明：<br>（選択肢）<br>・プロジェクトごとに予算を作成し、これらの予算すべてに予算アラートを設定します<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloudでは、プロジェクトごとに支払いに対する予算を設定することができます。これにより、特定のプロジェクトが使用できる資金の上限を制御することができます。<br>したがって、各開発者へのプロジェクト提供というシナリオでは、プロジェクトごとの予算設定が有用であり、各開発者が許容範囲内の費用で留まることを保証します。<br>さらに、"予算アラート"を設定することで、予算が一定の閾値まで使い果たされたときに通知を受けることが可能になります。この設定を行うことで、開発者のどのプロジェクトが毎月500ドル以上の費用を発生させた場合に、プロンプトに警告を受けることができます。<br>不正解の選択肢についての説明：<br>選択肢：すべてのプロジェクトに対して単一の予算を作成し、この予算に対して予算アラートを設定します<br>この選択肢が正しくない理由は以下の通りです。<br>単一の予算をすべてのプロジェクトに適用すると、個々のプロジェクトが500ドル以上費やしたかどうかを特定することは不可能になります。予算とアラートはプロジェクト単位で個別に設定する必要があります。<br>選択肢：サンドボックスプロジェクトごとに個別の課金アカウントを作成し、BigQuery課金エクスポートを有効にします。Data Studioダッシュボードを作成して、課金アカウントごとの支出をプロットします<br>この選択肢が正しくない理由は以下の通りです。<br>プロジェクトごとに個別の課金アカウントを作成すると管理負荷が高まります。<br>また、このアプローチではリアルタイムの通知が行えず、500ドルを超えたときにすぐに知ることができません。<br>一方、予算アラートを設定すると、指定した閾値を超えたときにリアルタイムで通知が行われるため、要件をより効果的に満たします。<br>選択肢：すべてのサンドボックスプロジェクトに対して単一の課金アカウントを作成し、BigQuery課金エクスポートを有効にします。Data Studioダッシュボードを作成して、プロジェクトごとの支出をプロットします<br>この選択肢が正しくない理由は以下の通りです。<br>BigQuery課金エクスポートとData Studioダッシュボードを使用しても、開発者の誰かがサンドボックス環境に毎月500ドル以上費やした場合の自動通知機能は提供できません。代わりに手動でダッシュボードをチェックする必要があります。これは、予算アラートを設定することで自動通知を受ける正解の方法と比べて非効率的です。'>
<div class='choice'> すべてのプロジェクトに対して単一の予算を作成し、この予算に対して予算アラートを設定します</div>
<div class='choice'> すべてのサンドボックスプロジェクトに対して単一の課金アカウントを作成し、BigQuery課金エクスポートを有効にします。Data Studioダッシュボードを作成して、プロジェクトごとの支出をプロットします</div>
<div class='choice'> サンドボックスプロジェクトごとに個別の課金アカウントを作成し、BigQuery課金エクスポートを有効にします。Data Studioダッシュボードを作成して、課金アカウントごとの支出をプロットします</div>
<div class='choice'> プロジェクトごとに予算を作成し、これらの予算すべてに予算アラートを設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題63<br>あなたは複数のGoogle Cloudプロジェクトを管理しており、過去60日間のすべてのログにアクセスする必要があります。ログの内容を調べ、すばやく分析できるようにしたいと考えています。Googleが推奨するプラクティスに従って、すべてのプロジェクトのログを取得する必要があります。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「BigQueryデータセットへのSink宛先でCloud Logging Exportを作成します。テーブルの有効期限を60日に設定します」です。<br>この問題では、Google Cloudでログ管理を行う際の最適な方法について問われています。大量のログデータを60日間保存し、分析可能な形式で利用することが目的です。要件を満たす最善の方法として、Google Cloudが提供する様々なサービスをいかに組み合わせて使用するかを検討する必要があります。BigQuery, Cloud Logging, Cloud StorageやCloud Schedulerなど、各サービスの特性を理解し、それぞれが提供する機能を充分に活用することが重要です。また、Googleが推奨するベストプラクティスの適用も求められています。<br>基本的な概念や原則：<br>Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムの動作を監視・診断するために必要なログデータを一元的に管理・分析することができます。<br>クラウドログエクスポート：Cloud Loggingからのログデータを他のGoogle Cloudサービスへエクスポートする機能です。BigQuery、Cloud Storage、Pub/Subなどのサービスにエクスポートすることができます。<br>BigQuery：Google Cloudのフルマネージドな大規模データ分析サービスです。SQL構文を用いて大量のデータを高速に分析することができます。<br>シンク（Sink）：ログデータの出力先を指定する設定のことです。Cloud Loggingでは、BigQuery、Cloud Storage、Pub/Subにシンクを設定することができます。<br>テーブルの有効期限：BigQueryで設定する、テーブルデータの保持期間のことです。設定した期間が経過すると、テーブルデータは自動的に削除されます。<br>ライフサイクルルール：Cloud Storageで設定する、オブジェクトの保存期間や保存条件のことです。設定した条件に従って、オブジェクトの保存・削除が自動的に行われます。<br>Cloud Scheduler：Google Cloudのジョブスケジューラーサービスです。定期的または特定のタイミングでHTTPリクエストやCloud Pub/Subメッセージの送信などのジョブを自動的に実行することができます。<br>正解についての説明：<br>（選択肢）<br>・BigQueryデータセットへのSink宛先でCloud Logging Exportを作成します。テーブルの有効期限を60日に設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud Loggingはプロジェクトのログデータを統合管理するサービスで、ログデータを分析に有用な形で蓄積できます。その一方、BigQueryは大量のデータを高速に分析することが可能なフルマネージド型のデータウェアハウスです。<br>この要件では過去60日間のすべてのログを確認し、分析することが求められています。そのため、Cloud Loggingの"Export"機能を使ってログデータをBigQueryにエクスポートすることを考えると、処理が効率的になります。<br>このとき、"Sink"を設定することで特定の条件に一致するエントリを自動的にエクスポートできるので、管理が容易になります。またテーブルの有効期限を60日に設定すれば、過去60日間のログだけを保持することも可能になります。<br>これらの理由から"BigQueryデータセットへのSink宛先でCloud Logging Exportを作成します。テーブルの有効期限を60日に設定します"が、この場合の最適な方法です。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Loggingに移動し、resource.labels.project_id="*"を選択します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Loggingを直接使用すると、過去のログを60日間全て保存することはできません。<br>また、すばやく分析することも難しくなります。反対に、BigQueryデータセットへのエクスポートを使用すると、ログの長期保管と迅速な分析が可能になります。<br>選択肢：Cloud Logging Exportを作成し、Cloud Storageへのシンク先を指定します。60日後にオブジェクトを削除するライフサイクルルールを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Storageへのエクスポートはログの保存には有用ですが、すばやく分析するためには最適ではありません。<br>それに対して、BigQueryは大量のデータを即座に分析するための設計がされているので、ログ分析要件をより効率的に満たします。<br>選択肢：Google Cloud Operations Suiteから読み取り、ログをBigQueryに保存するようにCloud Schedulerジョブを構成します。テーブルの有効期限を60日に設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Schedulerを利用して手動でログを正確なタイミングで取得しBigQueryに保存するという設定は、効率的ではなく、管理も煩雑になります。Cloud Logging Exportは自動的にログの取得と保存を行うため、より推奨される方法です。'>
<div class='choice'> Cloud Logging Exportを作成し、Cloud Storageへのシンク先を指定します。60日後にオブジェクトを削除するライフサイクルルールを作成します</div>
<div class='choice'> Cloud Loggingに移動し、resource.labels.project_id="*"を選択します</div>
<div class='choice'> BigQueryデータセットへのSink宛先でCloud Logging Exportを作成します。テーブルの有効期限を60日に設定します</div>
<div class='choice'> Google Cloud Operations Suiteから読み取り、ログをBigQueryに保存するようにCloud Schedulerジョブを構成します。テーブルの有効期限を60日に設定します</div>
</div>
            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>