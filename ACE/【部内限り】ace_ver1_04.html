<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Cloud Leader問題集 04</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="quiz-container">
        <div id="quiz-data" style="display: none;">
<div class='question' data-multiple='FALSE' data-question='問題16<br>あなたは新しいアプリケーションを開発しており、ソースコードをビルドしてデプロイするためのJenkinsのインストール方法を探しています。あなたは、できるだけ迅速かつ簡単にインストールを自動化したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「Google Cloud Marketplaceを通じてJenkinsをデプロイします」です。<br>この問題では、あなたが新しいアプリケーションの開発を進めており、ソースコードのビルドとデプロイのためにJenkinsを使用することを決定した状況を想定しています。特に、インストールをなるべく迅速かつ簡単に自動化したい、という要件が指定されています。選択肢を見る際には、この要件に合致する手法を選ぶことが重要です。Jenkinsをどのようにセットアップするのか、そのプロセスが迅速で簡単にできるか、そしてそれが自動化可能なのか、という観点で各選択肢を検討するべきです。<br>基本的な概念や原則：<br>Google Cloud Marketplace：サードパーティーのソフトウェアやサービスを提供するプラットフォームです。Jenkinsなど、一般的な開発ツールの準備済みのセットアップを提供しています。<br>Jenkins：オープンソースの自動化サーバです。ビルド、テスト、デプロイなどのプロセスを自動化するために使用されます。<br>Compute Engine：Google Cloudの仮想マシンを提供するサービスです。柔軟な仮想マシンの設定と自動スケーリングが可能です。<br>Kubernetes Engine：Google Cloud上でコンテナ化されたアプリケーションを実行するためのマネージドサービスです。高度なスケーリングと管理機能を提供します。<br>インスタンステンプレート：Compute Engineで利用される仮想マシンの設定を定義するテンプレートです。これにより、同じ設定で複数のインスタンスを迅速にデプロイすることができます。<br>マネージドインスタンスグループ：Compute Engine内で定義したインスタンステンプレートを基に、同じ設定のインスタンスをグループとして管理するサービスです。自動スケーリングやロードバランシングなどに対応しています。<br>正解についての説明：<br>（選択肢）<br>・Google Cloud Marketplaceを通じてJenkinsをデプロイします<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloud Marketplaceは、多くのアプリケーションや開発ツール、データベースなどのソフトウェアを簡単にデプロイできるワンストップショップのような存在です。これには、JenkinsのようなCI/CDツールも含まれています。Google Cloud Marketplaceを利用すると、必要なソフトウェアを選び、数回のクリックでデプロイすることができます。これにより迅速で簡単なインストールが可能です。<br>また、Google Cloud Marketplaceを通じてデプロイしたソフトウェアは、Google Cloudのすべてのリージョンで動作し、Googleのセキュリティとコンプライアンスのスタンダードに準拠しています。<br>従って、Google Cloud Marketplaceを通じてJenkinsをデプロイすると、指定した要件を満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：新しいCompute Engineインスタンスを作成します。Jenkinsの実行ファイルを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>新たにCompute Engineインスタンスを作成しJenkinsを手動で実行するという方法は、時間も手間もかかり、迅速・簡単な自動化インストールには向きません。<br>一方、Google Cloud Marketplaceを利用すると、Jenkinsのデプロイが簡易化されるためすばやく実装することができます。<br>選択肢：新しいKubernetes Engineクラスターを作成します。Jenkinsイメージのデプロイメントを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>新しいKubernetes Engineクラスターを作成してJenkinsイメージのデプロイメントを作成すると、設定やメンテナンスに手間がかかり、迅速かつ簡単なインストールを求める要件に合致しません。<br>それに対して、Google Cloud Marketplaceを通じてJenkinsをデプロイする方がその要件に適しています。<br>選択肢：Jenkins実行ファイルでインスタンステンプレートを作成します。このテンプレートでマネージドインスタンスグループを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンステンプレートでJenkins実行ファイルを作成し、そのテンプレートでマネージドインスタンスグループを作成する方法は、手間がかかり、迅速なインストールを実現するには不向きです。<br>それに対して、Google Cloud Marketplaceを通じてJenkinsをデプロイする方法は、数クリックで簡単にJenkinsインスタンスが立ち上がり、要件を満たす最善の方法です。'>
<div class='choice'> 新しいKubernetes Engineクラスターを作成します。Jenkinsイメージのデプロイメントを作成します</div>
<div class='choice'> Google Cloud Marketplaceを通じてJenkinsをデプロイします</div>
<div class='choice'> Jenkins実行ファイルでインスタンステンプレートを作成します。このテンプレートでマネージドインスタンスグループを作成します</div>
<div class='choice'> 新しいCompute Engineインスタンスを作成します。Jenkinsの実行ファイルを実行します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題17<br>あなたは、Deployment Managerを使用してGoogle Kubernetes Engineクラスターを作成しています。同じDeployment Managerデプロイメントを使用して、クラスターのkube-systemネームスペースにDaemonSetを作成します。また、可能な限り少ないサービスを使用するソリューションが必要です。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「クラスターのAPIをDeployment Managerの新しいタイププロバイダとして追加し、新しいタイプを使用してDaemonSetを作成します」です。<br>この問題では、Google Kubernetes Engineクラスターとそのkube-systemネームスペースにDaemonSetを作成するための最適な手法が問われています。Deployment Managerを使用してこれらのタスクを実行する必要があり、可能な限り少ないサービスを使用して解決策を見つけることが求められています。そのため、Deployment Managerが直接サポートしている機能や、それが統合されているGoogle Cloudの他のサービスをうまく利用することが重要です。しかし、不必要なまたは複雑なサービスを避けるためにも、Deployment Managerとそれが操作するリソースの間の明確な関係性に注意しながら問題に取り組む必要があります。<br>基本的な概念や原則：<br>Deployment Manager：Google Cloudのインフラストラクチャのデプロイメントを自動化するサービスです。テンプレートを使用してリソースをモデル化し、それらを一括して操作することができます。<br>Google Kubernetes Engine（GKE）：Google CloudのフルマネージドKubernetesサービスです。アプリケーションのデプロイ、スケーリング、運用を簡易化します。<br>kube-systemネームスペース：Kubernetesのシステムコンポーネントを保持する特別なネームスペースです。Kubernetesシステムが正常に動作するためのリソース（DaemonSetなど）が存在します。<br>DaemonSet：Kubernetesにおいて、すべての（または一部の）ノード上でポッドのコピーを実行するためのリソースです。ノードがクラスターに追加されると、ポッドがノードにスケジュールされます。<br>タイププロバイダ：Deployment Managerにおいて、特定のAPIやサービスを操作するためのエンドポイントです。新しいAPIを追加し、そのAPI特有のリソースをデプロイできます。<br>Runtime Configurator：Dynamicな設定情報を管理するサービスで、デプロイメントプロセス中に変更可能な設定を保存します。しかし、DaemonSetの作成には不適切です。<br>kubectl：KubernetesのCLIツールで、Kubernetesクラスターの管理に使用します。Deployment Managerとは別サービスのため、ここでは次善の策です。<br>正解についての説明：<br>（選択肢）<br>・クラスターのAPIをDeployment Managerの新しいタイププロバイダとして追加し、新しいタイプを使用してDaemonSetを作成します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Deployment ManagerはGoogle Cloudのサービスのデプロイメントと管理を自動化するためのインフラストラクチャ管理サービスであり、全体的なシステム設計をテンプレート化し、再利用可能な設計を作成します。この特性が問題の要件、つまり同一のDeployment Managerデプロイメントでkube-systemネームスペースにDaemonSetを作成するための要件を満たします。<br>その上で、Type ProviderはDeployment ManagerがAPIを理解し、リソースを作成、更新、削除するための仕組みであり、具体的にはAPIからの入力と出力をフィールドにマッピングします。つまり、クラスターのAPIを新しいType Providerとして追加することでDeployment ManagerがGoogle Kubernetes Engine（GKE）クラスターAPIと通信し、リソースを作成、更新、削除することが可能になります。このType Providerを用いてDaemonSetを作成することで、要件に記載されている、可能な限り少ないサービスを使用するという条件も満たすことが可能になります。<br>不正解の選択肢についての説明：<br>選択肢：Deployment Manager Runtime Configuratorを使用して、DaemonSet定義を含む新しいConfigリソースを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Deployment Manager Runtime Configuratorは、設定パラメータを集中的に管理するためのツールであり、Deployment Managerで直接リソースを作成する機能はありません。したがってDaemonSetの作成には不適切です。<br>逆に、正解の選択肢のようにタイププロバイダを追加すれば、Deployment Managerから直接Kubernetesリソースを作成できます。<br>選択肢：Deployment Managerで、kubectlを使用してDaemonSetを作成する起動スクリプトを使用して、Compute Engineインスタンスを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Deployment ManagerでCompute Engineインスタンスを作成してkubectlを使用してDaemonSetを作成する方法は、必要なサービスの数を増やすことになり、ソリューションが必要としている"可能な限り少ないサービスを使用する"要件を満たしません。<br>また、正解の選択肢はDeployment Managerだけを使用してクラスターとDaemonSetを作成しており、よりシンプルで効率的な手法です。<br>選択肢：Deployment Managerのクラスターの定義で、キーとしてkube-system、値としてDaemonSetマニフェストを持つメタデータを追加します<br>この選択肢が正しくない理由は以下の通りです。<br>Deployment Managerのメタデータにkube-systemやDaemonSetマニフェストを直接追加することはできません。Deployment Managerはカスタムタイププロバイダを使用してKubernetesリソースにアクセスするため、直接メタデータの操作ではDaemonSetを作成できません。'>
<div class='choice'> Deployment Managerで、kubectlを使用してDaemonSetを作成する起動スクリプトを使用して、Compute Engineインスタンスを作成します</div>
<div class='choice'> Deployment Managerのクラスターの定義で、キーとしてkube-system、値としてDaemonSetマニフェストを持つメタデータを追加します</div>
<div class='choice'> Deployment Manager Runtime Configuratorを使用して、DaemonSet定義を含む新しいConfigリソースを作成します</div>
<div class='choice'> クラスターのAPIをDeployment Managerの新しいタイププロバイダとして追加し、新しいタイプを使用してDaemonSetを作成します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題18<br>あなたの会社は、複数のマイクロサービスで構成される新しいアプリケーションを開発しました。このアプリケーションをGoogle Kubernetes Engine（GKE）にデプロイし、将来的にデプロイするアプリケーションが増えてもクラスターがスケールできるようにしたいと考えています。また、新しいアプリケーションがデプロイされるたびに手動で介入することは避けたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「アプリケーションをGKEにデプロイし、デプロイメントにHorizontalPodAutoscalerを追加します」です。<br>この問題では、Google Kubernetes Engine（GKE）を使用して管理される新しいマイクロサービスアプリケーションをデプロイし、管理する方法を問われています。また、手動介入なしでアプリケーションをスケールアップできるソリューションを探しています。ここで重要なのは、問題がアプリケーションレベルでの自動的なスケーリングを希望しているという点で、GKEのクラスターまたはノードレベルのスケーリングではないということです。選択肢を評価する際には、アプリケーションのスケーリングと管理の自動化に対応したものを探す必要があります。<br>基本的な概念や原則：<br>Google Kubernetes Engine（GKE）：Google CloudにおけるKubernetes環境を提供するマネージドサービスです。クラスター管理、ローリングアップデート、セキュリティ設定などの機能を持ちます。<br>マイクロサービス：単一の大規模なアプリケーションを、具体的で独立した小規模なサービスに分解して開発・運用するアーキテクチャスタイルです。各サービスは独立してスケールやデプロイが可能です。<br>HorizontalPodAutoscaler（HPA）：Kubernetesにおいて、CPU利用率などのメトリクスを元にポッドの数を自動的にスケールさせる機能です。ワークロードの増大に応じてポッドを増減できるので、手動による介入を減らすことができます。<br>VerticalPodAutoscaler：Kubernetesにおいて、各ポッドのリソース要求（CPU、メモリ）を自動的に調整する機能です。ただし、CPUやメモリの要求を増加させるとポッドは再起動する必要があります。<br>ノードプール：GKEクラスター内で共通の設定を持つノード（仮想マシン）のグループです。各ノードプールは独自のサイズ、タイプ、オペレーティングシステムなどの設定を持つことができます。<br>正解についての説明：<br>（選択肢）<br>・アプリケーションをGKEにデプロイし、デプロイメントにHorizontalPodAutoscalerを追加します<br>この選択肢が正解の理由は以下の通りです。<br>HorizontalPodAutoscaler（HPA）は、クラスターのCPU使用率やその他の定義されたメトリクスに基づいて、Kubernetes（k8s）のポッドの数を自動的に増減させる機能を提供します。アプリケーションが運用環境で増負荷に遭遇した場合、"HorizontalPodAutoscaler"が負荷に柔軟に対応しスケールすることで、アプリケーションのパフォーマンスを維持することができます。<br>また、新規アプリケーションのデプロイ時に、"HorizontalPodAutoscaler"を設定することで、その後の負荷増によるスケールアウトや負荷減少によるスケールインが自動的に行われ、手動で介入する必要がなくなります。<br>したがって、"アプリケーションをGKEにデプロイし、デプロイメントにHorizontalPodAutoscalerを追加します"が正解です。これにより、アプリケーションが増えてもクラスターが自動的にスケールし、手動の介入を最小限に抑えることができます。<br>不正解の選択肢についての説明：<br>選択肢：アプリケーションをGKEにデプロイし、VerticalPodAutoscalerをデプロイに追加します<br>この選択肢が正しくない理由は以下の通りです。<br>VerticalPodAutoscalerはポッドのCPUやメモリリソースの使用量に基づいて自動的にリソースの割り当て量を調整しますが、これは新しいポッドを追加するスケーリングではなく既存のポッド内でのリソース調整を行うものです。<br>一方、HorizontalPodAutoscalerはCPUやメモリ使用量などの指標に基づいてポッドの数を自動的に調節し、クラスターのスケールアウトとスケールインが可能です。つまり、アプリケーションが増えてもクラスターがスケールできるようにするためにはHorizontalPodAutoscalerが適しています。<br>選択肢：ノードプールでオートスケーリングを有効にしてGKEクラスターを作成します。ノードプールのサイズの最小値と最大値を設定します<br>この選択肢が正しくない理由は以下の通りです。<br>ノードプールでオートスケーリングを有効にするとGKEクラスターは確かにスケールしますが、新たにアプリケーションがデプロイされるたびに手動で介入しなければならない問題は解決しません。<br>それに対して、HorizontalPodAutoscalerを使用すると、アプリケーションのデプロイメント時に自動的にスケーリングが行われるため、手動介入を避けることが可能になります。<br>選択肢：アプリケーションごとに個別のノードプールを作成し、各アプリケーションを専用のノードプールにデプロイします<br>この選択肢が正しくない理由は以下の通りです。<br>アプリケーションごとに個別のノードプールを作成すると、新しいアプリケーションがデプロイされるたびに手動で介入が必要となり、要件に反します。<br>また、スケーリングの柔軟性も損なわれます。<br>一方、HorizontalPodAutoscalerを使用すると、資源使用量に基づき自動的にポッド数を調整し、スケーラビリティと手間削減の両方を実現します。'>
<div class='choice'> アプリケーションをGKEにデプロイし、デプロイメントにHorizontalPodAutoscalerを追加します</div>
<div class='choice'> アプリケーションをGKEにデプロイし、VerticalPodAutoscalerをデプロイに追加します</div>
<div class='choice'> ノードプールでオートスケーリングを有効にしてGKEクラスターを作成します。ノードプールのサイズの最小値と最大値を設定します</div>
<div class='choice'> アプリケーションごとに個別のノードプールを作成し、各アプリケーションを専用のノードプールにデプロイします</div>
</div>
<div class='question' data-multiple='true' data-question='問題19<br>あなたは、何千ものサプライヤーからアップロードされたデータファイルを処理するアプリケーションを構築しています。アプリケーションは、データのセキュリティと古いデータの有効期限を正しく管理するこ必要があります。また、以下のようにアプリケーションを設計する必要があります：<br>- サプライヤーが自分のデータのみにアクセスできるように、アクセスを制限します。<br>- サプライヤーが自分自身のデータのみにアクセスできるようにアクセスを制限します。<br>- 45日以上経過したデータは削除します。<br>あなたは非常に短い開発サイクルを持っており、アプリケーションが最小限のメンテナンスを必要とすることを確認する必要があります。<br>どの2つの戦略を使うべきですか？（2つ選択）' data-answer='1, 4' data-explanation='解説<br>正解は以下の通りです。<br>・Cloud Storageオブジェクトを45日後に削除するライフサイクルポリシーを構築します<br>・署名されたURLを使用し、サプライヤーがオブジェクトを保存するための期間限定アクセスを許可します<br>この問題では、大量のデータファイルを効率的に管理し、それぞれのサプライヤーに適切なアクセス制限を持たせ、45日経過したデータを自動で削除するための戦略を求められています。要点はデータの安全な管理、アクセス制御、データのライフサイクル管理です。特に、開発サイクルが短く、メンテナンスを最小限に抑える必要があるという情報から、可能な限りコードの無駄を省き、自動化とスケーラビリティが実現できる方法を採用することが重要です。そのためにGoogle Cloudの各種サービスを適切に利用することが鍵です。<br>基本的な概念や原則：<br>Cloud Storage：Google Cloudの拡張可能なオブジェクトストレージサービスです。それぞれのオブジェクトはバケット内に保存されます。<br>ライフサイクルポリシー：Google Cloud Storageの機能で、オブジェクトの寿命を管理します。特定の条件に基づいてオブジェクトを自動的に削除したり、ストレージクラスを変更したりします。<br>署名されたURL：Google Cloud Storageの機能で、特定の期間、特定のユーザーのみにオブジェクトへのアクセスを許可します。<br>アクセス制御：誰がどのリソースにアクセスできるかを管理するセキュリティの一部です。<br>SFTPサーバー：セキュアなファイル転送プロトコルを使用したサーバー。ユーザーごとにアクセスを管理することができますが、設定と管理が複雑になる可能性があります。<br>Cloud Functions：Google Cloudのサーバレス実行環境で、特定のイベントに基づいて自動的に実行されます。オブジェクトの削除などのタスクを自動化するのに適していますが、ライフサイクルポリシーと比べると管理が必要な部分が多いです。<br>正解についての説明：<br>（選択肢）<br>・Cloud Storageオブジェクトを45日後に削除するライフサイクルポリシーを構築します<br>・署名されたURLを使用し、サプライヤーがオブジェクトを保存するための期間限定アクセスを許可します<br>この選択肢が正解の理由は以下の通りです。<br>まず、データの有効期限については、Cloud Storageのライフサイクルポリシーを使用すると、特定の条件に基づいてオブジェクトを自動的に削除することができます。具体的には、ライフサイクルポリシーを作成し、それを45日後にデータを削除するように設定すれば、ストレージ上の古いデータの管理を自動化できます。これにより、アプリケーションのメンテナンスが最小限になり、開発サイクルを短く保つことができます。<br>次に、サプライヤーが自分のデータのみにアクセスできるようにするために、署名されたURLを使用するのが適切です。署名されたURLは、Cloud Storageの特定のオブジェクトへの一時的なアクセスを提供します。これにより、サプライヤーが自分のデータのみを保存、取得、削除するための一時的なリンクを生成できます。これもまた、セキュリティを確保しつつ、アプリケーションのメンテナンスを最小限に抑える戦略です。<br>不正解の選択肢についての説明：<br>選択肢：アプリケーション用にSFTPサーバーをセットアップし、サプライヤーごとに個別のユーザーを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>SFTPサーバーの設定やユーザー管理はメンテナンスが必要であり、問題のアプリケーションが最小限のメンテナンスを要求している要件に反します。<br>また、45日以上経過したデータの自動削除機能の実装も難しいでしょう。これに対して正解の選択肢はGoogle Cloudの機能を活用してこれらの課題を解決しています。<br>選択肢：期限切れのオブジェクトを削除する45日間のタイマーをトリガーするCloud Functionsを構築します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Functionsを使用して期限切れのオブジェクトを削除すると、メンテナンスが増えて開発サイクルが短い要求に対応できません。対して正解の選択肢では、ライフサイクルポリシーを用いて自動的にオブジェクトを削除するため、ランタイムエラーや管理負荷が少ないです。<br>選択肢：すべてのCloud Storageバケットをループし、45日以上前のバケットを削除するスクリプトを開発します<br>この選択肢が正しくない理由は以下の通りです。<br>スクリプトを開発するとメンテナンス作業が増え、開発サイクルが短い要件に反します。<br>また、古いデータの削除については、Cloud Storageのライフサイクルポリシーを使うほうが簡単かつ効率的です。これにより期間を過ぎたオブジェクトを自動的に削除することができます。'>
<div class='choice'> 期限切れのオブジェクトを削除する45日間のタイマーをトリガーするCloud Functionsを構築します</div>
<div class='choice'> 署名されたURLを使用し、サプライヤーがオブジェクトを保存するための期間限定アクセスを許可します</div>
<div class='choice'> すべてのCloud Storageバケットをループし、45日以上前のバケットを削除するスクリプトを開発します</div>
<div class='choice'> アプリケーション用にSFTPサーバーをセットアップし、サプライヤーごとに個別のユーザーを作成します</div>
<div class='choice'> Cloud Storageオブジェクトを45日後に削除するライフサイクルポリシーを構築します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題20<br>Compute Engine上でVMをプロビジョニングする動的な方法が必要です。正確な仕様は専用の設定ファイルに記載します。あなたはGoogleの推奨するプラクティスに従いたいと考えています。<br>この要件を満たすために、どの方法を使うべきですか？' data-answer='3' data-explanation='解説<br>正解は「Deployment Manager」です。<br>この問題では、正確な仕様に従ったCompute Engine上でのVMプロビジョニングに適したツールを求めています。ここで注意すべき点は、設定ファイルに従った動的なプロビジョニングが必要であることと、Googleの推奨するプラクティスに従いたいということです。選択肢を評価する際には、これらの要点を念頭に置きつつ、Compute Engine上でのVMのプロビジョニングをサポートするツールを選ぶ必要があります。<br>基本的な概念や原則：<br>Deployment Manager：Google Cloudリソースの作成、更新、削除を自動化するインフラストラクチャ管理サービスです。設定ファイルで構成を定義してリソースのプロビジョニングを行います。<br>Compute Engine：Google CloudのIaaS型プラットフォームです。単一のVMや大規模なクラスターまで、様々な規模のコンピューティングワークロードに対応します。<br>プロビジョニング：ITリソースをユーザーが必要とする状態に設定し、配布するプロセスです。ハードウェア、バーチャル化、ソフトウェアなど、様々な種類のリソースに対して行われます。<br>Cloud Composer：Google Cloudのフルマネージドなワークフローオーケストレーションサービスです。Apache Airflowをベースに作られています。<br>マネージドインスタンスグループ：Compute EngineのVMインスタンスを一元管理するためのサービスです。オートスケーリング、ロードバランシングなどの機能が利用できます。<br>アンマネージドインスタンスグループ：個別に制御したいVMインスタンスをまとめて管理するためのサービスです。各VMを個別に設定できますが、オートスケーリングなどは利用できません。<br>正解についての説明：<br>（選択肢）<br>・Deployment Manager<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud Deployment Managerは、Compute Engine上でVMをプロビジョニングするためのインフラストラクチャ管理サービスです。専用の設定ファイル、通常はYAMLまたはJSON形式を使用して、リソースの配置、更新、削除を自動化することができます。Deployment Managerを使用すれば、一貫した環境はもちろんのこと、誤った設定やヒューマンエラーを大幅に減らすことができるため、デプロイメントの効率性と信頼性が向上します。<br>さらに、Deployment ManagerはGoogle Cloudの推奨するプラクティスであり、公式のハンドブックやドキュメンテーションでも参照されています。<br>したがって、Compute Engine上でVMをプロビジョニングする動的な方法として適切です。<br>不正解の選択肢についての説明：<br>選択肢：Cloud Composer<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Composerは主にワークフローやパイプラインの定義、スケジューリング、監視に使用され、Compute Engine上でVMをプロビジョニングするのに使用する動的な方法とは一致しません。<br>一方、Deployment Managerはインフラストラクチャとリソースを自動的に作成・管理するためのサービスであり、これが正しい選択肢です。<br>選択肢：マネージドインスタンスグループ<br>この選択肢が正しくない理由は以下の通りです。<br>マネージドインスタンスグループは、同一設定のVM群をスケールアウトするための機能です。しかし問題は動的なVMプロビジョニングと設定ファイルを用いた方法が求められており、Deployment Managerのテンプレートと設定ファイルを用いて動的かつ柔軟なVMのプロビジョニングを可能にします。<br>選択肢：アンマネージドインスタンスグループ<br>この選択肢が正しくない理由は以下の通りです。<br>アンマネージドインスタンスグループは.Compute Engineインスタンスのグループ管理をサポートする機能ですが、設定ファイルに基づいて自動的にVMをプロビジョニングする機能はありません。<br>それに対して、Deployment Managerは設定ファイルを元にリソースを自動的にプロビジョニングする機能を持っており、必要な要件を満たします。'>
<div class='choice'> アンマネージドインスタンスグループ</div>
<div class='choice'> Cloud Composer</div>
<div class='choice'> マネージドインスタンスグループ</div>
<div class='choice'> Deployment Manager</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題21<br>新しいファイルがCloud Storageのバケットにアップロードされるたびにトリガーされるコードスニペットを作成しました。このコードスニペットをデプロイしたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「Cloud Functionsを使用し、バケットをトリガーリソースとして設定します」です。<br>この問題では、特定のイベント（ここではCloud Storageのバケットへの新規ファイルアップロード）に基づいてコードスニペットを実行するための最適な方法を選択する必要があります。選択肢を検討する際には、選択肢がファイルのアップロードイベントに自動的に反応できるかどうか、またリアルタイムで反応可能かどうかを考慮することが重要です。<br>基本的な概念や原則：<br>Cloud Functions：Google Cloudのスケーラブルなサーバレス実行環境で、特定のイベントによってトリガーされる小規模な独立した関数を記述し、デプロイするためのサービスです。<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスで、あらゆる規模のデータを保存し、取得することができます。<br>トリガーリソース：Cloud Functionsで定義した関数を起動するためのイベントのソースです。Cloud Storageのバケットのような特定のGoogle Cloudリソースを示します。<br>App Engine：Google Cloudのフルマネージドなアプリケーション開発とホスティング平台です。<br>Google Kubernetes Engine：コンテナ化されたアプリケーションをデプロイ、管理、スケールするためのマネージドサービスです。<br>Dataflow：ストリームおよびバッチデータ処理タスクを効率的に実行するためのフルマネージドのデータ処理サービスです。<br>正解についての説明：<br>（選択肢）<br>・Cloud Functionsを使用し、バケットをトリガーリソースとして設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud Functionsはイベント駆動型のコンピューティングソリューションで、特定のイベントに応じて自動的に実行される小さな一連のコードスニペットを作成・デプロイすることができます。与えられたシナリオで、新しいファイルがCloud Storageのバケットにアップロードされるたびにコードスニペットを実行したいというニーズにぴったりな機能を提供しています。具体的には、Cloud Functionsにおいては、Cloud Storageのバケットへのファイルの追加や削除など特定のイベントをトリガーとして設定できます。<br>したがって、Cloud Functionsを利用し、バケットをトリガーリソースとして設定すれば、新たなファイルのアップロードをトリガーにコードスニペットが自動的に実行されます。これにより要件を満たすことができます。<br>不正解の選択肢についての説明：<br>選択肢：App Engineを使用し、Pub/Subを使用してアプリケーションをトリガーするようにCloud Schedulerを構成します<br>この選択肢が正しくない理由は以下の通りです。<br>App Engineは新しいファイルのアップロードを即座にトリガーするためのシステムではありません。<br>さらに、Pub/SubとCloud Schedulerの組み合わせは定期的なタスクを実行するのに適していますが、イベント駆動型のタスク（例えば、新しいファイルのアップロードに対応するタスク）には適していません。<br>それに対して、Cloud Functionsは特定のイベント、この場合はバケットへの新規ファイルのアップロードに対して即座に反応できます。<br>選択肢：Google Kubernetes Engineを使用し、Pub/Subを使用してアプリケーションをトリガーするCronJobを設定します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、この選択肢ではGoogle Kubernetes EngineとCronJobを使用していますが、この方法はファイルアップロードのトリガーではなく、定期的な処理をトリガーします。<br>逆に、Cloud Functionsは特定のイベント、例えばファイルがアップロードされる等をトリガーに関数を実行することができます。<br>選択肢：Dataflowをバッチジョブとして使用し、バケットをデータソースとして設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Dataflowのバッチジョブは一定期間ごとにジョブを実行しますが、新しいファイルがCloud Storageのバケットにアップロードされるたびにトリガーされるコードスニペットを作成するためには、リアルタイムに反応できるCloud Functionsのほうが適しています。'>
<div class='choice'> Dataflowをバッチジョブとして使用し、バケットをデータソースとして設定します</div>
<div class='choice'> App Engineを使用し、Pub/Subを使用してアプリケーションをトリガーするようにCloud Schedulerを構成します</div>
<div class='choice'> Cloud Functionsを使用し、バケットをトリガーリソースとして設定します</div>
<div class='choice'> Google Kubernetes Engineを使用し、Pub/Subを使用してアプリケーションをトリガーするCronJobを設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題22<br>App Engineスタンダード環境でウェブサイトをホストしています。あなたは、1%のユーザーに新しいテストバージョンのウェブサイトを見てもらいたいと考えています。一方で、複雑さを最小限に抑えたいと考えています。<br>あなたはこの要件を満たすために、どうすればよいですか？' data-answer='1' data-explanation='解説<br>正解は「同じアプリケーションに新バージョンをデプロイし、--splitsオプションを使って、現在のバージョンの重みを99、新バージョンの重みを1にします」です。<br>この問題では、App Engineスタンダード環境でウェブサイトを運用した状況で、限定的なユーザー群（1%）に新しいテスト版ウェブサイトを公開する方法について試験対象者の理解が伺われています。また、"複雑さを最小限に抑えたい"という要望もあり、App Engineのバージョン管理、トラフィックの分散管理などの機能を有効に使って、簡素な操作で目的を達成する方法が求められています。以上の要件を考慮に入れて正解の選択肢を探すことが求められます。<br>基本的な概念や原則：<br>App Engineスタンダード環境：Google Cloudのフルマネージド、サーバレスプラットフォームです。アプリケーションを完全にGoogleのインフラストラクチャーで実行し、開発者はインフラストラクチャの管理から解放されます。<br>バージョン管理：App Engineでは、一つのアプリケーション内に複数のバージョンをデプロイすることができます。これにより、新旧のバージョンを同時に実行したり、ユーザーを特定のバージョンに誘導したりすることができます。<br>--splitsオプション：App Engineのgcloudコマンドにおけるオプションです。複数のバージョン間でトラフィックの流入量をコントロールします。<br>--migrateオプション：App Engineのgcloudコマンドにおけるオプションです。既存のバージョンから新バージョンにトラフィックを全面的に移行します。<br>新たなApp Engineアプリケーション作成：新しいバージョンをデプロイするために新しいアプリケーションを作成する方法ですが、不要な複雑性を加える可能性があります。一つのアプリケーション内で複数のバージョンを管理する方が簡単です。<br>ネットワークロードバランサ：Google Cloudのネットワーク層の負荷分散ツールです。効果的な負荷分散を提供しますが、App Engine内部でのバージョン間のトラフィック分割には適していません。<br>正解についての説明：<br>（選択肢）<br>・同じアプリケーションに新バージョンをデプロイし、--splitsオプションを使って、現在のバージョンの重みを99、新バージョンの重みを1にします<br>この選択肢が正解の理由は以下の通りです。<br>Google App Engineでは、同一のアプリケーションに異なるバージョンをデプロイすることができ、トラフィック分割（スプリット）によって異なるバージョンへのリクエストの割合を制御することができます。トラフィックの分割は、新しいバージョンのテストや段階的なロールアウトに非常に効果的です。ここでは、--splitsオプションを用いて、現在のバージョンへの98％のリクエストと新バージョンへの1％のリクエストの割合を設定しています。<br>このように、一部のユーザーだけに新しいバージョンを見てもらうことができます。<br>また、アプリケーションやインフラストラクチャの複雑さを増やすことなく、これを実現することができます。つまり、これは複雑さを最小限に抑えながら、一部のユーザーだけに新しいバージョンのウェブサイトを見てもらうための適切な解決策と言えます。<br>不正解の選択肢についての説明：<br>選択肢：新しいバージョンを同じアプリケーションにデプロイし、--migrateオプションを使用します<br>この選択肢が正しくない理由は以下の通りです。<br>--migrateオプションは全てのトラフィックを新しいバージョンに移行するため、テストバージョンを1%のユーザーだけに見てもらうという要件を満たしません。<br>それに対して、--splitsオプションを使用すると、トラフィックの分割が可能で、要件にマッチします。<br>選択肢：同じプロジェクトで新しいApp Engineアプリケーションを作成します。そのアプリケーションに新しいバージョンをデプロイします。App Engineライブラリを使用して、リクエストの1%を新しいバージョンにプロキシします<br>この選択肢が正しくない理由は以下の通りです。<br>新しいApp Engineアプリケーションを同じプロジェクト上に作成すると、管理が複雑化します。<br>また、リクエストを新しいバージョンにプロキシするためにライブラリを使用するのは、複雑さを最小限に抑えるという条件に反します。<br>対照的に、--splitsオプションを使用すると、新旧のバージョン間でのトラフィック分割を直感的に管理することができます。<br>選択肢：同じプロジェクトで新しいApp Engineアプリケーションを作成します。そのアプリケーションに新しいバージョンをデプロイします。トラフィックの1%をその新しいアプリケーションに送信するように、ネットワークロードバランサを設定します<br>この選択肢が正しくない理由は以下の通りです。<br>App Engine内で新しいアプリケーションを作成するのではなく、既存のアプリケーション内に新しいバージョンをデプロイする方が単純で、複雑さも最小限に抑えられます。<br>さらに、ネットワークロードバランサはApp Engineのバージョン間のトラフィック分割を管理するために使用するべきではなく、App Engine自体のスプリットトラフィック機能を使用するべきです。'>
<div class='choice'> 新しいバージョンを同じアプリケーションにデプロイし、--migrateオプションを使用します</div>
<div class='choice'> 同じアプリケーションに新バージョンをデプロイし、--splitsオプションを使って、現在のバージョンの重みを99、新バージョンの重みを1にします</div>
<div class='choice'> 同じプロジェクトで新しいApp Engineアプリケーションを作成します。そのアプリケーションに新しいバージョンをデプロイします。App Engineライブラリを使用して、リクエストの1%を新しいバージョンにプロキシします</div>
<div class='choice'> 同じプロジェクトで新しいApp Engineアプリケーションを作成します。そのアプリケーションに新しいバージョンをデプロイします。トラフィックの1%をその新しいアプリケーションに送信するように、ネットワークロードバランサを設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題23<br>あなたは、営業時間中に組織内のメンバーに対してサービスを提供するコンテナ化されたウェブアプリケーションを開発しました。アプリケーションの使用時間外にコストが発生しないようにしたいと考えています。また、あなたは新しいGoogle Cloudプロジェクトを作成し、アプリケーションをデプロイしたいと考えています。<br>あなたはこの要件を満たすために、何をすべきですか？' data-answer='3' data-explanation='解説<br>正解は「コンテナをフルマネージドのCloud Runにデプロイし、インスタンスの最小数をゼロに設定します」です。<br>この問題では、あなたが組織内のメンバーに対してサービスを提供するコンテナ化されたウェブアプリケーションを開発し、その運用及びコスト管理戦略をどのように設計すべきかを解答することを求められています。特に、営業時間外にコストが発生しない運用方法を選定することがポイントです。具体的には、選択肢の中からどのプロダクトや機能を利用し、どのような設定を適用すればこれらの要件が満たせるのかを見極める能力が求められます。<br>基本的な概念や原則：<br>Cloud Run：Google Cloudのフルマネージドサービスで、コンテナ化されたアプリケーションをサーバレス環境で実行できます。使用していないときはコストが発生せず、需要に応じて自動的にスケールアップ/ダウンします。<br>Cloud Run for Anthos：Google Kubernetes Engine（GKE）クラスター上でサーバレスアプリケーションを実行するためのプラットフォームです。故意に無効化しない限り、クラスターのノードが稼働するためコストが発生します。<br>App Engineフレキシブル環境：アプリケーションをコンテナ化して自動的にスケーリングさせるためのPaaSです。しかし、最小インスタンス数を0に設定することはできません。<br>手動スケーリング：app.yaml設定ファイルに記述する設定で、一定の数のインスタンスが常に実行されるようにします。これは使用時間外にもコストが発生する可能性があります。<br>正解についての説明：<br>（選択肢）<br>・コンテナをフルマネージドのCloud Runにデプロイし、インスタンスの最小数をゼロに設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Cloud RunはGoogle Cloudが提供するフルマネージドのサービスで、コンテナ化されたアプリケーションを簡単にデプロイし、公開することができます。その最大の特徴は、アプリケーションがリクエストを受けた時だけインスタンスが起動し、それ以外の時間はシャットダウンされる、いわゆるサーバレスの特性を持っていることです。<br>したがって、使用時間外にはインスタンスが起動せず、その結果としてコストが発生しないという要件を満たすことができます。<br>また、Cloud Runでは、"インスタンスの最小数"を設定することができます。これにより、アプリケーションの使用量に応じて自動的にスケーリングすることができます。この場合、"インスタンスの最小数"をゼロに設定することで、リクエストがない状態ではインスタンスが起動せず、必要最低限のコストしか発生しないという状況を作り出すことができます。<br>不正解の選択肢についての説明：<br>選択肢：コンテナをCloud Run for Anthosにデプロイし、インスタンスの最小数をゼロに設定します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Run for AnthosはGKEクラスター上で実行されるため、GKEクラスターが稼働している間はコストが発生します。これは使用時間外でも発生します。<br>対照的に、フルマネージドのCloud Runは使用時のみ料金が発生し、最小インスタンス数をゼロに設定できます。これで使用時間外のコスト発生を防げます。<br>選択肢：App Engineフレキシブル環境にコンテナをデプロイし、app.yamlでmin_instancesをゼロに設定します<br>この選択肢が正しくない理由は以下の通りです。<br>App Engineフレキシブル環境では、app.yamlのmin_instancesをゼロに設定しても、待機中のインスタンスが削除されないため、使用時間外でもコストが発生します。<br>それに対して、Cloud Runはインスタンスの最小数をゼロに設定でき、リクエストがないときはコストが発生しません。<br>選択肢：App Engineフレキシブル環境に手動スケーリングでコンテナをデプロイし、app.yamlでvalue instancesをゼロに設定します<br>この選択肢が正しくない理由は以下の通りです。<br>App Engineフレキシブル環境で手動スケーリングを行うと、最低でも1つのインスタンスが常に稼働します。そのため、使用時間外にコストが発生しないようにするという要件を満たすことができません。<br>一方、Cloud Runでは最小数をゼロに設定することが可能であり、使用時以外は料金が発生しないので問題の要件を満たします。'>
<div class='choice'> App Engineフレキシブル環境に手動スケーリングでコンテナをデプロイし、app.yamlでvalue instancesをゼロに設定します</div>
<div class='choice'> App Engineフレキシブル環境にコンテナをデプロイし、app.yamlでmin_instancesをゼロに設定します</div>
<div class='choice'> コンテナをCloud Run for Anthosにデプロイし、インスタンスの最小数をゼロに設定します</div>
<div class='choice'> コンテナをフルマネージドのCloud Runにデプロイし、インスタンスの最小数をゼロに設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題24<br>あなたは新しいアプリケーションをホストするために、オートスケールを有効にしたGoogle Kubernetes Engineを使用しています。あなたは、パブリックIPアドレスでHTTPSを使用して、この新しいアプリケーションを公開したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「アプリケーション用にNodePortタイプのKubernetes Serviceを作成し、Cloud Load Balancer経由でこのサービスを公開するためにKubernetes Ingressを作成します」です。<br>この問題では、オートスケールを有効にしたGoogle Kubernetes Engineでホストする新しいアプリケーションをパブリックIPアドレスでHTTPSを使って公開する方法を解答しなければなりません。Kubernetes Serviceのタイプやその使い方、ロードバランサの設定と統合、そしてDNS設定について理解していることが必須です。また、パブリックアクセスを可能にするための観点から、どのようにトラフィックを制御し、どのIPを公開するかについても注意すべきです。問題の要件と選択肢を対比し、それぞれの選択肢が要件を満たすか、またそれが最善の選択かどうかを見極めます。<br>基本的な概念や原則：<br>Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を行います。<br>オートスケーリング：ロードに基づいて自動的にリソースのスケールを調節する機能です。GKEでは、ポッドのオートスケーリングやNodeのオートスケーリングを行います。<br>NodePort Service：KubernetesのServiceの一種で、特定のポートをクラスターの各Nodeに公開します。<br>Ingress：Kubernetesのリソースの一つで、HTTPとHTTPSのルートを管理します。外部からのアクセスをCluster内のServiceにルーティングします。<br>Cloud Load Balancer：Google Cloudのロードバランシングサービスです。HTTP(S)、TCP/UDPに対応し、グローバルなスケールでのトラフィックの分散を実現します。<br>ClusterIP Service：KubernetesのServiceの一種で、クラスター内からのみアクセス可能なIPアドレスをServiceに割り当てます。<br>HAProxy：高性能なロードバランサおよびプロキシサーバーです。Kubernetesクラスター内でのトラフィックの負荷分散に利用します。<br>正解についての説明：<br>（選択肢）<br>・アプリケーション用にNodePortタイプのKubernetes Serviceを作成し、Cloud Load Balancer経由でこのサービスを公開するためにKubernetes Ingressを作成します<br>この選択肢が正解の理由は以下の通りです。<br>まず、KubernetesのServiceは、デプロイされたアプリケーションのエンドポイントを提供しますが、NodePortタイプのKubernetes Serviceは各ノードの特定のポートにバインドし、それを通じてアクセスを許可します。これにより、アプリケーションはインターネットからアクセス可能になります。しかしながら、単独のNodePortは安全な公開には適していないばかりか、外部からのトラフィックを均等に分散するロードバランシングの機能が不足しています。<br>そこで、Kubernetes Ingressが役立ちます。Ingressはクラスター内部のServiceへの外部アクセスを制御しますが、これによりHTTPSを使用する安全なアクセスとLoad Balancerを統合することが可能になります。Ingressは更に高度な負荷分散を提供し、高負荷時のトラフィックの流れを制御します。以上から、NodePortタイプのKubernetes ServiceとIngressの組み合わせは外部からの安全かつ効率的なアクセスを実現するので、正解の選択肢です。<br>不正解の選択肢についての説明：<br>選択肢：アプリケーション用にClusterIPタイプのKubernetes Serviceを作成します。このServiceのIPを使用して、アプリケーションのパブリックDNS名を設定します<br>この選択肢が正しくない理由は以下の通りです。<br>ClusterIPタイプのKubernetes Serviceは、クラスター内部からのみアクセス可能とするためのサービスであり、外部からのアクセスを直接許可しないため、必要な要件を満たしません。<br>一方、正解のNodePortタイプのサービスとIngressを使用することで、外部からのアクセスとトラフィックのルーティングを柔軟に制御することができます。<br>選択肢：NodePortタイプのKubernetes Serviceを作成して、Kubernetesクラスターの各ノードのポート443でアプリケーションを公開します。アプリケーションのパブリックDNS名をクラスターの各ノードのIPで構成し、ロードバランシングを実現します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、この選択肢ではアプリケーションのパブリックDNS名を各ノードのIPで構成し、ロードバランシングを行うとしていますが、これは非効率的です。ロードバランシングの管理が手動となり、ノード追加や削除時に漏れや誤りが発生し易くなります。逆に正解選択肢の場合、Kubernetes IngressとCloud Load Balancerを使用することで、自動で効率的なロードバランシングが実現できます。<br>選択肢：アプリケーションのすべてのポッドへのトラフィックをロードバランスするために、クラスター内にHAProxyポッドを作成します。iptableルールでパブリックトラフィックをHAProxyに転送します。HAProxyが動作しているノードのパブリックIPを使用して、アプリケーションのDNS名を設定します<br>この選択肢が正しくない理由は以下の通りです。<br>HAProxyとiptablesを用いて手動でロードバランシングを設定するアプローチは、非常に手間がかかり、容易にスケーラビリティと耐障害性を確保できません。<br>対照的に、NodePortタイプのKubernetes ServiceとKubernetes Ingressを使用すれば、これらの要件を容易に満たすことができます。'>
<div class='choice'> アプリケーション用にNodePortタイプのKubernetes Serviceを作成し、Cloud Load Balancer経由でこのサービスを公開するためにKubernetes Ingressを作成します</div>
<div class='choice'> アプリケーションのすべてのポッドへのトラフィックをロードバランスするために、クラスター内にHAProxyポッドを作成します。iptableルールでパブリックトラフィックをHAProxyに転送します。HAProxyが動作しているノードのパブリックIPを使用して、アプリケーションのDNS名を設定します</div>
<div class='choice'> NodePortタイプのKubernetes Serviceを作成して、Kubernetesクラスターの各ノードのポート443でアプリケーションを公開します。アプリケーションのパブリックDNS名をクラスターの各ノードのIPで構成し、ロードバランシングを実現します</div>
<div class='choice'> アプリケーション用にClusterIPタイプのKubernetes Serviceを作成します。このServiceのIPを使用して、アプリケーションのパブリックDNS名を設定します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題25<br>あなたは、Kubernetes上にデプロイする必要がある新しいアプリケーションを開発したチームで働いています。本番アプリケーションはビジネスクリティカルであり、信頼性を最適化する必要があります。あなたはKubernetesクラスターをプロビジョニングする必要があり、Googleが推奨するプラクティスに従いたいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「GKE Autopilotクラスターを作成します。クラスターを安定リリースチャネルに登録します」です。<br>この問題では、ビジネスクリティカルなアプリケーションをデプロイするためのKubernetesクラスタープロビジョニングについて考える必要があります。そして、その際にGoogleの推奨するプラクティスに従う必要があります。問題のポイントは、アプリケーションのビジネスクリティカル性と信頼性の最適化の必要性です。つまり、最新の機能よりも信頼性と安定性が優先されるべきだということに注意が必要です。それに加え、Googleの推奨するプラクティスに従うことも重要なので、Googleが提唱しているKubernetesの運用方法に照らし合わせながら、適切な選択肢を選べばよいです。<br>基本的な概念や原則：<br>GKE Autopilot：Google Kubernetes Engine（GKE）のフルマネージド版です。インフラストラクチャの管理負荷を軽減し、ユーザーがアプリケーションの開発に集中できるようにします。<br>安定リリースチャネル：Google Cloudが提供するリリースチャネルの一つで、長期的な安定性と信頼性を優先するためのチャネルです。ビジネスクリティカルなワークロードに推奨されます。<br>ラピッドリリースチャネル：最新のリリースと機能を最初に提供するGKEのリリースチャネルですが、安定した運用よりも新機能の提供を優先するため、ビジネスクリティカルなワークロードでの使用は推奨されません。<br>GKE標準クラスター：Google Kubernetes Engineの従来のクラスタータイプで、ユーザーがクラスターの管理負担を担う必要があります。GKE Autopilotよりも詳細な管理が可能ですが、管理負荷が増えます。<br>リージョンGKE標準クラスター：GKEクラスターを1つのリージョン内の複数のゾーンに分散させる方式です。可用性が高い反面、設定の複雑性が増します。<br>正解についての説明：<br>（選択肢）<br>・GKE Autopilotクラスターを作成します。クラスターを安定リリースチャネルに登録します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Kubernetes Engine（GKE）Autopilotは、GoogleがサポートするKubernetesクラスターのプロビジョニング、設定、アップグレードなどといった運用を自動化し、堅牢で最適化されたクラスターコンフィギュレーションを提供します。これにより、開発チームはKubernetesの運用から解放され、アプリケーションの開発に集中することが可能になります。これはビジネスクリティカルなアプリケーションにとって重要な要件であり、信頼性を最適化するためにも推奨されます。<br>また、安定リリースチャネルにクラスターを登録することは、Googleの推奨プラクティスの一つです。これにより安定性と信頼性が向上し、新しい機能を試すよりもクラスターの動作を安定させることを優先できます。これらの理由から、GKE Autopilotクラスターを作成し、そのクラスターを安定リリースチャネルに登録することが適切な選択肢です。<br>不正解の選択肢についての説明：<br>選択肢：GKE Autopilotクラスターを作成します。クラスターをラピッドリリースチャネルに登録します<br>この選択肢が正しくない理由は以下の通りです。<br>ラピッドリリースチャネルは最新の機能を含む最新版のGKEを利用できますが、安定性は必ずしも保証されていません。<br>一方、安定リリースチャネルは長期間のテストと検証を経て安定性が確保されており、ビジネスクリティカルなアプリケーションの信頼性を最適化するのに適しています。<br>選択肢：ゾーンGKE標準クラスターを作成します。クラスターを安定リリースチャネルに登録します<br>この選択肢が正しくない理由は以下の通りです。<br>ゾーンGKE標準クラスターを使用すると、クラスターノードの管理やアップグレードなどは自身で行わなければならず、信頼性を最適化するのが難しくなります。反対に、GKE Autopilotはノードの管理をGoogleに委ねることができ、信頼性を最適化するのに役立ちます。<br>選択肢：リージョンGKE標準クラスターを作成します。クラスターをラピッドリリースチャネルに登録します<br>この選択肢が正しくない理由は以下の通りです。<br>リージョンGKE標準クラスターの作成とラピッドリリースチャネルへの登録は、速やかな新機能の利用やテスト環境向けであり、信頼性の最大化を目指すビジネスクリティカルな本番環境には不適切です。一方GKE Autopilotは、管理が容易でロバスト性の高い本番環境に向いており、安定リリースチャネルは信頼性が最優先されます。'>
<div class='choice'> GKE Autopilotクラスターを作成します。クラスターを安定リリースチャネルに登録します</div>
<div class='choice'> ゾーンGKE標準クラスターを作成します。クラスターを安定リリースチャネルに登録します</div>
<div class='choice'> リージョンGKE標準クラスターを作成します。クラスターをラピッドリリースチャネルに登録します</div>
<div class='choice'> GKE Autopilotクラスターを作成します。クラスターをラピッドリリースチャネルに登録します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題26<br>アプリケーション開発チームは、Google Cloud上にデプロイされるアプリケーションのDockerイメージを作成しました。あなたのチームは、このアプリケーションに関連するインフラストラクチャを管理したくありません。あなたは、アプリケーションが人気を集めるにつれて自動的にスケールできるようにする必要があります。<br>この要件を満たすために、どうすればよいですか？' data-answer='0' data-explanation='解説<br>正解は「DockerイメージをArtifact Registryにアップロードし、Cloud Run上にアプリケーションをデプロイします」です。<br>この問題では、既にDockerイメージを持っているアプリケーションをGoogle Cloud上にデプロイし、人気が出るにつれて自動的にスケーリングできるように設計することが求められています。問題文からはインフラストラクチャの管理を避けたいとの要望が読み取れます。そのため、少ない管理負荷で自動スケーリングが可能なサービスの選択が重要です。また、Dockerイメージをどのようにアップロードし、どのサービスを利用してデプロイするかがポイントとなります。適切なサービスを選択し、Dockerイメージの適切な配置と利用を行うことが求められます。<br>基本的な概念や原則：<br>Cloud Run：サーバレス環境でコンテナ化されたアプリケーションをフルマネージドで実行するGoogle Cloudのサービスです。アプリケーションが人気を集めるにつれて自動的にスケールが可能です。<br>Artifact Registry：Google Cloudのパッケージマネージメントサービスです。Dockerイメージや言語に依存するパッケージ等を保存し、共有することができます。<br>Docker：アプリケーションとその依存関係をパッケージ化し、コンテナとして実行するためのオープンソースプラットフォームです。<br>マネージドインスタンスグループ：Google Cloudでインスタンスグループの作成と自動スケーリングを行うサービスです。しかし、この選択肢はアプリケーションに関連するインフラストラクチャを自分で管理する必要があります。<br>Google Kubernetes Engine：Dockerコンテナを管理し、オートスケーリングを行うGoogle Cloudのサービスです。Kubernetesは自動化されていますが、Kubernetesクラスターを管理するオーバーヘッドが存在します。<br>Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データを可用性と耐久性を保ちながら、大規模に保存し、アクセスできます。ただし、直接Dockerイメージを実行することはできません。<br>正解についての説明：<br>（選択肢）<br>・DockerイメージをArtifact Registryにアップロードし、Cloud Run上にアプリケーションをデプロイします<br>この選択肢が正解の理由は以下の通りです。<br>まず、DockerイメージをArtifact Registryにアップロードすることにより、安全で信頼性の高いパッケージストレージと配布を提供します。Artifact RegistryはGoogle Cloud上に存在し、すぐに利用可能であり、特定のインフラストラクチャを管理する必要がありません。<br>次に、Cloud Runは管理型のコンテナ実行環境であり、瞬時にスケーリングされ、使った分だけ課金されるため、これを活用することで、アプリケーションが人気を集めて利用が増えても自動的にスケールし、適切なレスポンスを提供できます。このため、開発チームがアプリケーションに関連するインフラストラクチャを管理したくない要件や、アプリケーションが人気を集めるにつれて自動的にスケールする要件を同時に満たすことができ、この選択肢が最適と言えます。<br>不正解の選択肢についての説明：<br>選択肢：コンテナイメージでインスタンステンプレートを作成し、オートスケーリング機能付きのマネージドインスタンスグループをデプロイします<br>この選択肢が正しくない理由は以下の通りです。<br>インスタンステンプレートとマネージドインスタンスグループを使うと、インフラストラクチャの管理を手放すことはできません。<br>一方、Cloud Runはサーバレスなプラットフォームであり、インフラストラクチャの管理を一切せずにアプリケーションをデプロイしスケールすることができます。<br>選択肢：DockerイメージをArtifact Registryにアップロードし、Standardモードを使用してGoogle Kubernetes Engineにアプリケーションをデプロイします<br>この選択肢が正しくない理由は以下の通りです。<br>Google Kubernetes Engineを使用すると、インフラストラクチャの管理作業が発生します。問題文で指定されている"インフラストラクチャの管理をしたくない"という要件に反するため、この選択肢は正しくありません。<br>一方、Cloud Runはフルマネージドサービスであり、インフラストラクチャの管理をクラウドプロバイダに委ねられます。<br>選択肢：DockerイメージをCloud Storageにアップロードし、Standardモードを使用してGoogle Kubernetes Engineにアプリケーションをデプロイします<br>この選択肢が正しくない理由は以下の通りです。<br>まず、DockerイメージはArtifact Registryにアップロードするのが通常の手順です。Cloud Storageはバイナリデータを保存するためのサービスで、Dockerイメージのアップロードには適していません。<br>また、Kubernetes Engineはインフラ管理が必要なので、アプリケーション開発チームがインフラ管理をしたくないという要件とは対立します。自動スケーリングはGKEでも可能ですが、インフラの管理負荷を減らす目的ではCloud Runがより適しています。'>
<div class='choice'> DockerイメージをArtifact Registryにアップロードし、Cloud Run上にアプリケーションをデプロイします</div>
<div class='choice'> DockerイメージをArtifact Registryにアップロードし、Standardモードを使用してGoogle Kubernetes Engineにアプリケーションをデプロイします</div>
<div class='choice'> コンテナイメージでインスタンステンプレートを作成し、オートスケーリング機能付きのマネージドインスタンスグループをデプロイします</div>
<div class='choice'> DockerイメージをCloud Storageにアップロードし、Standardモードを使用してGoogle Kubernetes Engineにアプリケーションをデプロイします</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題27<br>あなたはGoogle Cloudにデプロイされる新しいウェブアプリケーションを開発しています。リリースサイクルの一環として、あなたは実際のユーザトラフィックのごく一部でアプリケーションのアップデートをテストしたいと考えています。ユーザーのトラフィックの大部分は、まだアプリケーションの安定版に向けられているべきです。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「App Engineにアプリケーションをデプロイします。アップデートのたびに、同じサービスの新しいバージョンを作成します。トラフィックのごく一部を新しいバージョンに送信するようにトラフィック分割を設定します」です。<br>この問題では、新しいウェブアプリケーションのリリースサイクルにおいて、アップデートを一部のユーザートラフィックでテストしたいという要求があります。また、大部分のユーザートラフィックはアプリケーションの安定版に向けられるべきである点も重要です。したがって問題を解く上で注意すべきは、既存の安定版と新バージョンを同時に運用し、しかも効率的にトラフィックを制御する能力を持つGoogle Cloudのサービス・設定を選択することです。選択肢からApp EngineやKubernetes Engineの利用の可否や設定方法を判断する必要があります。<br>基本的な概念や原則：<br>App Engine：Google Cloudのフルマネージドなプラットフォームで、開発者がアプリケーションをビルド、デプロイ、スケールするためのサービスです。<br>サービスとバージョン：App Engineでは、アプリケーションはサービスとバージョンによって組織化されます。各サービスは独立して動作し、各サービスは複数のバージョンを持つことができます。<br>トラフィック分割：App Engineの機能で、異なるバージョンのアプリケーションサービス間で受信トラフィックを分割することができます。これにより、新機能の影響を一部のユーザーでのみ確認するといったシナリオを実現することができます。<br>Kubernetes Engine：Google Cloudのコンテナ化されたアプリケーションを実行するためのマネージド環境です。Kubernetesのパワフルな機能を利用しながら、インフラの管理をGoogleに任せることができます。<br>デプロイメントとサービス：Kubernetesにおける主要なリソースで、デプロイメントはアプリケーションの更新を管理し、サービスは継続的なネットワークアクセスを提供します。新しいバージョンのリリース時にこれらを更新することで、アプリケーションの新版を適切にデプロイと配布することができます。<br>正解についての説明：<br>（選択肢）<br>・App Engineにアプリケーションをデプロイします。アップデートのたびに、同じサービスの新しいバージョンを作成します。トラフィックのごく一部を新しいバージョンに送信するようにトラフィック分割を設定します<br>この選択肢が正解の理由は以下の通りです。<br>まず、Google Cloud App Engineは、開発者がアプリケーションを容易にデプロイし、管理することを可能にする完全マネージドのPaaS（Platform as a Service）です。App Engineの重要な特性の一つは、同じアプリケーション内の異なるバージョン間でユーザートラフィックをシームレスに振り分ける能力です。<br>この機能は"トラフィック分割"と呼ばれ、新しいバージョンのアプリケーションに対するテストを可能にします。つまり、リリースサイクルの一環として新しいバージョンをデプロイし、そのアップデートが安定していることを確認した後、全体のトラフィックを徐々に新しいバージョンに移行することができます。<br>しかも、新しいバージョンが不安定な場合でも、トラフィックを既存の安定版に戻すことが簡単にできます。これは、新しいウェブアプリケーション開発時に世の中にリリースする前のアプリケーション更新のテストなどに非常に便利で、リスクを最小化します。<br>したがって、この選択肢はリリースサイクルとリスク管理における要件を最もよく満たしています。<br>不正解の選択肢についての説明：<br>選択肢：App Engineにアプリケーションをデプロイします。更新ごとに新しいサービスを作成します。トラフィックのごく一部を新しいサービスに送信するように、トラフィック分割を設定します<br>この選択肢が正しくない理由は以下の通りです。<br>App Engine内で新しいサービスを作成するというアプローチは、一部のトラフィックだけをテストに使用するという要件とは対照的になります。新しいサービスを作成すると、そのサービスに対して完全に新しいURLが割り当てられ、トラフィック分割を適用することが難しくなります。<br>一方、同じサービスで新しいバージョンを作成すると、簡単にトラフィックを新旧のバージョン間で分割することができます。<br>選択肢：Kubernetes Engineにアプリケーションをデプロイします。新しいリリースの場合は、新しいバージョンを使用するようにデプロイを更新します<br>この選択肢が正しくない理由は以下の通りです。<br>Kubernetes Engineでは新しいバージョンのデプロイ更新が全トラフィックに適用されるため、一部のトラフィックだけで新しいバージョンをテストするという要求に対応できません。<br>対照的に、App Engineではトラフィック分割を設定し、一部のトラフィックだけ新しいバージョンに向けることができます。<br>選択肢：Kubernetes Engineにアプリケーションをデプロイします。新しいリリースの場合は、新しいバージョン用の新しいデプロイメントを作成します。新しいデプロイメントを使用するようにサービスを更新します<br>この選択肢が正しくない理由は以下の通りです。<br>Kubernetes Engineを使用した場合、新しいデプロイメントを作成してサービスを更新するとトラフィックは全て新しいバージョンに向けられ、アプリケーションのアップデートをテストしたいという要件を満たすことができません。対してApp Engineではトラフィック分割を設定できるため、要件を満たすことができます。'>
<div class='choice'> App Engineにアプリケーションをデプロイします。更新ごとに新しいサービスを作成します。トラフィックのごく一部を新しいサービスに送信するように、トラフィック分割を設定します</div>
<div class='choice'> Kubernetes Engineにアプリケーションをデプロイします。新しいリリースの場合は、新しいバージョン用の新しいデプロイメントを作成します。新しいデプロイメントを使用するようにサービスを更新します</div>
<div class='choice'> App Engineにアプリケーションをデプロイします。アップデートのたびに、同じサービスの新しいバージョンを作成します。トラフィックのごく一部を新しいバージョンに送信するようにトラフィック分割を設定します</div>
<div class='choice'> Kubernetes Engineにアプリケーションをデプロイします。新しいリリースの場合は、新しいバージョンを使用するようにデプロイを更新します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題28<br>あなたの開発チームは、プロジェクトのために新しいJenkinsサーバーを必要としています。可能な限り少ない手順でサーバーをデプロイする必要があります。<br>この要件を満たすために、どうすればよいですか？' data-answer='2' data-explanation='解説<br>正解は「Google Cloud Marketplaceを使用して、Jenkinsソリューションを起動します」です。<br>この問題では、開発チームが新しいJenkinsサーバーをデプロイする際の助言を求めています。特に注目すべきは"可能な限り少ない手順でサーバーをデプロイする"という要件です。解答選択肢を精査する際には、その解答が具体的にどのような手順や操作を必要とするか考えることが重要です。言い換えれば、最も効率的で直接的な方法を選択するべきです。<br>基本的な概念や原則：<br>Google Cloud Marketplace：Google Cloudで利用できる、あらかじめ包装と最適化が行われたソフトウェアスタックを提供するサービスです。一連の設定を簡単に実行でき、公開サービスやアプリケーションを迅速にデプロイできます。<br>Jenkins：継続的なソフトウェア開発をサポートするオープンソースの自動化サーバーです。ビルド、テスト、デプロイなどの効率的な自動化を実行します。<br>App Engine Standard：Google Cloudの完全マネージドのアプリケーションプラットフォームです。自動スケーリングとゼロサーバー管理を提供しますが、特定のランタイム環境でのみ動作します。<br>Compute Engine：Google Cloudの仮想マシンを提供するサービスです。高度な設定と自動スケーリングが可能ですが、ソフトウェアのインストールや設定は手動で行う必要があります。<br>Kubernetesクラスター：コンテナ化されたアプリケーションのデプロイと管理を行うためのプラットフォームです。柔軟な設定とスケーリングが可能ですが、クラスターの設定と管理が必要です。<br>Jenkins Dockerイメージ：Dockerコンテナ内で実行できるようにパッケージ化されたJenkinsのバージョンです。Kubernetesなどのコンテナオーケストレーションプラットフォーム上で使用します。<br>正解についての説明：<br>（選択肢）<br>・Google Cloud Marketplaceを使用して、Jenkinsソリューションを起動します<br>この選択肢が正解の理由は以下の通りです。<br>Google Cloud Marketplaceは、あらゆる種類のソフトウェアソリューションをGoogle Cloudで簡単にデプロイできる環境を提供しています。Marketplaceには多数のJenkinsソリューションが含まれており、その多くはすぐに使える状態で提供されています。<br>また、Google Cloud Marketplaceからのソリューションのデプロイは非常に簡単で、ワンクリックで可能となっています。<br>したがって、新しいJenkinsサーバーが必要な場合、Google Cloud MarketplaceからJenkinsソリューションを起動することで、可能な限り少ない手順でサーバーをデプロイできます。この機能は特に、迅速なインフラストラクチャのデプロイが求められる開発環境にとって、時短や手間の削減に大きく貢献します。<br>不正解の選択肢についての説明：<br>選択肢：Jenkins Java WARをダウンロードしてApp Engine Standardにデプロイします<br>この選択肢が正しくない理由は以下の通りです。<br>Jenkins Java WARをダウンロードしてApp Engine Standardにデプロイする方法は複数の手順が必要です。それに比べGoogle Cloud Marketplaceを使えば、必要なJenkinsソリューションを直接起動することができ、より少ない手順でデプロイ可能です。<br>選択肢：新しいCompute Engineインスタンスを作成し、コマンドラインインターフェイスからJenkinsをインストールします<br>この選択肢が正しくない理由は以下の通りです。<br>新しいCompute Engineインスタンスを作成し、コマンドラインインターフェイスからJenkinsをインストールする方法は、手順が多くなり、時間と労力がかかります。対してGoogle Cloud Marketplaceを利用すると、既に組み立てられたJenkinsソリューションを簡単に起動でき、最小限の手順で目的を達成できます。<br>選択肢：Compute Engine上にKubernetesクラスターを作成し、Jenkins Dockerイメージでデプロイを作成します<br>この選択肢が正しくない理由は以下の通りです。<br>Compute Engine上にKubernetesクラスターを作成し、Jenkins Dockerイメージでデプロイ作成する方法は可能ですが、これでは手順が多くなってしまいます。<br>それに対して、Google Cloud Marketplaceを使用してJenkinsのソリューションを起動するとフォールなしで体験が可能で、手順の数と手間を大幅に減らすことができます。'>
<div class='choice'> Jenkins Java WARをダウンロードしてApp Engine Standardにデプロイします</div>
<div class='choice'> 新しいCompute Engineインスタンスを作成し、コマンドラインインターフェイスからJenkinsをインストールします</div>
<div class='choice'> Google Cloud Marketplaceを使用して、Jenkinsソリューションを起動します</div>
<div class='choice'> Compute Engine上にKubernetesクラスターを作成し、Jenkins Dockerイメージでデプロイを作成します</div>
</div>
<div class='question' data-multiple='FALSE' data-question='問題29<br>あなたの会社はオンプレミスのワークロードをGoogle Cloudに移行したいと考えています。現在のオンプレミスのワークロードは次のようなものです：<br>- Flask Webアプリケーション<br>- バックエンドAPI<br>- ETLとレポーティングのためのスケジュールされた長時間バックグラウンドジョブ<br>運用コストを抑える必要があるGoogleが推奨するプラクティスに従って、これらのワークロードをGoogle Cloud上のサーバレスソリューションに移行したいと考えています。<br>この要件を満たすために、どうすればよいですか？' data-answer='3' data-explanation='解説<br>正解は「ウェブアプリケーションをApp Engineに、バックエンドAPIをCloud Runに移行します。Cloud Tasksを使用してCloud Runでバックグラウンドジョブを実行します」です。<br>この問題では、オンプレミスのワークロードをGoogle Cloudのサーバレスソリューションに移行する最適な方法を選択することが求められています。ワークロードはウェブアプリケーション、バックエンドAPI、スケジュールされたバックグラウンドジョブの3つがあることから、それぞれに適したGoogle Cloudのサービスを選択する必要があります。サーバレスソリューションの利用が求められているため、インフラ管理に掛かる工数やコストを軽減するためのソリューションを選ぶことが重要です。それゆえ、選択肢は各ワークロードに適したサービスを使用し、かつサーバレスの特性を活用して効率的な運用が可能なオプションであることを確認する必要があります。<br>基本的な概念や原則：<br>App Engine：Google CloudのフルマネージドなPaaS（Platform as a Service）サービスです。開発者がサーバーの管理やスケーリングを気にせずにアプリケーションを構築・デプロイできます。<br>Cloud Run：Google Cloudのサービスで、コンテナ化したアプリケーションをサーバレス環境で実行することができます。インフラストラクチャの管理が不要で、リクエストに応じて自動的にスケールアップ・ダウンします。<br>Cloud Tasks：非同期タスクのキューを管理するGoogle Cloudのサービスです。システム全体の負荷を抑えながら、バックエンドサービスで時間のかかるタスクをスケジュールできます。<br>Compute Engine：Google CloudのIaaS（Infrastructure as a Service）サービスです。VM（Virtual Machine）のインフラストラクチャの管理が必要です。<br>Cloud Storage：大量のデータを安全に保存・取得できるGoogle Cloudのオブジェクトストレージサービスです。ただし、ウェブアプリケーションの実行には向かないツールです。<br>サーバレスソリューション：インフラストラクチャの管理が不要なソフトウェア開発のアプローチです。リソースの自動スケーリングと、利用したリソースに対してのみ課金されるため運用コストを抑えることができます。<br>正解についての説明：<br>（選択肢）<br>・ウェブアプリケーションをApp Engineに、バックエンドAPIをCloud Runに移行します。Cloud Tasksを使用してCloud Runでバックグラウンドジョブを実行します<br>この選択肢が正解の理由は以下の通りです。<br>まず、App EngineはGoogle Cloudの完全管理型サーバレスプラットフォームであり、ウェブアプリケーションを対象としています。Flask WebアプリケーションをApp Engineに移行すると、アプリケーションのスケーリング、監視、セキュリティ等に関するオペレーショナルな作業が自動化され、運用コストを抑えることができます。<br>次に、Cloud Runは、ステートレスバックエンドAPIのための完全管理型サーバレスプラットフォームであり、コンテナの使用に最適化されています。これにより、開発者は裏側のインフラストラクチャを気にせずにAPIをデプロイして運用することができます。<br>最後に、長時間稼働するバックグラウンドジョブをCloud Tasksでスケジュールすることで、実行タイミングを制御しつつ、適切にロードが分散され、エラーハンドリングが可能になります。<br>以上の理由から、正解はWebアプリケーションをApp Engineに、バックエンドAPIをCloud Runに移行し、Cloud Tasksを使用してバックグラウンドジョブを実行する方法です。<br>不正解の選択肢についての説明：<br>選択肢：WebアプリケーションをApp Engineに、バックエンドAPIをCloud Runに移行します。Cloud Tasksを使用して、Compute Engine上でバックグラウンドジョブを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>Compute Engineはサーバレスソリューションではなく、サーバーが必要であり、運用コストが増加します。<br>また、バックグラウンドジョブの実行にCompute Engineを使用すると、ジョブのスケジューリングやリソース管理が必要となり、これにより運用コストがさらに増加します。そのため、サーバレスソリューションを使用することで低コストを維持でき、正解の選択肢のようにCloud Runを使用する方が適切です。<br>選択肢：Cloud Storageバケット上でウェブアプリケーションを実行し、Cloud Run上でバックエンドAPIを実行します。Cloud Tasksを使ってCloud Run上でバックグラウンドジョブを実行します<br>この選択肢が正しくない理由は以下の通りです。<br>Cloud Storageはスタティックなコンテンツのホスティングに使用されるサービスであり、ダイナミックなFlask Webアプリケーションを実行することはできません。そのため、ウェブアプリケーションをCloud Storageに移行することは不適切です。それに対してApp Engineは自動スケーリングを提供し、Flaskアプリケーションを実行するのに適しています。<br>選択肢：ウェブアプリケーションをCloud Storageバケット上で実行し、バックエンドAPIをCloud Run上で実行します。Compute Engine上でバックグラウンドジョブを実行するために、Cloud Tasksを使用します<br>この選択肢が正しくない理由は以下の通りです。<br>まず、Cloud Storageバケットは静的なウェブページをホスティングするのに適していますが、Flask Webアプリケーションのようなダイナミックなウェブアプリケーションを実行するのには適していません。<br>また、Compute Engineはサーバレスではないため、サーバレスソリューションの要件に合致しません。バックグラウンドジョブにはCloud TasksとCloud Runの組み合わせが推奨されます。'>
<div class='choice'> WebアプリケーションをApp Engineに、バックエンドAPIをCloud Runに移行します。Cloud Tasksを使用して、Compute Engine上でバックグラウンドジョブを実行します</div>
<div class='choice'> Cloud Storageバケット上でウェブアプリケーションを実行し、Cloud Run上でバックエンドAPIを実行します。Cloud Tasksを使ってCloud Run上でバックグラウンドジョブを実行します</div>
<div class='choice'> ウェブアプリケーションをCloud Storageバケット上で実行し、バックエンドAPIをCloud Run上で実行します。Compute Engine上でバックグラウンドジョブを実行するために、Cloud Tasksを使用します</div>
<div class='choice'> ウェブアプリケーションをApp Engineに、バックエンドAPIをCloud Runに移行します。Cloud Tasksを使用してCloud Runでバックグラウンドジョブを実行します</div>
</div>
            <!-- 他の問題も同様に追加 -->
        </div>

        <h2 id="question"></h2>
        <ul class="choices" id="choices"></ul>
        <button onclick="checkAnswer()">採点</button>
        <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
        <div class="result" id="result"></div>
    </div>

    <script>
        let currentQuestionIndex = 0;
        let correctCount = 0;
        const questions = [];

        document.addEventListener('DOMContentLoaded', () => {
            const questionElements = document.querySelectorAll('#quiz-data .question');
            questions.push(...Array.from(questionElements).map(questionElement => ({
                question: questionElement.getAttribute('data-question').replace(/\\n/g, '<br>'),
                choices: Array.from(questionElement.querySelectorAll('.choice')).map((choice, index) => ({
                    text: choice.innerHTML.replace(/\\n/g, '<br>'),  // innerHTMLに変更
                    index: index
                })),
                correctAnswer: questionElement.getAttribute('data-answer').split(',').map(Number),
                explanation: questionElement.getAttribute('data-explanation').replace(/\\n/g, '<br>'),
                multiple: questionElement.getAttribute('data-multiple') === 'true'
            })));
            showQuestion();
        });

        function shuffleArray(array) {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
        }

        function showQuestion() {
            const questionElement = document.getElementById('question');
            const choicesContainer = document.getElementById('choices');
            const currentQuestion = questions[currentQuestionIndex];

            shuffleArray(currentQuestion.choices);

            questionElement.innerHTML = currentQuestion.question;
            choicesContainer.innerHTML = '';

            currentQuestion.choices.forEach((choice, i) => {
                const li = document.createElement('li');
                const input = document.createElement('input');
                const label = document.createElement('label');

                input.type = currentQuestion.multiple ? 'checkbox' : 'radio';
                input.name = 'choice';
                input.value = choice.index;
                input.id = 'choice' + i;

                label.htmlFor = 'choice' + i;
                label.innerHTML = choice.text;  // textContentをinnerHTMLに変更

                li.appendChild(input);
                li.appendChild(label);
                choicesContainer.appendChild(li);
            });

            document.getElementById('result').textContent = "";
            document.getElementById('nextButton').style.display = 'none';
        }

        function checkAnswer() {
            const currentQuestion = questions[currentQuestionIndex];
            const selectedChoices = Array.from(document.querySelectorAll('input[name="choice"]:checked'))
                                        .map(checkbox => parseInt(checkbox.value))
                                        .sort();
            const resultElement = document.getElementById('result');
            
            if (selectedChoices.length > 0) {
                const isCorrect = currentQuestion.multiple
                    ? selectedChoices.toString() === currentQuestion.correctAnswer.sort().toString()
                    : selectedChoices.length === 1 && selectedChoices[0] === currentQuestion.correctAnswer[0];
                
                if (isCorrect) {
                    resultElement.innerHTML = "正解です！<br>" + currentQuestion.explanation;
                    resultElement.style.color = "green";
                    correctCount++; // 正解数をカウント
                } else {
                    resultElement.innerHTML = "残念、不正解です。<br>" + currentQuestion.explanation;
                    resultElement.style.color = "red";
                }
                document.getElementById('nextButton').style.display = 'inline';
            } else {
                resultElement.textContent = "回答を選択してください。";
                resultElement.style.color = "orange";
            }
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < questions.length) {
                showQuestion();
            } else {
                showFinalResult();
            }
        }

        function showFinalResult() {
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2>問題終了！</h2>
                <p>あなたの正解数は ${correctCount} / ${questions.length} です。</p>
                <button onclick="restartQuiz()">再挑戦する</button>
            `;
        }

        function restartQuiz() {
            correctCount = 0;
            currentQuestionIndex = 0;

            // クイズのUI全体を初期化
            const quizContainer = document.querySelector('.quiz-container');
            quizContainer.innerHTML = `
                <h2 id="question"></h2>
                <ul class="choices" id="choices"></ul>
                <button onclick="checkAnswer()">採点</button>
                <button onclick="nextQuestion()" id="nextButton" style="display: none;">次の問題へ</button>
                <div class="result" id="result"></div>
            `;

            // 初期化後に最初の問題を表示
            showQuestion();
        }        
    </script>
</body>
</html>